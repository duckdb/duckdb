import json
import re
import os
from typing import OrderedDict

hpp_header = """//-------------------------------------------------------------------------
//                         DuckDB
//
//
// duckdb/common/enums/metrics_type.hpp
// 
// This file is automatically generated by scripts/generate_metric_enums.py
// Do not edit this file manually, your changes will be overwritten
//-------------------------------------------------------------------------

#pragma once

#include "duckdb/common/types/value.hpp"
#include "duckdb/common/unordered_set.hpp"
#include "duckdb/common/constants.hpp"
#include "duckdb/common/enums/optimizer_type.hpp"

namespace duckdb {

"""

hpp_typedefs = """
struct MetricsTypeHashFunction {
    uint64_t operator()(const MetricsType &index) const {
        return std::hash<uint8_t>()(static_cast<uint8_t>(index));
    }
};

typedef unordered_set<MetricsType, MetricsTypeHashFunction> profiler_settings_t;
typedef unordered_map<MetricsType, Value, MetricsTypeHashFunction> profiler_metrics_t;

"""

cpp_header = """// This file is automatically generated by scripts/generate_metric_enums.py
// Do not edit this file manually, your changes will be overwritten

#include "duckdb/common/enums/metric_type.hpp"
#include "duckdb/common/enum_util.hpp"

namespace duckdb {

"""


class IndentedFileWriter:
    """Wrapper around a file object that adds write_indented method."""

    def __init__(self, file_obj):
        self.file = file_obj

    def write_indented(self, indent_level, text):
        """Write text to file with the specified indentation level."""
        indent = '\t' * indent_level
        self.file.write(f"{indent}{text}\n")

    def write(self, text):
        """Delegate write to the underlying file object."""
        self.file.write(text)

    def close(self):
        """Delegate close to the underlying file object."""
        self.file.close()


def retrieve_optimizers():
    enum_pattern = r'\s*([A-Z_]+)\s*=\s*\d+,?|\s*([A-Z_]+),?'
    optimizer_file = os.path.join("..", "src", "include", "duckdb", "common", "enums", "optimizer_type.hpp")

    inside_enum = False
    optimizer_metrics = []
    with open(optimizer_file, "r") as f:
        for line in f:
            line = line.strip()

            if line.startswith("enum class OptimizerType"):
                inside_enum = True
                continue

            if inside_enum and line.startswith("};"):
                break

            if inside_enum:
                match = re.match(enum_pattern, line)
                if match:
                    optimizer_type = match[1] if match[1] else match[2]
                    if optimizer_type == "INVALID":
                        continue
                    optimizer_metrics.append(optimizer_type)

    optimizer_metrics.sort()
    return optimizer_metrics


def setup_hpp(f):
    f.write(hpp_header)

    f.write("enum class MetricGroup : uint8_t {\n")

    groups = []
    for group in all_metrics:
        groups.append(group.upper())

    groups.append("INVALID")
    groups.sort()

    for group in groups:
        f.write_indented(1, f"{group},")
    f.write("};\n\n")

    f.write("enum class MetricsType : uint8_t {\n")
    for metric in all_metrics["all"]:
        f.write_indented(1, f"{metric},")

    f.write("};\n")

    f.write(hpp_typedefs)

    f.write('class MetricsUtils {\n')
    f.write('public:\n')


# function that takes a string and turns it into pascal case
def to_pascal_case(string):
    return ''.join(word.capitalize() for word in string.split('_'))


def generate_standard_functions(group_name, hpp_f, cpp_f, metrics=None):
    # capitalize first letter of group name
    if metrics is None:
        metrics = all_metrics

    formatted_group_name = to_pascal_case(group_name)
    get_function = 'Get' + formatted_group_name + 'Metrics'

    hpp_f.write('\n')
    hpp_f.write_indented(1, f"// {formatted_group_name} metrics")
    hpp_f.write_indented(1, f"static profiler_settings_t {get_function}();")

    cpp_f.write(f"profiler_settings_t MetricsUtils::{get_function}() {{\n")
    cpp_f.write_indented(1, "return {")
    for metric in metrics[group_name]:
        cpp_f.write_indented(2, f"MetricsType::{metric},")
    cpp_f.write_indented(1, "};")
    cpp_f.write('}\n\n')

    if group_name == "all":
        generate_get_metric_by_group_function(hpp_f, cpp_f)
        return

    check_function = 'Is' + formatted_group_name + 'Metric'
    hpp_f.write_indented(1, f"static bool {check_function}(MetricsType type);")
    cpp_f.write(f"bool MetricsUtils::{check_function}(MetricsType type) {{\n")
    cpp_f.write_indented(1, "switch(type) {")
    for metric in metrics[group_name]:
        cpp_f.write_indented(2, f"case MetricsType::{metric}:")
    cpp_f.write_indented(3, "return true;")
    cpp_f.write_indented(2, "default:")
    cpp_f.write_indented(3, "return false;")
    cpp_f.write_indented(1, "}")
    cpp_f.write("}\n\n")


def generate_custom_optimizer_functions(optimizers, hpp_f, cpp_f):
    by_type = "GetOptimizerMetricByType(OptimizerType type)"
    by_metric = "GetOptimizerTypeByMetric(MetricsType type)"

    hpp_f.write_indented(1, f"static MetricsType {by_type};")
    hpp_f.write_indented(1, f"static OptimizerType {by_metric};")

    cpp_f.write(f"MetricsType MetricsUtils::{by_type} {{\n")
    cpp_f.write_indented(1, "switch(type) {")
    for optimizer in optimizers:
        cpp_f.write_indented(2, f"case OptimizerType::{optimizer}:")
        cpp_f.write_indented(3, f"return MetricsType::OPTIMIZER_{optimizer};")
    cpp_f.write_indented(2, "default:")
    cpp_f.write_indented(
        3, 'throw InternalException("OptimizerType %s cannot be converted to a MetricsType", EnumUtil::ToString(type));'
    )
    cpp_f.write_indented(1, "}")
    cpp_f.write('}\n\n')

    cpp_f.write(f"OptimizerType MetricsUtils::{by_metric} {{\n")
    cpp_f.write_indented(1, "switch(type) {")
    for optimizer in optimizers:
        cpp_f.write_indented(2, f"case MetricsType::OPTIMIZER_{optimizer}:")
        cpp_f.write_indented(3, f"return OptimizerType::{optimizer};")
    cpp_f.write_indented(2, "default:")
    cpp_f.write_indented(3, "return OptimizerType::INVALID;")
    cpp_f.write_indented(1, "}")
    cpp_f.write('}\n\n')


def generate_get_metric_by_group_function(hpp_f, cpp_f):
    func_name = "GetMetricsByGroupType(MetricGroup type)"

    hpp_f.write_indented(1, f"static profiler_settings_t {func_name};")

    cpp_f.write(f"profiler_settings_t MetricsUtils::{func_name} {{\n")
    cpp_f.write_indented(1, "switch(type) {")
    for group in all_metrics:
        formatted_group_name = group.upper()
        cpp_f.write_indented(1, f"case MetricGroup::{formatted_group_name}:")
        cpp_f.write_indented(2, "return {")
        for metric in all_metrics[group]:
            cpp_f.write_indented(3, f"MetricsType::{metric},")
        cpp_f.write_indented(3, "};")

    cpp_f.write_indented(1, "default:")
    cpp_f.write_indented(2, 'throw InternalException("The MetricGroup passed is invalid");')

    cpp_f.write_indented(1, "}")
    cpp_f.write('}\n')


def generate_metric_type_files(metrics_json, optimizers, root_scope_metrics):
    metrics_hpp_file = os.path.join("..", "src", "include", "duckdb", "common", "enums", "metric_type.hpp")
    metrics_cpp_file = os.path.join("..", "src", "common", "enums", "metric_type.cpp")

    hpp_f = IndentedFileWriter(open(metrics_hpp_file, "w"))
    setup_hpp(hpp_f)

    cpp_f = IndentedFileWriter(open(metrics_cpp_file, "w"))
    cpp_f.write(cpp_header)

    # for group in metrics_json:
    for group in all_metrics:
        generate_standard_functions(group, hpp_f, cpp_f)

        if group == "optimizer":
            generate_custom_optimizer_functions(optimizers, hpp_f, cpp_f)

    root_scope_metrics.sort()
    root_scope_parent = {"root_scope": root_scope_metrics}
    generate_standard_functions("root_scope", hpp_f, cpp_f, root_scope_parent)

    hpp_f.write("};\n")
    hpp_f.write("} // namespace duckdb\n")
    cpp_f.write("}\n")

    hpp_f.close()
    cpp_f.close()


def write_statement(f, statement_type, statement):
    f.write(f"statement {statement_type}\n")
    f.write(statement + "\n\n")


def write_query(f, options, query):
    f.write(f"query {options}\n")
    f.write(query + "\n")
    f.write("----\n")


def write_default_query(f):
    query = "SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();"
    write_statement(f, "ok", query)
    write_statement(f, "ok", "PRAGMA disable_profiling;")


def write_get_custom_profiling_settings(f):
    query = """
SELECT unnest(res) FROM (
    SELECT current_setting('custom_profiling_settings') AS raw_setting,
    raw_setting.trim('{}') AS setting,
    string_split(setting, ', ') AS res
) ORDER BY ALL;
            """.strip()
    write_query(f, "I", query)


def write_custom_profiling_optimizer(f):
    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"ALL_OPTIMIZERS\": \"true\"}';")

    write_default_query(f)

    query = """
SELECT * FROM (
    SELECT unnest(res) str FROM (
        SELECT current_setting('custom_profiling_settings') as raw_setting,
        raw_setting.trim('{}') AS setting,
        string_split(setting, ', ') AS res
    )
) WHERE '"true"' NOT in str
ORDER BY ALL \
            """.strip()
    write_query(f, "I", query)
    f.write("\n")

    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{}'")
    write_default_query(f)

    write_get_custom_profiling_settings(f)
    f.write("(empty)\n\n")

    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"OPTIMIZER_JOIN_ORDER\": \"true\"}'")
    write_default_query(f)

    write_get_custom_profiling_settings(f)
    f.write("\"OPTIMIZER_JOIN_ORDER\": \"true\"\n\n")

    write_statement(
        f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
    )

    query = """
SELECT
    CASE WHEN optimizer_join_order > 0 THEN 'true'
     ELSE 'false' END
FROM metrics_output;
            """.strip()
    write_query(f, "I", query)
    f.write("true\n\n")

    write_statement(f, "ok", "SET disabled_optimizers = 'JOIN_ORDER';")
    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"OPTIMIZER_JOIN_ORDER\": \"true\"}'")
    write_default_query(f)

    write_get_custom_profiling_settings(f)
    f.write("(empty)\n\n")

    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"CUMULATIVE_OPTIMIZER_TIMING\": \"true\"}';")
    write_default_query(f)

    write_statement(
        f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
    )

    query = """
SELECT
    CASE WHEN cumulative_optimizer_timing > 0 THEN 'true'
    ELSE 'false' END
FROM metrics_output;
        """.strip()
    write_query(f, "I", query)
    f.write("true\n\n")

    f.write("# All phase timings must be collected when using detailed profiling mode.\n\n")

    write_statement(f, "ok", "RESET custom_profiling_settings;")
    write_statement(f, "ok", "SET profiling_mode = 'detailed';")
    write_default_query(f)

    query = """
SELECT * FROM (
    SELECT unnest(res) str FROM (
        SELECT current_setting('custom_profiling_settings') AS raw_setting,
        raw_setting.trim('{}') AS setting,
        string_split(setting, ', ') AS res
    )
)
WHERE '"true"' NOT IN str
ORDER BY ALL
            """.strip()
    write_query(f, "I", query)
    f.write("\n")

    write_statement(f, "ok", "RESET custom_profiling_settings;")
    write_statement(f, "ok", "SET profiling_mode = 'standard';")


def generate_group_tests():
    top = """# name: test/sql/pragma/profiling/test_custom_profiling_using_groups.test
# description: Test default profiling settings using groups.
# group: [profiling]

# This file is automatically generated by scripts/generate_metric_enums.py
# Do not edit this file manually, your changes will be overwritten

require json

"""

    with open(
        os.path.join("..", "test", "sql", "pragma", "profiling", "test_custom_profiling_using_groups.test"), "w"
    ) as f:
        f.write(top)
        for group in all_metrics:
            write_statement(f, "ok", "PRAGMA enable_profiling = 'json';")
            write_statement(f, "ok", "PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';")
            write_statement(f, "ok", f"PRAGMA custom_profiling_settings='{{\"{group.upper()}\": \"true\"}}';")

            write_default_query(f)

            write_get_custom_profiling_settings(f)

            metrics = all_metrics[group]

            if group != "all" and "ALL_OPTIMIZERS" in metrics:
                metrics.extend(all_metrics["optimizer"])

            metrics.sort()
            for metric in metrics:
                f.write(f'"{metric}": "true"\n')
            f.write("\n")

            write_statement(
                f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
            )
            select = "SELECT\n"
            for metric in metrics:
                if group != "operator" and metric in all_metrics["operator"]:
                    continue
                select += f"\t{metric},\n"
            select = select[:-2]

            if group == "operator":
                select += "\nFROM (\n"
                select += "\tSELECT unnest(children, max_depth := 2)\n"
                select += "\tFROM metrics_output\n"
                select += ")"
            else:
                select += "\nFROM metrics_output;"
            write_statement(f, "ok", select)


def generate_test_files():
    test_names = ["test_default_profiling_settings", "test_custom_profiling_optimizer"]
    test_descriptions = ["default", "custom optimizer"]
    test_files = [os.path.join("..", "test", "sql", "pragma", "profiling", f"{name}.test") for name in test_names]

    for test_file, name, description in zip(test_files, test_names, test_descriptions):
        with open(test_file, "w") as f:
            display_name = test_file.replace("../", "")
            f.write(f"# name: {display_name}\n")
            f.write(f"# description: Test {description} profiling settings.\n")
            f.write("# group: [profiling]\n\n")
            f.write("# This file is automatically generated by scripts/generate_metric_enums.py\n")
            f.write("# Do not edit this file manually, your changes will be overwritten\n\n")

            f.write("require json\n\n")

            write_statement(f, "ok", "PRAGMA enable_profiling = 'json';")
            write_statement(f, "ok", "PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';")

            if name == "test_custom_profiling_optimizer":
                write_custom_profiling_optimizer(f)

            write_default_query(f)

            write_get_custom_profiling_settings(f)

            for group in all_metrics:
                if group == "default":
                    for metric in all_metrics[group]:
                        f.write(f'"{metric}": "true"\n')
            f.write("\n")

            write_statement(
                f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
            )
            write_statement(f, "ok", "SELECT cpu_time, extra_info, rows_returned, latency FROM metrics_output;")

    generate_group_tests()


def main():
    os.chdir(os.path.dirname(__file__))

    metrics_json_file = os.path.join("..", "src", "common", "enums", "metric_type.json")

    # extract all metrics from json
    with open(metrics_json_file, "r") as metrics_json:
        metrics_json = json.load(metrics_json)

    root_scope_metrics = []

    unsorted_metrics = {}
    for group in metrics_json:
        if "metrics" in group:
            metrics = []
            for metric in group["metrics"]:
                metrics.append(metric["name"])
                if "query_root" in metric:
                    root_scope_metrics.append(metric["name"])
            metrics.sort()
            group_name = group["group"]
            unsorted_metrics[group_name] = metrics

    optimizers = retrieve_optimizers()
    optimizers.sort()

    optimizer_metrics = []
    for optimizer in optimizers:
        optimizer_metrics.append(f"OPTIMIZER_{optimizer}")
    unsorted_metrics['optimizer'] = optimizer_metrics

    all_metrics_list = []
    for group in unsorted_metrics:
        for metric in unsorted_metrics[group]:
            all_metrics_list.append(metric)
    all_metrics_list.sort()
    unsorted_metrics["all"] = all_metrics_list

    global all_metrics
    all_metrics = OrderedDict(sorted(unsorted_metrics.items()))

    generate_metric_type_files(metrics_json, optimizers, root_scope_metrics)
    generate_test_files()


if __name__ == "__main__":
    main()
