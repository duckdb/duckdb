import json
import re
import os

hpp_header = """//-------------------------------------------------------------------------
//                         DuckDB
//
//
// duckdb/common/enums/metrics_type.hpp
// 
// This file is automatically generated by scripts/generate_metric_enums.py
// Do not edit this file manually, your changes will be overwritten
//-------------------------------------------------------------------------

#pragma once

#include "duckdb/common/types/value.hpp"
#include "duckdb/common/unordered_set.hpp"
#include "duckdb/common/constants.hpp"
#include "duckdb/common/enums/optimizer_type.hpp"

namespace duckdb {

"""

hpp_typedefs = """
struct MetricsTypeHashFunction {
	uint64_t operator()(const MetricsType &index) const {
		return std::hash<uint8_t>()(static_cast<uint8_t>(index));
	}
};

typedef unordered_set<MetricsType, MetricsTypeHashFunction> profiler_settings_t;
typedef unordered_map<MetricsType, Value, MetricsTypeHashFunction> profiler_metrics_t;

"""

cpp_header = """// This file is automatically generated by scripts/generate_metric_enums.py
// Do not edit this file manually, your changes will be overwritten

#include "duckdb/common/enums/metric_type.hpp"
#include "duckdb/common/enum_util.hpp"

namespace duckdb {

"""

all_metrics = {}


def retrieve_optimizers():
    enum_pattern = r'\s*([A-Z_]+)\s*=\s*\d+,?|\s*([A-Z_]+),?'
    optimizer_file = os.path.join("..", "src", "include", "duckdb", "common", "enums", "optimizer_type.hpp")

    inside_enum = False
    optimizer_metrics = []
    with open(optimizer_file, "r") as f:
        for line in f:
            line = line.strip()

            if line.startswith("enum class OptimizerType"):
                inside_enum = True
                continue

            if inside_enum and line.startswith("};"):
                break

            if inside_enum:
                match = re.match(enum_pattern, line)
                if match:
                    optimizer_type = match[1] if match[1] else match[2]
                    if optimizer_type == "INVALID":
                        continue
                    optimizer_metrics.append(optimizer_type)

    optimizer_metrics.sort()
    return optimizer_metrics


def setup_hpp(f):
    f.write(hpp_header)
    f.write("enum class MetricsType : uint8_t {\n")
    for group in all_metrics:
        for metric in all_metrics[group]:
            f.write(f"    {metric},\n")

    f.write("};\n")

    f.write(hpp_typedefs)

    f.write('class MetricsUtils {\n')
    f.write('public:\n')


# function that takes a string and turns it into pascal case
def to_pascal_case(string):
    return ''.join(word.capitalize() for word in string.split('_'))


def generate_standard_functions(group_name, hpp_f, cpp_f, metrics=None):
    # capitalize first letter of group name
    if metrics is None:
        metrics = all_metrics
    formatted_group_name = to_pascal_case(group_name)
    get_function = 'Get' + formatted_group_name + 'Metrics'
    check_function = 'Is' + formatted_group_name + 'Metric'

    hpp_f.write(f"    // {formatted_group_name} metrics\n")
    hpp_f.write(f"    static profiler_settings_t {get_function}();\n")
    hpp_f.write(f"    static bool {check_function}(MetricsType type);\n")

    cpp_f.write(f"profiler_settings_t MetricsUtils::{get_function}() {{\n")
    cpp_f.write('    return {\n')
    for metric in metrics[group_name]:
        cpp_f.write(f"        MetricsType::{metric},\n")
    cpp_f.write('    };\n')
    cpp_f.write('}\n\n')

    cpp_f.write(f"bool MetricsUtils::{check_function}(MetricsType type) {{\n")
    cpp_f.write('    switch(type) {\n')
    for metric in metrics[group_name]:
        cpp_f.write(f"        case MetricsType::{metric}:\n")
    cpp_f.write(f"            return true;\n")
    cpp_f.write("        default:\n")
    cpp_f.write("            return false;\n")
    cpp_f.write("    }\n")
    cpp_f.write("}\n\n")


def generate_custom_optimizer_functions(optimizers, hpp_f, cpp_f):
    by_type = "GetOptimizerMetricByType(OptimizerType type)"
    by_metric = "GetOptimizerTypeByMetric(MetricsType type)"

    hpp_f.write(f"    static MetricsType {by_type};\n")
    hpp_f.write(f"    static OptimizerType {by_metric};\n")

    cpp_f.write(f"MetricsType MetricsUtils::{by_type} {{\n")
    cpp_f.write('    switch(type) {\n')
    for optimizer in optimizers:
        cpp_f.write(f"        case OptimizerType::{optimizer}:\n")
        cpp_f.write(f"            return MetricsType::OPTIMIZER_{optimizer};\n")
    cpp_f.write('        default:\n')
    cpp_f.write(
        '            throw InternalException("OptimizerType %s cannot be converted to a MetricsType", EnumUtil::ToString(type));\n'
    )
    cpp_f.write('    }\n')
    cpp_f.write('}\n\n')

    cpp_f.write(f"OptimizerType MetricsUtils::{by_metric} {{\n")
    cpp_f.write('    switch(type) {\n')
    for optimizer in optimizers:
        cpp_f.write(f"        case MetricsType::OPTIMIZER_{optimizer}:\n")
        cpp_f.write(f"            return OptimizerType::{optimizer};\n")
    cpp_f.write('        default:\n')
    cpp_f.write('            return OptimizerType::INVALID;\n')
    cpp_f.write('    }\n')
    cpp_f.write('}\n\n')


def generate_metric_type_files(metrics_json, optimizers, root_scope_metrics):
    metrics_hpp_file = os.path.join("..", "src", "include", "duckdb", "common", "enums", "metric_type.hpp")
    metrics_cpp_file = os.path.join("..", "src", "common", "enums", "metric_type.cpp")

    hpp_f = open(metrics_hpp_file, "w")
    setup_hpp(hpp_f)

    cpp_f = open(metrics_cpp_file, "w")
    cpp_f.write(cpp_header)

    # for group in metrics_json:
    for group in metrics_json:
        group_name = group["group"]

        generate_standard_functions(group_name, hpp_f, cpp_f)

        if "custom_functions" in group:
            generate_custom_optimizer_functions(optimizers, hpp_f, cpp_f)

        hpp_f.write('\n')

    root_scope_metrics.sort()
    root_scope_parent = {"root_scope": root_scope_metrics}
    generate_standard_functions("root_scope", hpp_f, cpp_f, root_scope_parent)

    hpp_f.write("};\n")
    hpp_f.write("} // namespace duckdb\n")
    cpp_f.write("}\n")

    hpp_f.close()
    cpp_f.close()


def write_statement(f, statement_type, statement):
    f.write(f"statement {statement_type}\n")
    f.write(statement + "\n\n")


def write_query(f, options, query):
    f.write(f"query {options}\n")
    f.write(query + "\n")
    f.write("----\n")


def write_default_query(f):
    query = "SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();"
    write_statement(f, "ok", query)
    write_statement(f, "ok", "PRAGMA disable_profiling;")


def write_get_custom_profiling_settings(f):
    query = """
SELECT unnest(res) FROM (
    SELECT current_setting('custom_profiling_settings') AS raw_setting,
    raw_setting.trim('{}') AS setting,
    string_split(setting, ', ') AS res
) ORDER BY ALL;
            """.strip()
    write_query(f, "I", query)


def write_custom_profiling_optimizer(f):
    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"ALL_OPTIMIZERS\": \"true\"}';")

    write_default_query(f)

    query = """
SELECT * FROM (
    SELECT unnest(res) str FROM (
        SELECT current_setting('custom_profiling_settings') as raw_setting,
        raw_setting.trim('{}') AS setting,
        string_split(setting, ', ') AS res
    )
) WHERE '"true"' NOT in str
ORDER BY ALL \
            """.strip()
    write_query(f, "I", query)
    f.write("\n")

    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{}'")
    write_default_query(f)

    write_get_custom_profiling_settings(f)
    f.write("(empty)\n\n")

    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"OPTIMIZER_JOIN_ORDER\": \"true\"}'")
    write_default_query(f)

    write_get_custom_profiling_settings(f)
    f.write("\"OPTIMIZER_JOIN_ORDER\": \"true\"\n\n")

    write_statement(
        f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
    )

    query = """
SELECT
    CASE WHEN optimizer_join_order > 0 THEN 'true'
     ELSE 'false' END
FROM metrics_output;
            """.strip()
    write_query(f, "I", query)
    f.write("true\n\n")

    write_statement(f, "ok", "SET disabled_optimizers = 'JOIN_ORDER';")
    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"OPTIMIZER_JOIN_ORDER\": \"true\"}'")
    write_default_query(f)

    write_get_custom_profiling_settings(f)
    f.write("(empty)\n\n")

    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"CUMULATIVE_OPTIMIZER_TIMING\": \"true\"}';")
    write_default_query(f)

    write_statement(
        f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
    )

    query = """
SELECT
    CASE WHEN cumulative_optimizer_timing > 0 THEN 'true'
    ELSE 'false' END
FROM metrics_output;
        """.strip()
    write_query(f, "I", query)
    f.write("true\n\n")

    f.write("# All phase timings must be collected when using detailed profiling mode.\n\n")

    write_statement(f, "ok", "RESET custom_profiling_settings;")
    write_statement(f, "ok", "SET profiling_mode = 'detailed';")
    write_default_query(f)

    query = """
SELECT * FROM (
    SELECT unnest(res) str FROM (
        SELECT current_setting('custom_profiling_settings') AS raw_setting,
        raw_setting.trim('{}') AS setting,
        string_split(setting, ', ') AS res
    )
)
WHERE '"true"' NOT IN str
ORDER BY ALL
            """.strip()
    write_query(f, "I", query)
    f.write("\n")

    write_statement(f, "ok", "RESET custom_profiling_settings;")
    write_statement(f, "ok", "SET profiling_mode = 'standard';")


def generate_test_files():
    test_names = ["test_default_profiling_settings", "test_custom_profiling_optimizer"]
    test_descriptions = ["default", "custom optimizer"]
    test_files = [os.path.join("..", "test", "sql", "pragma", "profiling", f"{name}.test") for name in test_names]

    for test_file, name, description in zip(test_files, test_names, test_descriptions):
        with open(test_file, "w") as f:
            display_name = test_file.replace("../", "")
            f.write(f"# name: {display_name}\n")
            f.write(f"# description: Test {description} profiling settings.\n")
            f.write("# group: [profiling]\n\n")
            f.write("# This file is automatically generated by scripts/generate_metric_enums.py\n")
            f.write("# Do not edit this file manually, your changes will be overwritten\n\n")

            f.write("require json\n\n")

            write_statement(f, "ok", "PRAGMA enable_verification;")
            write_statement(f, "ok", "PRAGMA enable_profiling = 'json';")
            write_statement(f, "ok", "PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';")

            if name == "test_custom_profiling_optimizer":
                write_custom_profiling_optimizer(f)

            write_default_query(f)

            write_get_custom_profiling_settings(f)

            for group in all_metrics:
                if group == "default":
                    for metric in all_metrics[group]:
                        f.write(f'"{metric}": "true"\n')
            f.write("\n")

            write_statement(
                f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
            )
            write_statement(f, "ok", "SELECT cpu_time, extra_info, rows_returned, latency FROM metrics_output;")


def main():
    os.chdir(os.path.dirname(__file__))

    metrics_json_file = os.path.join("..", "src", "common", "enums", "metric_type.json")

    # extract all metrics from json
    with open(metrics_json_file, "r") as metrics_json:
        metrics_json = json.load(metrics_json)

    root_scope_metrics = []

    for group in metrics_json:
        if "metrics" in group:
            metrics = []
            for metric in group["metrics"]:
                metrics.append(metric["name"])
                if "query_root" in metric:
                    root_scope_metrics.append(metric["name"])
            metrics.sort()
            group_name = group["group"]
            all_metrics[group_name] = metrics

    optimizers = retrieve_optimizers()
    optimizers.sort()

    optimizer_metrics = []
    for optimizer in optimizers:
        optimizer_metrics.append(f"OPTIMIZER_{optimizer}")
    all_metrics['optimizer'] = optimizer_metrics

    generate_metric_type_files(metrics_json, optimizers, root_scope_metrics)
    generate_test_files()


if __name__ == "__main__":
    main()
