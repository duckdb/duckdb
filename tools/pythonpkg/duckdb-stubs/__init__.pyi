# to regenerate this from scratch, run scripts/regenerate_python_stubs.sh .
# be warned - currently there are still tweaks needed after this file is
# generated. These should be annotated with a comment like
# # stubgen override
# to help the sanity of maintainers.
from typing import Any, ClassVar

from typing import overload
import pandas
# stubgen override - unfortunately we need this for version checks
import sys
# stubgen override - This should probably not be exposed
#_clean_default_connection: Any
apilevel: str
comment: token_type
default_connection: DuckDBPyConnection
identifier: token_type
keyword: token_type
numeric_const: token_type
operator: token_type
paramstyle: str
string_const: token_type
threadsafety: int

class DuckDBPyConnection:
    def __init__(self, *args, **kwargs) -> None: ...
    def append(self, table_name: str, df: object) -> DuckDBPyConnection: ...
    def arrow(self, arg0: int) -> object: ...
    def begin(self) -> DuckDBPyConnection: ...
    def close(self) -> None: ...
    def commit(self) -> DuckDBPyConnection: ...
    def cursor(self) -> DuckDBPyConnection: ...
    @overload
    def df(self) -> object: ...
    @overload
    def df(self, df: object) -> DuckDBPyRelation: ...
    @overload
    def df(aliasoffrom_df) -> Any: ...
    def duplicate(self) -> DuckDBPyConnection: ...
    def execute(self, query: str, parameters: object = ..., multiple_parameter_sets: bool = ...) -> DuckDBPyConnection: ...
    def executemany(self, query: str, parameters: object = ...) -> DuckDBPyConnection: ...
    def fetch_arrow_table(self, chunk_size: int = ...) -> object: ...
    def fetch_df(self) -> object: ...
    def fetch_df_chunk(self, vectors_per_chunk: int = ...) -> object: ...
    def fetch_record_batch(self, chunk_size: int = ...) -> object: ...
    def fetchall(self) -> list: ...
    def fetchdf(self) -> object: ...
    def fetchnumpy(self) -> dict: ...
    def fetchone(self) -> object: ...
    def from_arrow(self, arrow_object: object, rows_per_thread: int = ...) -> DuckDBPyRelation: ...
    def from_csv_auto(self, file_name: str) -> DuckDBPyRelation: ...
    def from_df(self, df: object = ...) -> DuckDBPyRelation: ...
    def from_parquet(self, file_name: str, binary_as_string: bool = ...) -> DuckDBPyRelation: ...
    def from_query(self, query: str, alias: str = ...) -> DuckDBPyRelation: ...
    def from_substrait(self, proto: bytes) -> DuckDBPyRelation: ...
    def get_substrait(self, query: str) -> DuckDBPyRelation: ...
    def query(self, query: str, alias: str = ...) -> DuckDBPyRelation: ...
    def register(self, view_name: str, python_object: object, rows_per_thread: int = ...) -> DuckDBPyConnection: ...
    def rollback(self) -> DuckDBPyConnection: ...
    def table(self, table_name: str) -> DuckDBPyRelation: ...
    def table_function(self, name: str, parameters: object = ...) -> DuckDBPyRelation: ...
    def unregister(self, view_name: str) -> DuckDBPyConnection: ...
    def values(self, values: object) -> DuckDBPyRelation: ...
    def view(self, view_name: str) -> DuckDBPyRelation: ...
    def get_table_names(self, query: str) -> object: ...
    def __enter__(self, database: str, read_only: bool, config: dict) -> DuckDBPyConnection: ...
    def __exit__(self, exc_type: str, exc: str, traceback: str) -> bool: ...
    @property
    def description(self) -> object: ...

class DuckDBPyRelation:
    def __init__(self, *args, **kwargs) -> None: ...
    def abs(self, aggregation_columns: str, group_columns: str = ...) -> DuckDBPyRelation: ...
    def aggregate(self, aggr_expr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def apply(self, function_name: str, function_aggr: str, group_expr: str = ..., function_parameter: str = ..., projected_columns: str = ...) -> DuckDBPyRelation: ...
    def arrow(self, batch_size: int = ...) -> object: ...
    def count(self, count_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def create(self, table_name: str) -> None: ...
    def create_view(self, view_name: str, replace: bool = ...) -> DuckDBPyRelation: ...
    def cummax(self, aggregation_columns: str) -> DuckDBPyRelation: ...
    def cummin(self, aggregation_columns: str) -> DuckDBPyRelation: ...
    def cumprod(self, aggregation_columns: str) -> DuckDBPyRelation: ...
    def cumsum(self, aggregation_columns: str) -> DuckDBPyRelation: ...
    def describe(self) -> DuckDBPyRelation: ...
    def df(self) -> object: ...
    def distinct(self) -> DuckDBPyRelation: ...
    def except_(self, other_rel: DuckDBPyRelation) -> DuckDBPyRelation: ...
    def execute(self, *args, **kwargs) -> Any: ...
    def fetchall(self) -> object: ...
    def fetchone(self) -> object: ...
    def filter(self, filter_expr: str) -> DuckDBPyRelation: ...
    def insert(self, values: object) -> None: ...
    def insert_into(self, table_name: str) -> None: ...
    def intersect(self, other_rel: DuckDBPyRelation) -> DuckDBPyRelation: ...
    def join(self, other_rel: DuckDBPyRelation, condition: str, how: str = ...) -> DuckDBPyRelation: ...
    def kurt(self, aggregation_columns: str, group_columns: str = ...) -> DuckDBPyRelation: ...
    def limit(self, n: int, offset: int = ...) -> DuckDBPyRelation: ...
    def mad(self, aggregation_columns: str, group_columns: str = ...) -> DuckDBPyRelation: ...
    def map(self, map_function: function) -> DuckDBPyRelation: ...
    def max(self, max_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def mean(self, mean_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def median(self, median_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def min(self, min_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def mode(self, aggregation_columns: str, group_columns: str = ...) -> DuckDBPyRelation: ...
    def order(self, order_expr: str) -> DuckDBPyRelation: ...
    def prod(self, aggregation_columns: str, group_columns: str = ...) -> DuckDBPyRelation: ...
    def project(self, project_expr: str) -> DuckDBPyRelation: ...
    def quantile(self, q: str, quantile_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def query(self, *args, **kwargs) -> Any: ...
    def record_batch(self, batch_size: int = ...) -> object: ...
    def sem(self, aggregation_columns: str, group_columns: str = ...) -> DuckDBPyRelation: ...
    def set_alias(self, alias: str) -> DuckDBPyRelation: ...
    def skew(self, aggregation_columns: str, group_columns: str = ...) -> DuckDBPyRelation: ...
    def std(self, std_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def sum(self, sum_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def to_arrow_table(self, batch_size: int = ...) -> object: ...
    def to_df(self) -> object: ...
    @overload
    def union(self, union_rel: DuckDBPyRelation) -> DuckDBPyRelation: ...
    @overload
    def union(self, arg0: DuckDBPyRelation) -> DuckDBPyRelation: ...
    def unique(self, unique_aggr: str) -> DuckDBPyRelation: ...
    def value_counts(self, value_counts_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def var(self, var_aggr: str, group_expr: str = ...) -> DuckDBPyRelation: ...
    def write_csv(self, file_name: str) -> None: ...
    def __len__(self) -> int: ...
    @property
    def alias(self) -> str: ...
    @property
    def columns(self) -> list: ...
    @property
    def dtypes(self) -> list: ...
    @property
    def shape(self) -> tuple: ...
    @property
    def type(self) -> str: ...
    @property
    def types(self) -> list: ...

class DuckDBPyResult:
    def __init__(self, *args, **kwargs) -> None: ...
    def arrow(self, chunk_size: int = ...) -> object: ...
    def close(self) -> None: ...
    def description(self) -> list: ...
    def df(self) -> object: ...
    def fetch_arrow_reader(self, approx_batch_size: int) -> object: ...
    def fetch_arrow_table(self, chunk_size: int = ...) -> object: ...
    def fetch_df(self) -> object: ...
    def fetch_df_chunk(self, arg0: int) -> object: ...
    def fetchall(self) -> list: ...
    def fetchdf(self) -> object: ...
    def fetchnumpy(self) -> dict: ...
    def fetchone(self) -> object: ...

class token_type:
    # stubgen override - these make mypy sad
    #__doc__: ClassVar[str] = ...  # read-only
    #__members__: ClassVar[dict] = ...  # read-only
    __entries: ClassVar[dict] = ...
    comment: ClassVar[token_type] = ...
    identifier: ClassVar[token_type] = ...
    keyword: ClassVar[token_type] = ...
    numeric_const: ClassVar[token_type] = ...
    operator: ClassVar[token_type] = ...
    string_const: ClassVar[token_type] = ...
    def __init__(self, value: int) -> None: ...
    def __eq__(self, other: object) -> bool: ...
    def __getstate__(self) -> int: ...
    def __hash__(self) -> int: ...
    # stubgen override - pybind only puts index in python >= 3.8: https://github.com/EricCousineau-TRI/pybind11/blob/54430436/include/pybind11/pybind11.h#L1789
    if sys.version_info >= (3, 7):
        def __index__(self) -> int: ...
    def __int__(self) -> int: ...
    def __ne__(self, other: object) -> bool: ...
    def __setstate__(self, state: int) -> None: ...
    @property
    def name(self) -> str: ...
    @property
    def value(self) -> int: ...
    @property
    def __members__(self) -> object: ...

def aggregate(df: object, aggr_expr: str, group_expr: str = ..., connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def alias(df: object, alias: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def arrow(table: object, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def connect(database: str = ..., read_only: bool = ..., config: dict = ...) -> DuckDBPyConnection: ...
def df(df: object, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def distinct(df: object, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def filter(df: object, filter_expr: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def from_arrow(table: object, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def from_csv_auto(file_name: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def from_df(df: object, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
@overload
def from_parquet(file_name: str, binary_as_string: bool, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
@overload
def from_parquet(file_name: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def from_query(query: str, alias: str = ..., connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def from_substrait(proto: bytes, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def get_substrait(query: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def limit(df: object, n: int, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def order(df: object, order_expr: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def project(df: object, project_expr: str, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def query(query: str, alias: str = ..., connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def query_df(df: object, virtual_table_name: str, sql_query: str, connection: DuckDBPyConnection = ...) -> DuckDBPyResult: ...
def tokenize(query: str) -> object: ...
def values(values: object, connection: DuckDBPyConnection = ...) -> DuckDBPyRelation: ...
def write_csv(df: object, file_name: str, connection: DuckDBPyConnection = ...) -> None: ...
