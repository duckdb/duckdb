# name: test/sql/copy/csv/glob/read_csv_glob_s3.test
# description: Test globbing CSVs over s3
# group: [glob]

require httpfs

require-env S3_TEST_SERVER_AVAILABLE 1

# Require that these environment variables are also set

require-env AWS_DEFAULT_REGION

require-env AWS_ACCESS_KEY_ID

require-env AWS_SECRET_ACCESS_KEY

require-env DUCKDB_S3_ENDPOINT

require-env DUCKDB_S3_USE_SSL

# override the default behaviour of skipping HTTP errors and connection failures: this test fails on connection issues
set ignore_error_messages

# Copy files to S3 before beginning tests
statement ok
COPY (select * from read_csv_auto('test/sql/copy/csv/data/glob/a1/a1.csv', header=True)) to 's3://test-bucket/read_csv_glob_s3/glob/a1/a1.csv' ( HEADER );
COPY (select * from read_csv_auto('test/sql/copy/csv/data/glob/a2/a2.csv', header=True)) to 's3://test-bucket/read_csv_glob_s3/glob/a2/a2.csv' ( HEADER );
COPY (select * from read_csv_auto('test/sql/copy/csv/data/glob/a3/b1.csv', header=True)) to 's3://test-bucket/read_csv_glob_s3/glob/a3/b1.csv' ( HEADER );
COPY (select null) to 's3://test-bucket/read_csv_glob_s3/glob/empty/empty.csv';
COPY (select * from read_csv_auto('test/sql/copy/csv/data/glob/i1/integer.csv', header=True)) to 's3://test-bucket/read_csv_glob_s3/glob/i1/integer.csv' ( HEADER );
COPY (select * from read_csv_auto('test/sql/copy/csv/data/glob/a1/a1.csv', header=True)) to 's3://test-bucket/read_csv_glob_s3/glob/f1/f*.csv' ( HEADER );
COPY (select * from read_csv_auto('test/sql/copy/csv/data/glob/a2/a2.csv', header=True)) to 's3://test-bucket/read_csv_glob_s3/glob/f2/f[a].csv' ( HEADER );

foreach urlstyle path vhost

statement ok
SET s3_url_style='${urlstyle}'

# simple globbing
query I
SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/a[123]/*.csv', auto_detect=1) ORDER BY 1
----
2019-06-05
2019-06-15
2019-06-25
2019-07-05
2019-07-15
2019-07-25
2019-08-05
2019-08-15
2019-08-25

query I
SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/*/a[123]/a*.csv', auto_detect=1) ORDER BY 1
----
2019-06-05
2019-06-15
2019-06-25
2019-07-05
2019-07-15
2019-07-25

query II
SELECT a, b LIKE '%a1.csv%' FROM read_csv('s3://test-bucket/read_csv_glob_s3/gl*/a[123]/a*.csv', auto_detect=1, filename=1) t1(a,b) ORDER BY 1
----
2019-06-05	1
2019-06-15	1
2019-06-25	1
2019-07-05	0
2019-07-15	0
2019-07-25	0

# read-csv auto fails here because of a type mismatch: most files contain dates, but one file contains integers
statement error
SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/*/*.csv', auto_detect=1) ORDER BY 1

# forcing string parsing works
query I
SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/[aei]*/*.csv', columns=STRUCT_PACK(d := 'STRING'), header=1) ORDER BY 1
----
1
2
2019-06-05
2019-06-15
2019-06-25
2019-07-05
2019-07-15
2019-07-25
2019-08-05
2019-08-15
2019-08-25
3

query II
SELECT a, b LIKE '%a_.csv' FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/[aei]*/*.csv', columns=STRUCT_PACK(d := 'STRING'), header=1, filename=1) t(a,b) ORDER BY 1
----
1	0
2	0
2019-06-05	1
2019-06-15	1
2019-06-25	1
2019-07-05	1
2019-07-15	1
2019-07-25	1
2019-08-05	0
2019-08-15	0
2019-08-25	0
3	0

# test glob parsing
query I
SELECT COUNT(*) FROM glob('s3://test-bucket/read_csv_glob_s3/glob/[aei]*/*.csv')
----
5

# nothing matches the glob
statement error
SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/[aei]*/a*a.csv', auto_detect=1) ORDER BY 1

query I
SELECT COUNT(*) FROM glob('s3://test-bucket/read_csv_glob_s3/glob/[aei]*/a*a.csv')
----
0

query I
select count(*) from glob('s3://test-bucket/read_csv_glob_s3/glob/rewoiarwiouw3rajkawrasdf790273489*.csv') limit 10;
----
0

# Escaping
query I
SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/f*/f\*.csv', auto_detect=1) ORDER BY 1
----
2019-06-05
2019-06-15
2019-06-25

# TODO: for supporting this we need to combine s3 url encoding with duckdb pattern matching
#query I
#SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/f2/f[a].csv', auto_detect=1) ORDER BY 1
#----
#2019-07-05
#2019-07-15
#2019-07-25

#query I
#SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/f2/f\[a\].csv', auto_detect=1) ORDER BY 1
#----
#2019-07-05
#2019-07-15
#2019-07-25

statement error
SELECT * FROM read_csv('s3://test-bucket/read_csv_glob_s3/glob/e2/e[a].csv', auto_detect=1) ORDER BY 1

endloop