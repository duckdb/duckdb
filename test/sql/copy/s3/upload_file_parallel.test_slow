# name: test/sql/copy/s3/upload_file_parallel.test_slow
# description: Copy large parquet files from and to S3 in parallel.
# group: [s3]

require tpch

require parquet

require httpfs

require-env S3_TEST_SERVER_AVAILABLE 1

# Require that these environment variables are also set

require-env AWS_DEFAULT_REGION

require-env AWS_ACCESS_KEY_ID

require-env AWS_SECRET_ACCESS_KEY

require-env DUCKDB_S3_ENDPOINT

require-env DUCKDB_S3_USE_SSL

# override the default behaviour of skipping HTTP errors and connection failures: this test fails on connection issues
set ignore_error_messages

statement ok
CALL DBGEN(sf=1)

statement ok
set http_timeout=120000;

# More retries (longest wait will be 25600ms)
statement ok
set http_retries=6;

query I
SELECT
    sum(l_extendedprice * l_discount) AS revenue
FROM
    lineitem
WHERE
    l_shipdate >= CAST('1994-01-01' AS date)
    AND l_shipdate < CAST('1995-01-01' AS date)
    AND l_discount BETWEEN 0.05
    AND 0.07
    AND l_quantity < 24;
----
123141078.2283

# We do this in parallel to also test synchronization of s3fs between 2 connections
concurrentloop threadid 0 2

statement ok
SET s3_endpoint='${DUCKDB_S3_ENDPOINT}';SET s3_use_ssl=${DUCKDB_S3_USE_SSL};

# Parquet file
statement ok
COPY lineitem TO 's3://test-bucket/multipart/export_large_${threadid}.parquet' (FORMAT 'parquet');

query I
SELECT
    sum(l_extendedprice * l_discount) AS revenue
FROM
    "s3://test-bucket/multipart/export_large_${threadid}.parquet"
WHERE
    l_shipdate >= CAST('1994-01-01' AS date)
    AND l_shipdate < CAST('1995-01-01' AS date)
    AND l_discount BETWEEN 0.05
    AND 0.07
    AND l_quantity < 24;
----
123141078.2283

endloop

statement ok
CALL dbgen(sf=0.01, suffix='_small');

query I
SELECT
    sum(l_extendedprice * l_discount) AS revenue
FROM
    lineitem_small
WHERE
    l_shipdate >= CAST('1994-01-01' AS date)
    AND l_shipdate < CAST('1995-01-01' AS date)
    AND l_discount BETWEEN 0.05
    AND 0.07
    AND l_quantity < 24;
----
1193053.2253

# Upload and query 100 tiny files in parallel
concurrentloop threadid 0 100

statement ok
SET s3_secret_access_key='${AWS_SECRET_ACCESS_KEY}';SET s3_access_key_id='${AWS_ACCESS_KEY_ID}';SET s3_region='${AWS_DEFAULT_REGION}'; SET s3_endpoint='${DUCKDB_S3_ENDPOINT}';SET s3_use_ssl=${DUCKDB_S3_USE_SSL};

statement ok
SET s3_uploader_thread_limit=1

# Parquet file
statement ok
COPY lineitem_small TO 's3://test-bucket/multipart/export_small_${threadid}.parquet' (FORMAT 'parquet');

query I
SELECT
    sum(l_extendedprice * l_discount) AS revenue
FROM
    "s3://test-bucket/multipart/export_small_${threadid}.parquet"
WHERE
    l_shipdate >= CAST('1994-01-01' AS date)
    AND l_shipdate < CAST('1995-01-01' AS date)
    AND l_discount BETWEEN 0.05
    AND 0.07
    AND l_quantity < 24;
----
1193053.2253

endloop