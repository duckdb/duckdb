# name: test/sql/copy/s3/glob_s3_paging.test_slow
# description: Test globbing of a large number of parquet files to test the paging mechanism
# group: [s3]

require parquet

require httpfs

require-env S3_TEST_SERVER_AVAILABLE 1

# override the default behaviour of skipping HTTP errors and connection failures: this test fails on connection issues
set ignore_error_messages

statement ok
SET s3_secret_access_key='minio_duckdb_user_password';SET s3_access_key_id='minio_duckdb_user';SET s3_region='eu-west-1'; SET s3_endpoint='duckdb-minio.com:9000';SET s3_use_ssl=false;

# Test should be a bit faster using the metadata cache
statement ok
SET enable_http_metadata_cache=true;

foreach urlstyle path vhost

statement ok
SET s3_url_style='${urlstyle}'

## For both formats we generate 2000 files which we will glob to test the paging mechanism of aws ListObjectV2 call is handled properly
foreach format parquet csv

foreach i 0 1

foreach j 0 1 2 3 4 5 6 7 8 9

foreach k 0 1 2 3 4 5 6 7 8 9

foreach l 0 1 2 3 4 5 6 7 8 9

statement ok
COPY (select (${i}${j}${k}${l})::INT as column0) to 's3://test-bucket/parquet_glob_s3_paging/paging/t${i}${j}${k}${l}-${urlstyle}-urls.${format}';

endloop

endloop

endloop

endloop

# Begin tests
query I
select sum(column0) from 's3://test-bucket/parquet_glob_s3_paging/paging/t*-${urlstyle}-urls.${format}'
----
1999000

endloop

endloop