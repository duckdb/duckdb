# name: test/sql/copy/parquet/batched_write/batch_memory_usage.test_slow
# description: Batched Parquet write memory usage
# group: [batched_write]

require parquet

set seed 0.72

statement ok
COPY (SELECT uuid()::VARCHAR as varchar, uuid() AS uuid FROM range(10000000) t(i)) TO '{TEMP_DIR}/random_uuids.parquet'

# copy from one parquet file to another in a memory constrained environment
statement ok
SET memory_limit='650MB'

statement ok
COPY '{TEMP_DIR}/random_uuids.parquet' TO '{TEMP_DIR}/random_uuids_copy.parquet';

# ensure the parquet files hold the same content
statement ok
SET memory_limit='2GB';

# ensure the parquet files hold the same content in the same order
query III
SELECT *, row_number() OVER () as rownum FROM '{TEMP_DIR}/random_uuids.parquet'
EXCEPT
SELECT *, row_number() OVER () as rownum FROM '{TEMP_DIR}/random_uuids_copy.parquet';
----