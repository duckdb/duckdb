# name: test/sql/storage/compression/roaring/roaring_analyze_array.test
# description: Check the produced (final_)analyze result
# group: [roaring]

require block_size 262144

require noforcestorage

statement ok
SET storage_compatibility_version='v1.2.0'

load __TEST_DIR__/test_roaring.db

statement ok
set logging_level='info';

# 1 rowgroup
statement ok
set variable dataset_size = 122880;

statement ok
PRAGMA force_compression='uncompressed'

statement ok
set enable_logging=true;

statement ok
CREATE TABLE test_uncompressed AS SELECT
	case
		when i%25=0
			then 1337
		else null
	end
	FROM range(getvariable('dataset_size')) tbl(i);

statement ok
checkpoint

statement ok
set enable_logging=false;

query I
SELECT message.split(': ')[2]::INTEGER FROM duckdb_logs
where
	message.starts_with('FinalAnalyze') and
	message.contains('test_uncompressed') and
	message.contains('VALIDITY') and
	message.contains('COMPRESSION_UNCOMPRESSED');
----
15360

statement ok
PRAGMA force_compression='roaring'

statement ok
set enable_logging=true;

statement ok
CREATE TABLE test_roaring AS select * from test_uncompressed;

statement ok
checkpoint

statement ok
set enable_logging=false;

# For single row group
# 60 vectors with 82 non-null values per vector
# Total compressed bytes:
# 2 bits (is_inverted + is_run) + 8 bits (cardinality) = 10 bits per Vector
# 10 * 60 = 600 bits == 75 bytes of metadata per RowGroup
#
# 8 (compressed overhead) + (82 * sizeof(uint8_t)) = 90 bytes per Vector
# 90 * 60 = 5400 bytes of data per RowGroup
# 5475 bytes

# We 2x the actual result, to pay for the slower decompression speed
query I
SELECT message.split(': ')[2]::INTEGER FROM duckdb_logs
where
	message.starts_with('FinalAnalyze') and
	message.contains('test_roaring') and
	message.contains('VALIDITY') and
	message.contains('COMPRESSION_ROARING');
----
10944
