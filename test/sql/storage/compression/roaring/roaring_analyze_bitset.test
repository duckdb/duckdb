# name: test/sql/storage/compression/roaring/roaring_analyze_bitset.test
# description: Check the produced (final_)analyze result
# group: [roaring]

require block_size 262144

require noforcestorage

statement ok
SET storage_compatibility_version='v1.2.0'

load __TEST_DIR__/test_roaring.db

statement ok
set logging_level='info';

# 1 rowgroup
statement ok
set variable dataset_size = 122880;

statement ok
PRAGMA force_compression='uncompressed'

statement ok
set enable_logging=true;

statement ok
CREATE TABLE test_uncompressed AS SELECT
	case
		when i%3=0
			then 1337
		else null
	end
	FROM range(getvariable('dataset_size')) tbl(i);

statement ok
checkpoint

statement ok
set enable_logging=false;

query I
SELECT message.split(': ')[2]::INTEGER FROM duckdb_logs
where
	message.starts_with('FinalAnalyze') and
	message.contains('test_uncompressed') and
	message.contains('VALIDITY') and
	message.contains('COMPRESSION_UNCOMPRESSED');
----
15360

statement ok
PRAGMA force_compression='roaring'

statement ok
set enable_logging=true;

statement ok
CREATE TABLE test_roaring AS select * from test_uncompressed;

statement ok
checkpoint

statement ok
set enable_logging=false;

# For single row group
# 60 vectors with 7 or 8 runs of nulls per vector
# Total compressed bytes:
# 2 bits (is_inverted + is_run) = 2 bits per Vector
# 2 * 60 = 120 bits == 15 bytes of metadata per RowGroup
#
# 256 bytes bytes per Vector
# 256 * 60 = 15360 bytes of data per RowGroup
# 15375 bytes

# We 2x the actual result, to pay for the slower decompression speed
query I
SELECT message.split(': ')[2]::INTEGER FROM duckdb_logs
where
	message.starts_with('FinalAnalyze') and
	message.contains('test_roaring') and
	message.contains('VALIDITY') and
	message.contains('COMPRESSION_ROARING');
----
30872
