# name: test/sql/storage/parallel/memory_limit_batch_load_list.test_slow
# description: Test batch streaming to disk with different row group sizes
# group: [parallel]

require parquet

load __TEST_DIR__/memory_limit_batch_load_list.db

# in this test we load data of around 100M rows - uncompressed this will be 1.4GB~2GB (without/with NULLs)
# we do these operations with a low memory limit to verify the data is streamed to and from disk correctly
statement ok
SET memory_limit='300MB'

foreach row_group_size 5000 150000 1000000

statement ok
COPY (
	SELECT [i] AS l FROM range(10000000) tbl(i)
) TO '__TEST_DIR__/giant_row_groups.parquet' (
	ROW_GROUP_SIZE ${row_group_size}
)

statement ok
CREATE TABLE list AS FROM '__TEST_DIR__/giant_row_groups.parquet'

query IIIII
SELECT
	SUM(i),
	MIN(i),
	MAX(i),
	COUNT(i),
	COUNT(*)
FROM (
	SELECT UNNEST(l) AS i FROM list
)
----
49999995000000	0	9999999	10000000	10000000

query I
SELECT * FROM list LIMIT 5 OFFSET 99998
----
[99998]
[99999]
[100000]
[100001]
[100002]

statement ok
DROP TABLE list

# now with NULL values
statement ok
COPY (
	SELECT CASE WHEN i%2=0 THEN NULL ELSE [i] END AS l FROM range(10000000) tbl(i)
) TO '__TEST_DIR__/giant_row_groups_nulls.parquet' (
	ROW_GROUP_SIZE ${row_group_size}
)

statement ok
CREATE TABLE list AS FROM '__TEST_DIR__/giant_row_groups_nulls.parquet'

query IIIII
SELECT
	SUM(i),
	MIN(i),
	MAX(i),
	COUNT(i),
	COUNT(*)
FROM (
	SELECT UNNEST(l) AS i FROM list
)
----
25000000000000	1	9999999	5000000	5000000

query I
SELECT
	*
FROM list LIMIT 5 OFFSET 99998
----
NULL
[99999]
NULL
[100001]
NULL

statement ok
DROP TABLE list

endloop
