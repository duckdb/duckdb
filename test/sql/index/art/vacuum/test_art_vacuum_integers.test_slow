# name: test/sql/index/art/vacuum/test_art_vacuum_integers.test_slow
# description: Test checkpointing for vacuum operations with integers
# group: [vacuum]

statement ok
PRAGMA enable_verification

statement ok
CREATE FUNCTION mem_to_bytes(x) AS CASE
    WHEN CONTAINS(x, 'KB') THEN REPLACE(x, 'KB', '')::INT * 1000
    WHEN CONTAINS(x, 'MB') THEN REPLACE(x, 'MB', '')::INT * 1000 * 1000
    WHEN CONTAINS(x, 'GB') THEN REPLACE(x, 'GB', '')::INT * 1000 * 1000 * 1000
    WHEN CONTAINS(x, 'TB') THEN REPLACE(x, 'TB', '')::INT * 1000 * 1000 * 1000 * 1000
    WHEN x = '0 bytes' THEN 0
    ELSE x::INT END;

# store the memory usage of 1M integers in base table
# verify that the memory increases and drops again
# this is the setup phase of the memory tests in this file

statement ok
CREATE TABLE temp (i integer);

statement ok
CREATE TABLE empty AS
SELECT mem_to_bytes(memory_usage) AS usage FROM pragma_database_size();

statement ok
INSERT INTO temp SELECT * FROM range(1000000);

statement ok
CREATE TABLE base AS
SELECT mem_to_bytes(memory_usage) AS usage FROM pragma_database_size();

query I
SELECT base.usage > empty.usage
FROM base, empty;
----
true

statement ok
DROP TABLE temp;

statement ok
UPDATE empty SET usage = (SELECT mem_to_bytes(current.memory_usage) FROM pragma_database_size() AS current);

# create a table with an index, then restart the database
# due to serialization + lazy loading, the index size after the reload must be almost zero

statement ok
CREATE TABLE t (i integer);

statement ok
INSERT INTO t SELECT * FROM range(1000000);

statement ok
CREATE INDEX idx ON t(i);

query I
SELECT mem_to_bytes(current.memory_usage) < 4 * base.usage
FROM base, pragma_database_size() current;
----
1

# insert 250K values into every fourth leaf, partially deserializing the ART
# the size of the database also increases more significantly, as we now have duplicates in leaves,
# i.e., we no longer inline row IDs

statement ok
INSERT INTO t SELECT range * 4 FROM range(250000);

# store the current size of the DB
statement ok
CREATE TABLE db_size AS
SELECT mem_to_bytes(current.memory_usage) AS usage
FROM pragma_database_size() AS current;

# now perform one bulk deletion of half the values
# and then loop and perform some smaller deletions

statement ok
DELETE FROM t WHERE i > 500000;

# the previous bulk deletion causes a vacuum-operation. We delete excess_buffer_count in-memory buffers
# during a vacuum. We move their data to buffers that still have free space and that potentially
# are not yet deserialized, deserializing them. Therefore, our overall ART size decreases, but our in-memory
# ART size potentially increases, as we deserialize additional buffers

# we add some +10MB
query I
SELECT mem_to_bytes(current.memory_usage) < db_size.usage + 10000000
FROM db_size, pragma_database_size() current;
----
1

statement ok
UPDATE db_size SET usage = (SELECT mem_to_bytes(current.memory_usage) AS usage
FROM pragma_database_size() AS current);

loop threshold 0 10

statement ok
DELETE FROM t WHERE i < (${threshold} * 25000);

endloop

query I
SELECT mem_to_bytes(current.memory_usage) < db_size.usage
FROM db_size, pragma_database_size() current;
----
1

statement ok
UPDATE db_size SET usage = (SELECT mem_to_bytes(current.memory_usage) AS usage
FROM pragma_database_size() AS current);

statement ok
DELETE FROM t;

query I
SELECT mem_to_bytes(current.memory_usage) < db_size.usage
FROM db_size, pragma_database_size() current;
----
1

