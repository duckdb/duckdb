# name: test/sql/index/art/vacuum/test_art_vacuum_strings.test_slow
# description: Test checkpointing for vacuum operations with strings
# group: [vacuum]

statement ok
PRAGMA enable_verification

statement ok
CREATE FUNCTION mem_to_bytes(x) AS CASE
    WHEN CONTAINS(x, 'KB') THEN REPLACE(x, 'KB', '')::INT * 1000
    WHEN CONTAINS(x, 'MB') THEN REPLACE(x, 'MB', '')::INT * 1000 * 1000
    WHEN CONTAINS(x, 'GB') THEN REPLACE(x, 'GB', '')::INT * 1000 * 1000 * 1000
    WHEN CONTAINS(x, 'TB') THEN REPLACE(x, 'TB', '')::INT * 1000 * 1000 * 1000 * 1000
    WHEN x = '0 bytes' THEN 0
    ELSE x::INT END;

# store the memory usage of 100K strings in base table
# verify that the memory increases and drops again
# this is the setup phase of the memory tests in this file

statement ok
CREATE TABLE temp (i varchar);

statement ok
CREATE TABLE empty AS
SELECT mem_to_bytes(memory_usage) AS usage FROM pragma_database_size();

statement ok
INSERT INTO temp SELECT range || 'I am' || range || 'a long not' || range || 'inlined string' || range FROM range(100000) AS range;

statement ok
CREATE TABLE base AS
SELECT mem_to_bytes(memory_usage) AS usage FROM pragma_database_size();

query I
SELECT base.usage > empty.usage
FROM base, empty;
----
true

statement ok
DROP TABLE temp;

statement ok
UPDATE empty SET usage = (SELECT mem_to_bytes(current.memory_usage) FROM pragma_database_size() AS current);

# create a table with an index, then restart the database
# due to serialization + lazy loading, the index size after the reload must be almost zero

statement ok
CREATE TABLE t (i varchar);

statement ok
INSERT INTO t SELECT range || 'I am' || range || 'a long not' || range || 'inlined string' || range FROM range(100000) AS range;

statement ok
CREATE INDEX idx ON t(i);

query I
SELECT mem_to_bytes(current.memory_usage) > 2 * base.usage AND mem_to_bytes(current.memory_usage) < 3 * base.usage
FROM base, pragma_database_size() current;
----
1

# insert 100K values into every fourth leaf, deserializing a significant part of the ART

statement ok
INSERT INTO t SELECT (range * 4) || 'I am' || (range * 4) || 'a long not' || (range * 4) || 'inlined string' || (range * 4) FROM range(100000) AS range;

query I
SELECT mem_to_bytes(current.memory_usage) > 4 * base.usage AND mem_to_bytes(current.memory_usage) < 6 * base.usage
FROM base, pragma_database_size() current;
----
1

# store the current size of the DB
statement ok
CREATE TABLE db_size AS
SELECT mem_to_bytes(current.memory_usage) AS usage
FROM pragma_database_size() AS current;

# now perform one bulk deletion of half the values
# and then loop and perform some smaller deletions

statement ok
DELETE FROM t WHERE rowid > (SELECT AVG(rowid) FROM t);

# the previous bulk deletion causes a vacuum-operation. We delete excess_buffer_count in-memory buffers
# during a vacuum. We move their data to buffers that still have free space and that potentially
# are not yet deserialized, deserializing them. Therefore, our overall ART size decreases, but our in-memory
# ART size potentially increases, as we deserialize additional buffers

# we add some +10MB
query I
SELECT mem_to_bytes(current.memory_usage) < db_size.usage + 10000000
FROM db_size, pragma_database_size() current;
----
1

statement ok
UPDATE db_size SET usage = (SELECT mem_to_bytes(current.memory_usage) AS usage
FROM pragma_database_size() AS current);

loop threshold 0 4

statement ok
DELETE FROM t WHERE rowid > (SELECT AVG(rowid) FROM t);

endloop

query I
SELECT mem_to_bytes(current.memory_usage) < db_size.usage
FROM db_size, pragma_database_size() current;
----
1

statement ok
UPDATE db_size SET usage = (SELECT mem_to_bytes(current.memory_usage) AS usage
FROM pragma_database_size() AS current);

# only ~6250 values remaining (~4MB), and we are only slightly under 4MB after the vacuum (~3.6MB)
# which we then round up to 4MB in our mem_to_bytes macro
statement ok
DELETE FROM t;

query I
SELECT mem_to_bytes(current.memory_usage) <= db_size.usage
FROM db_size, pragma_database_size() current;
----
1

