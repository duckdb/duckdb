# name: benchmark/parquet/dictionary_read-short-1000000.benchmark
# description: Read dictionary-encoded data from Parquet, 1000000 unique long strings, 10% NULLs
# group: [parquet]

name Parquet Dictionary Read Benchmark
group parquet

load
set variable total_rows = 100000000;
set variable null_rows_factor = 0.1;
set variable unique_values = ${UNIQUE_COUNT};
copy (select * from (select '${PREFIX}' || r1.range::varchar v from range(0,getvariable('unique_values')) r1, range(0,((getvariable('total_rows') * (1-getvariable('null_rows_factor'))) // getvariable('unique_values'))::INTEGER) r2 union all select null from range((getvariable('total_rows') * getvariable('null_rows_factor'))::INTEGER) ) order by random()) to '${BENCHMARK_DIR}/dictionary_read.parquet' (dictionary_compression_ratio_threshold 0);

run
select count(v) from '${BENCHMARK_DIR}/dictionary_read.parquet';