# Bug Report: Aggressive Memory Allocation on Full Text Scan with `LIKE` Leads to OOM Crash

## 1. Summary

DuckDB's query executor can aggressively allocate memory when performing a `lower(CAST(...))` followed by a `LIKE` with a leading wildcard on a large `VARCHAR` column. This leads to an Out-of-Memory (OOM) crash (exit code 137) on systems where the database size significantly exceeds available RAM, even when using the memory-efficient CLI client. The out-of-core engine does not appear to spill intermediate string data effectively for this specific operation, causing the process to exceed physical memory limits.

## 2. Environment

*   **DuckDB Version:** 1.4.2 (as per `pip install` log)
*   **Client:** DuckDB Python Client & Native CLI
*   **Operating System:** Linux
*   **Hardware:** 48GB RAM
*   **Database Size:** ~60GB

## 3. Steps to Reproduce

1.  Create a large DuckDB database with a table containing a `VARCHAR` column with billions of rows.
2.  Execute the following query using the DuckDB CLI:
    ```sql
    SELECT large_text_column
    FROM large_table
    WHERE lower(CAST(large_text_column AS VARCHAR)) LIKE '%some_string%';
    ```
3.  Observe the process memory consumption.

In our test, this was the failing command on the `leak` table:
```bash
duckdb -readonly /path/to/comb.db -c "SELECT email FROM leak WHERE lower(CAST(email AS VARCHAR)) LIKE '%bachini@%';"
```
*Note: This query eventually succeeded with the CLI, but a slightly more complex version with an `OR` condition failed consistently, indicating it is at the edge of what the system can handle.*

The following command, which adds a second `LIKE` scan, reliably failed:
```bash
duckdb -readonly /path/to/comb.db -c "SELECT * FROM leak WHERE lower(CAST(email AS VARCHAR)) LIKE '%bachini@%' OR lower(CAST(password AS VARCHAR)) LIKE '%bachini@%';"
```

## 4. Observed vs. Expected Behavior

*   **Observed Behavior:** The `duckdb` process consumes memory rapidly until it exceeds the system's available RAM, at which point the OS OOM killer terminates it with exit code `137`.
*   **Expected Behavior:** The query should execute successfully without crashing, even if it is slow. The out-of-core engine should spill intermediate data or operator state to the temporary directory, keeping memory usage within the configured limits.

## 5. Technical Analysis & Codebase Hypothesis

The issue does not appear to be with the client, but rather with the memory accounting and spilling strategy for string-heavy, non-indexable query operations within the DuckDB engine itself.

1.  **Operator-Internal Memory Allocation:** The `BufferManager` and `BufferPool` are highly effective at managing and spilling *table data* (blocks from the `.duckdb` file). However, the memory required for the intermediate results of the `lower(CAST(...))` operation seems to be the primary issue. For each row, a new, lowercased string is generated. For a multi-billion row table, the memory for these transient strings can easily exceed system RAM.

2.  **Lack of Spilling for Intermediate Operator State:** It's hypothesized that this intermediate data is being allocated in a way that is not effectively tracked or managed by the `TemporaryMemoryManager` or spilled by the `BufferManager`. The memory is likely held within the operator's local state during the scan. While the `StandardBufferManager` has an `EvictBlocksOrThrow` mechanism, it seems the memory pressure from the operator's internal allocations for these transient strings is not triggering this mechanism in time or at all for this specific data.

3.  **Query Plan Memory Costing:** The query planner may be underestimating the memory cost of this operation. A full scan involving `lower()` on a `VARCHAR` column has a very high memory cost per row that is not proportional to the size of the raw data on disk. This could lead to a plan that does not proactively prepare for spilling.

4.  **Exacerbation with `OR`:** The failure with the `OR` condition suggests that the engine may be processing both `LIKE` scans concurrently or holding both sets of intermediate results, effectively doubling the memory pressure and pushing it over the OOM threshold.

In summary, the out-of-core mechanism appears to be bypassed or overwhelmed by the rapid, large-scale allocation of intermediate string data generated by the `lower()` and `LIKE` operations during a full table scan. The fix would likely involve better memory accounting for string functions within the query execution engine and integrating this accounting with the `TemporaryMemoryManager` to trigger spilling of this intermediate state when memory pressure is high.
