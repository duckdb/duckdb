diff --git a/Makefile b/Makefile
index 1387981010..7d0fff6408 100644
--- a/Makefile
+++ b/Makefile
@@ -509,8 +509,8 @@ generate-files:
 	$(PYTHON) scripts/generate_settings.py
 	$(PYTHON) scripts/generate_serialization.py
 	$(PYTHON) scripts/generate_storage_info.py
-	$(PYTHON) scripts/generate_metric_enums.py
 	$(PYTHON) scripts/generate_enum_util.py
+	$(PYTHON) scripts/generate_metric_enums.py
 	$(PYTHON) scripts/generate_builtin_types.py
 # Run the formatter again after (re)generating the files
 	$(MAKE) format-main
diff --git a/scripts/generate_metric_enums.py b/scripts/generate_metric_enums.py
index 7832f064c4..83cb4a9fbf 100644
--- a/scripts/generate_metric_enums.py
+++ b/scripts/generate_metric_enums.py
@@ -1,52 +1,404 @@
-from metrics.emit_enum_cpp import generate_metric_type_files
-from metrics.emit_profiling_utils_cpp import generate_profiling_utils
-from metrics.emit_tests import generate_test_files
-from metrics.inputs import load_metrics_json, retrieve_optimizers
-from metrics.model import build_all_metrics
-from metrics.paths import (
-    METRICS_JSON,
-    OPTIMIZER_HPP,
-    OUT_METRIC_HPP,
-    OUT_METRIC_CPP,
-    TEST_PROFILING_DIR,
-    OUT_PROFILING_HPP,
-    OUT_PROFILING_CPP,
-    path_from_duckdb,
-    format_file,
-)
+# Script that takes src/include/duckdb/common/enums/optimizer_type.hpp, extracts the optimizer types
+# and adds them to the metrics types.
+# Then it creates a new file src/include/duckdb/common/enums/metric_type.hpp with the new metrics types as enums.
+# and generates both test/sql/pragma/profiling/test_default_profiling_settings.test
+# and test/sql/pragma/profiling/test_custom_profiling_optimizer.test
+
+import re
+import os
+
+os.chdir(os.path.dirname(__file__))
+
+metrics_header_file = os.path.join("..", "src", "include", "duckdb", "common", "enums", "metric_type.hpp")
+metrics_cpp_file = os.path.join("..", "src", "common", "enums", "metric_type.cpp")
+optimizer_file = os.path.join("..", "src", "include", "duckdb", "common", "enums", "optimizer_type.hpp")
+
+metrics = [
+    "ATTACH_LOAD_STORAGE_LATENCY",
+    "ATTACH_REPLAY_WAL_LATENCY",
+    "BLOCKED_THREAD_TIME",
+    "CHECKPOINT_LATENCY",
+    "CPU_TIME",
+    "CUMULATIVE_CARDINALITY",
+    "CUMULATIVE_ROWS_SCANNED",
+    "EXTRA_INFO",
+    "LATENCY",
+    "OPERATOR_CARDINALITY",
+    "OPERATOR_NAME",
+    "OPERATOR_ROWS_SCANNED",
+    "OPERATOR_TIMING",
+    "OPERATOR_TYPE",
+    "QUERY_NAME",
+    "RESULT_SET_SIZE",
+    "ROWS_RETURNED",
+    "SYSTEM_PEAK_BUFFER_MEMORY",
+    "SYSTEM_PEAK_TEMP_DIR_SIZE",
+    "TOTAL_BYTES_READ",
+    "TOTAL_BYTES_WRITTEN",
+    "TOTAL_MEMORY_ALLOCATED",
+    "WAITING_TO_ATTACH_LATENCY",
+    "COMMIT_LOCAL_STORAGE_LATENCY",
+    "WRITE_TO_WAL_LATENCY",
+    "WAL_REPLAY_ENTRY_COUNT",
+]
 
-if __name__ == "__main__":
-    # load metrics from JSON
-    metrics_json = load_metrics_json(METRICS_JSON)
+phase_timing_metrics = [
+    "ALL_OPTIMIZERS",
+    "CUMULATIVE_OPTIMIZER_TIMING",
+    "PHYSICAL_PLANNER",
+    "PHYSICAL_PLANNER_COLUMN_BINDING",
+    "PHYSICAL_PLANNER_CREATE_PLAN",
+    "PHYSICAL_PLANNER_RESOLVE_TYPES",
+    "PLANNER",
+    "PLANNER_BINDING",
+]
 
-    optimizers = retrieve_optimizers(OPTIMIZER_HPP)
+query_global_metrics = [
+    "ATTACH_LOAD_STORAGE_LATENCY",
+    "ATTACH_REPLAY_WAL_LATENCY",
+    "BLOCKED_THREAD_TIME",
+    "CHECKPOINT_LATENCY",
+    "SYSTEM_PEAK_BUFFER_MEMORY",
+    "SYSTEM_PEAK_TEMP_DIR_SIZE",
+    "TOTAL_MEMORY_ALLOCATED",
+    "WAITING_TO_ATTACH_LATENCY",
+]
 
-    metric_index = build_all_metrics(metrics_json, optimizers)
+optimizer_types = []
 
-    print(f"Metric Information:")
-    print(f"  * Total Metrics: {len(metric_index.metrics_by_group['all'])}")
-    print(f"  * Default Metrics: {len(metric_index.metrics_by_group['default'])}")
-    print(f"  * Total Groups: {len(metric_index.group_names)}")
-    print(f"  * Metric Groups and Total Metrics per Group:")
-    for group in metric_index.group_names:
-        if group == "all" or group == "default":
+# Regular expression to match the enum values
+enum_pattern = r'\s*([A-Z_]+)\s*=\s*\d+,?|\s*([A-Z_]+),?'
+
+inside_enum = False
+
+# open the optimizer file and extract the optimizer types
+with open(optimizer_file, "r") as f:
+    for line in f:
+        line = line.strip()
+
+        if line.startswith("enum class OptimizerType"):
+            inside_enum = True
             continue
-        print(f"    * {group}: {len(metric_index.metrics_by_group[group])}")
-
-    print("\nGenerating files:")
-    # emit C++ files
-    generate_metric_type_files(OUT_METRIC_HPP, OUT_METRIC_CPP, metric_index, optimizers)
-    print(f"  * {path_from_duckdb(OUT_METRIC_HPP)}")
-    format_file(OUT_METRIC_HPP)
-    print(f"  * {path_from_duckdb(OUT_METRIC_CPP)}")
-    format_file(OUT_METRIC_CPP)
-
-    generate_profiling_utils(OUT_PROFILING_HPP, OUT_PROFILING_CPP, metric_index)
-    print(f"  * {path_from_duckdb(OUT_PROFILING_HPP)}")
-    format_file(OUT_PROFILING_HPP)
-    print(f"  * {path_from_duckdb(OUT_PROFILING_CPP)}")
-    format_file(OUT_PROFILING_CPP)
-
-    print("\nGenerating tests:")
-    # emit test files
-    generate_test_files(TEST_PROFILING_DIR, metric_index.metrics_by_group)
+
+        if inside_enum and line.startswith("};"):
+            break
+
+        if inside_enum:
+            match = re.match(enum_pattern, line)
+            if match:
+                optimizer_type = match[1] if match[1] else match[2]
+                if optimizer_type == "INVALID":
+                    continue
+                optimizer_types.append(optimizer_type)
+
+header = """//-------------------------------------------------------------------------
+//                         DuckDB
+//
+//
+// duckdb/common/enums/metrics_type.hpp
+// 
+// This file is automatically generated by scripts/generate_metric_enums.py
+// Do not edit this file manually, your changes will be overwritten
+//-------------------------------------------------------------------------\n
+"""
+
+typedefs = """struct MetricsTypeHashFunction {
+	uint64_t operator()(const MetricsType &index) const {
+		return std::hash<uint8_t>()(static_cast<uint8_t>(index));
+	}
+};
+
+typedef unordered_set<MetricsType, MetricsTypeHashFunction> profiler_settings_t;
+typedef unordered_map<MetricsType, Value, MetricsTypeHashFunction> profiler_metrics_t;
+
+"""
+
+get_optimizer_metric_fun = 'GetOptimizerMetrics()'
+get_phase_timing_metric_fun = 'GetPhaseTimingMetrics()'
+get_optimizer_metric_by_type_fun = 'GetOptimizerMetricByType(OptimizerType type)'
+get_optimizer_type_by_metric_fun = 'GetOptimizerTypeByMetric(MetricsType type)'
+is_optimizer_metric_fun = 'IsOptimizerMetric(MetricsType type)'
+is_phase_timing_metric_fun = 'IsPhaseTimingMetric(MetricsType type)'
+is_query_global_metric_fun = 'IsQueryGlobalMetric(MetricsType type)'
+
+metrics_class = 'MetricsUtils'
+
+# Write the metric type header file
+with open(metrics_header_file, "w") as f:
+    f.write(header)
+
+    f.write('#pragma once\n\n')
+    f.write('#include "duckdb/common/types/value.hpp"\n')
+    f.write('#include "duckdb/common/unordered_set.hpp"\n')
+    f.write('#include "duckdb/common/unordered_map.hpp"\n')
+    f.write('#include "duckdb/common/constants.hpp"\n')
+    f.write('#include "duckdb/common/enum_util.hpp"\n')
+    f.write('#include "duckdb/common/enums/optimizer_type.hpp"\n\n')
+
+    f.write("namespace duckdb {\n\n")
+
+    f.write("enum class MetricsType : uint8_t {\n")
+
+    for metric in metrics:
+        f.write(f"    {metric},\n")
+
+    for metric in phase_timing_metrics:
+        f.write(f"    {metric},\n")
+
+    for metric in optimizer_types:
+        f.write(f"    OPTIMIZER_{metric},\n")
+
+    f.write("};\n\n")
+
+    f.write(typedefs)
+
+    f.write('class MetricsUtils {\n')
+    f.write('public:\n')
+    f.write(f'    static profiler_settings_t {get_optimizer_metric_fun};\n')
+    f.write(f'    static profiler_settings_t {get_phase_timing_metric_fun};\n\n')
+    f.write(f'    static MetricsType {get_optimizer_metric_by_type_fun};\n')
+    f.write(f'    static OptimizerType {get_optimizer_type_by_metric_fun};\n\n')
+    f.write(f'    static bool {is_optimizer_metric_fun};\n')
+    f.write(f'    static bool {is_phase_timing_metric_fun};\n')
+    f.write(f'    static bool {is_query_global_metric_fun};\n')
+    f.write('};\n\n')
+
+    f.write("} // namespace duckdb\n")
+
+# Write the metric_type.cpp file
+with open(metrics_cpp_file, "w") as f:
+    f.write(header)
+
+    f.write('#include "duckdb/common/enums/metric_type.hpp"\n')
+    f.write("namespace duckdb {\n\n")
+
+    f.write(f'profiler_settings_t {metrics_class}::{get_optimizer_metric_fun} {{\n')
+    f.write(f"    return {{\n")
+    for metric in optimizer_types:
+        f.write(f"        MetricsType::OPTIMIZER_{metric},\n")
+    f.write("    };\n")
+    f.write("}\n\n")
+
+    f.write(f'profiler_settings_t {metrics_class}::{get_phase_timing_metric_fun} {{\n')
+    f.write(f"    return {{\n")
+    for metric in phase_timing_metrics:
+        f.write(f"        MetricsType::{metric},\n")
+    f.write("    };\n")
+    f.write("}\n\n")
+
+    f.write(f'MetricsType {metrics_class}::{get_optimizer_metric_by_type_fun} {{\n')
+    f.write('    switch(type) {\n')
+    for metric in optimizer_types:
+        f.write(f"        case OptimizerType::{metric}:\n")
+        f.write(f"            return MetricsType::OPTIMIZER_{metric};\n")
+    f.write('       default:\n')
+    f.write(
+        '            throw InternalException("OptimizerType %s cannot be converted to a MetricsType", '
+        'EnumUtil::ToString(type));\n'
+    )
+    f.write('    };\n')
+    f.write('}\n\n')
+
+    f.write(f'OptimizerType {metrics_class}::{get_optimizer_type_by_metric_fun} {{\n')
+    f.write('    switch(type) {\n')
+    for metric in optimizer_types:
+        f.write(f"        case MetricsType::OPTIMIZER_{metric}:\n")
+        f.write(f"            return OptimizerType::{metric};\n")
+    f.write('    default:\n')
+    f.write('            return OptimizerType::INVALID;\n')
+    f.write('    };\n')
+    f.write('}\n\n')
+
+    f.write(f'bool {metrics_class}::{is_optimizer_metric_fun} {{\n')
+    f.write('    switch(type) {\n')
+    for metric in optimizer_types:
+        f.write(f"        case MetricsType::OPTIMIZER_{metric}:\n")
+
+    f.write('            return true;\n')
+    f.write('        default:\n')
+    f.write('            return false;\n')
+    f.write('    };\n')
+    f.write('}\n\n')
+
+    f.write(f'bool {metrics_class}::{is_phase_timing_metric_fun} {{\n')
+    f.write('    switch(type) {\n')
+    for metric in phase_timing_metrics:
+        f.write(f"        case MetricsType::{metric}:\n")
+
+    f.write('            return true;\n')
+    f.write('        default:\n')
+    f.write('            return false;\n')
+    f.write('    };\n')
+    f.write('}\n\n')
+
+    f.write(f'bool {metrics_class}::{is_query_global_metric_fun} {{\n')
+    f.write('    switch(type) {\n')
+    for metric in query_global_metrics:
+        f.write(f"        case MetricsType::{metric}:\n")
+
+    f.write('            return true;\n')
+    f.write('        default:\n')
+    f.write('            return false;\n')
+    f.write('    };\n')
+    f.write('}\n\n')
+
+    f.write("} // namespace duckdb\n")
+
+# Generate the test files
+test_names = ["test_default_profiling_settings", "test_custom_profiling_optimizer"]
+
+test_descriptions = ["default", "custom optimizer"]
+
+test_files = [os.path.join("..", "test", "sql", "pragma", "profiling", f"{name}.test") for name in test_names]
+
+
+def write_statement(f, statement_type, statement):
+    f.write(f"statement {statement_type}\n")
+    f.write(statement + "\n\n")
+
+
+def write_query(f, options, query):
+    f.write(f"query {options}\n")
+    f.write(query + "\n")
+    f.write("----\n")
+
+
+def write_default_query(f):
+    query = "SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();"
+    write_statement(f, "ok", query)
+    write_statement(f, "ok", "PRAGMA disable_profiling;")
+
+
+def write_get_custom_profiling_settings(f):
+    query = """
+SELECT unnest(res) FROM (
+    SELECT current_setting('custom_profiling_settings') AS raw_setting,
+    raw_setting.trim('{}') AS setting,
+    string_split(setting, ', ') AS res
+) ORDER BY ALL;
+            """.strip()
+    write_query(f, "I", query)
+
+
+def write_custom_profiling_optimizer(f):
+    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"ALL_OPTIMIZERS\": \"true\"}';")
+
+    write_default_query(f)
+
+    query = """
+SELECT * FROM (
+    SELECT unnest(res) str FROM (
+        SELECT current_setting('custom_profiling_settings') as raw_setting,
+        raw_setting.trim('{}') AS setting,
+        string_split(setting, ', ') AS res
+    )
+) WHERE '"true"' NOT in str
+ORDER BY ALL \
+            """.strip()
+    write_query(f, "I", query)
+    f.write("\n")
+
+    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{}'")
+    write_default_query(f)
+
+    write_get_custom_profiling_settings(f)
+    f.write("(empty)\n\n")
+
+    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"OPTIMIZER_JOIN_ORDER\": \"true\"}'")
+    write_default_query(f)
+
+    write_get_custom_profiling_settings(f)
+    f.write("\"OPTIMIZER_JOIN_ORDER\": \"true\"\n\n")
+
+    write_statement(
+        f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
+    )
+
+    query = """
+SELECT
+    CASE WHEN optimizer_join_order > 0 THEN 'true'
+     ELSE 'false' END
+FROM metrics_output;
+            """.strip()
+    write_query(f, "I", query)
+    f.write("true\n\n")
+
+    write_statement(f, "ok", "SET disabled_optimizers = 'JOIN_ORDER';")
+    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"OPTIMIZER_JOIN_ORDER\": \"true\"}'")
+    write_default_query(f)
+
+    write_get_custom_profiling_settings(f)
+    f.write("(empty)\n\n")
+
+    write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"CUMULATIVE_OPTIMIZER_TIMING\": \"true\"}';")
+    write_default_query(f)
+
+    write_statement(
+        f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
+    )
+
+    query = """
+SELECT
+    CASE WHEN cumulative_optimizer_timing > 0 THEN 'true'
+    ELSE 'false' END
+FROM metrics_output;
+        """.strip()
+    write_query(f, "I", query)
+    f.write("true\n\n")
+
+    f.write("# All phase timings must be collected when using detailed profiling mode.\n\n")
+
+    write_statement(f, "ok", "RESET custom_profiling_settings;")
+    write_statement(f, "ok", "SET profiling_mode = 'detailed';")
+    write_default_query(f)
+
+    query = """
+SELECT * FROM (
+    SELECT unnest(res) str FROM (
+        SELECT current_setting('custom_profiling_settings') AS raw_setting,
+        raw_setting.trim('{}') AS setting,
+        string_split(setting, ', ') AS res
+    )
+)
+WHERE '"true"' NOT IN str
+ORDER BY ALL
+            """.strip()
+    write_query(f, "I", query)
+    f.write("\n")
+
+    write_statement(f, "ok", "RESET custom_profiling_settings;")
+    write_statement(f, "ok", "SET profiling_mode = 'standard';")
+
+
+# Create the test files
+for test_file, name, description in zip(test_files, test_names, test_descriptions):
+    with open(test_file, "w") as f:
+        display_name = test_file.replace("../", "")
+        f.write(f"# name: {display_name}\n")
+        f.write(f"# description: Test {description} profiling settings.\n")
+        f.write("# group: [profiling]\n\n")
+        f.write("# This file is automatically generated by scripts/generate_metric_enums.py\n")
+        f.write("# Do not edit this file manually, your changes will be overwritten\n\n")
+
+        f.write("require json\n\n")
+
+        write_statement(f, "ok", "PRAGMA enable_verification;")
+        write_statement(f, "ok", "PRAGMA enable_profiling = 'json';")
+        write_statement(f, "ok", "PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';")
+
+        if name == "test_custom_profiling_optimizer":
+            write_custom_profiling_optimizer(f)
+
+        write_default_query(f)
+
+        write_get_custom_profiling_settings(f)
+        metrics.sort()
+
+        for metric in metrics:
+            f.write(f'"{metric}": "true"\n')
+        f.write("\n")
+
+        write_statement(
+            f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
+        )
+        write_statement(f, "ok", "SELECT cpu_time, extra_info, rows_returned, latency FROM metrics_output;")
diff --git a/scripts/metrics/__init__.py b/scripts/metrics/__init__.py
deleted file mode 100644
index 8b13789179..0000000000
--- a/scripts/metrics/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-
diff --git a/scripts/metrics/emit_enum_cpp.py b/scripts/metrics/emit_enum_cpp.py
deleted file mode 100644
index 67d9764d57..0000000000
--- a/scripts/metrics/emit_enum_cpp.py
+++ /dev/null
@@ -1,234 +0,0 @@
-from __future__ import annotations
-
-from asyncore import file_wrapper
-from typing import Dict, List, Tuple
-from pathlib import Path
-
-from .inputs import _to_pascal_case
-from .model import MetricIndex
-from .writer import IndentedFileWriter, write_warning
-
-HPP_HEADER = """
-
-#pragma once
-
-#include "duckdb/common/types/value.hpp"
-#include "duckdb/common/unordered_set.hpp"
-#include "duckdb/common/constants.hpp"
-#include "duckdb/common/enums/optimizer_type.hpp"
-
-namespace duckdb {
-
-"""
-
-HPP_TYPEDEFS = """
-struct MetricTypeHashFunction {
-    uint64_t operator()(const MetricType &index) const {
-        return std::hash<uint8_t>()(static_cast<uint8_t>(index));
-    }
-};
-
-typedef unordered_set<MetricType, MetricTypeHashFunction> profiler_settings_t;
-typedef unordered_map<MetricType, Value, MetricTypeHashFunction> profiler_metrics_t;
-
-"""
-
-CPP_HEADER = """
-#include "duckdb/common/enums/metric_type.hpp"
-#include "duckdb/common/enum_util.hpp"
-
-namespace duckdb {
-
-"""
-
-
-def _setup_hpp(out_hpp: Path, f: IndentedFileWriter, metric_index: MetricIndex):
-    f.write_header("duckdb/common/enums/metric_type.hpp")
-    f.write(HPP_HEADER)
-
-    f.write("enum class MetricGroup : uint8_t {\n")
-
-    groups = metric_index.group_names + ["INVALID"]
-    for g in groups:
-        f.write_indented(1, f"{g.upper()},")
-    f.write("};\n\n")
-
-    count_per_type: Dict[str, int] = {}
-
-    f.write("enum class MetricType : uint8_t {\n")
-    previous_end = None
-    for g in metric_index.group_names:
-        if g == "all" or g == "default":
-            continue
-
-        g_name = g.upper()
-
-        start = "START_" + g_name
-        end = "END_" + g_name
-
-        metrics = metric_index.metrics_per_group(g)
-        count_per_type[g_name + "_METRIC_COUNT"] = len(metrics)
-
-        f.write_indented(1, f"// {g_name}")
-        if previous_end is None:
-            # First type starts at 0
-            f.write_indented(1, f"{start} = 0,")
-        else:
-            # Subsequent types start where previous ended
-            f.write_indented(1, f"{start},")
-
-        # First metric equals START
-        f.write_indented(1, f"{metrics[0]} = {start},")
-
-        # Middle metrics
-        for m in metrics[1:]:
-            f.write_indented(1, f"{m},")
-
-        # END equals last metric
-        f.write_indented(1, f"{end} = {metrics[-1]},")
-
-        previous_end = end
-
-    f.write("};\n")
-
-    f.write(
-        """
-inline MetricType &operator++(MetricType &metric) {
-	metric = static_cast<MetricType>(static_cast<uint8_t>(metric) + 1);
-	return metric;
-}
-
-inline MetricType operator++(MetricType &metric, int) {
-	const MetricType tmp = metric;
-	++metric;
-	return tmp;
-}
-"""
-    )
-
-    f.write(HPP_TYPEDEFS)
-    f.write('class MetricsUtils {\n')
-    f.write('public:\n')
-    for t in count_per_type:
-        f.write_indented(1, f"static constexpr const idx_t {t} = {count_per_type[t]};")
-    f.write('\n')
-    f.write('public:\n')
-
-
-def _generate_standard_functions(
-    group: str, hpp_f: IndentedFileWriter, cpp_f: IndentedFileWriter, metric_index: MetricIndex
-):
-    formatted = _to_pascal_case(group)
-    get_fn = f"Get{formatted}Metrics"
-
-    hpp_f.write('\n')
-    hpp_f.write_indented(1, f"// {formatted} metrics")
-    hpp_f.write_indented(1, f"static profiler_settings_t {get_fn}();")
-
-    metrics = metric_index.metrics_per_group(group) if group != "root_scope" else metric_index.root_scope_metrics()
-
-    cpp_f.write(f"profiler_settings_t MetricsUtils::{get_fn}() {{\n")
-
-    if group == "root_scope" or group == "default" or group == "all":
-        cpp_f.write_indented(1, "return {")
-        for m in metrics:
-            cpp_f.write_indented(2, f"MetricType::{m},")
-        cpp_f.write_indented(1, "};")
-    else:
-        cpp_f.write_indented(1, "profiler_settings_t result;")
-        cpp_f.write_indented(
-            1,
-            f"for (auto metric = MetricType::START_{group.upper()}; metric <= MetricType::END_{group.upper()}; metric++) {{",
-        )
-        cpp_f.write_indented(2, f"result.insert(metric);")
-        cpp_f.write_indented(1, "}")
-        cpp_f.write_indented(1, "return result;")
-    cpp_f.write('}\n\n')
-
-    if group == "all":
-        _generate_get_metric_by_group_function(hpp_f, cpp_f, metric_index)
-        return
-
-    check_fn = f"Is{formatted}Metric"
-    hpp_f.write_indented(1, f"static bool {check_fn}(MetricType type);")
-
-    cpp_f.write(f"bool MetricsUtils::{check_fn}(MetricType type) {{\n")
-    cpp_f.write_indented(1, "switch(type) {")
-    for m in metrics:
-        cpp_f.write_indented(1, f"case MetricType::{m}:")
-    cpp_f.write_indented(2, "return true;")
-    cpp_f.write_indented(1, "default:")
-    cpp_f.write_indented(2, "return false;")
-    cpp_f.write_indented(1, "}")
-    cpp_f.write("}\n\n")
-
-
-def _generate_custom_optimizer_functions(optimizers: List[str], hpp_f: IndentedFileWriter, cpp_f: IndentedFileWriter):
-    by_type = "GetOptimizerMetricByType(OptimizerType type)"
-    by_metric = "GetOptimizerTypeByMetric(MetricType type)"
-
-    hpp_f.write_indented(1, f"static MetricType {by_type};")
-    hpp_f.write_indented(1, f"static OptimizerType {by_metric};")
-
-    cpp_f.write(f"MetricType MetricsUtils::{by_type} {{\n")
-    cpp_f.write_indented(1, "switch(type) {")
-    for o in optimizers:
-        cpp_f.write_indented(1, f"case OptimizerType::{o}:")
-        cpp_f.write_indented(2, f"return MetricType::OPTIMIZER_{o};")
-    cpp_f.write_indented(1, "default:")
-    cpp_f.write_indented(
-        2, 'throw InternalException("OptimizerType %s cannot be converted to a MetricType", EnumUtil::ToString(type));'
-    )
-    cpp_f.write_indented(1, "}")
-    cpp_f.write('}\n\n')
-
-    cpp_f.write(f"OptimizerType MetricsUtils::{by_metric} {{\n")
-    cpp_f.write_indented(1, "switch(type) {")
-    for o in optimizers:
-        cpp_f.write_indented(1, f"case MetricType::OPTIMIZER_{o}:")
-        cpp_f.write_indented(2, f"return OptimizerType::{o};")
-    cpp_f.write_indented(1, "default:")
-    cpp_f.write_indented(2, "return OptimizerType::INVALID;")
-    cpp_f.write_indented(1, "}")
-    cpp_f.write('}\n\n')
-
-
-def _generate_get_metric_by_group_function(
-    hpp_f: IndentedFileWriter, cpp_f: IndentedFileWriter, metric_index: MetricIndex
-):
-    fn = "GetMetricsByGroupType(MetricGroup type)"
-    hpp_f.write_indented(1, f"static profiler_settings_t {fn};")
-
-    cpp_f.write(f"profiler_settings_t MetricsUtils::{fn} {{\n")
-    cpp_f.write_indented(1, "switch(type) {")
-    for group in metric_index.group_names:
-        formatted = group.upper()
-        cpp_f.write_indented(1, f"case MetricGroup::{formatted}:")
-        cpp_f.write_indented(2, "return Get" + _to_pascal_case(group) + "Metrics();")
-    cpp_f.write_indented(1, "default:")
-    cpp_f.write_indented(2, 'throw InternalException("The MetricGroup passed is invalid");')
-    cpp_f.write_indented(1, "}")
-    cpp_f.write('}\n')
-
-
-def generate_metric_type_files(
-    out_hpp: Path,
-    out_cpp: Path,
-    metric_index: MetricIndex,
-    optimizers: List[str],
-) -> None:
-    with IndentedFileWriter(out_hpp) as hpp_f, IndentedFileWriter(out_cpp) as cpp_f:
-        _setup_hpp(out_hpp, hpp_f, metric_index)
-        cpp_f.write(write_warning())
-        cpp_f.write(CPP_HEADER)
-
-        for group in metric_index.metrics_by_group:
-            _generate_standard_functions(group, hpp_f, cpp_f, metric_index)
-            if group == "optimizer":
-                _generate_custom_optimizer_functions(optimizers, hpp_f, cpp_f)
-
-        _generate_standard_functions("root_scope", hpp_f, cpp_f, metric_index)
-
-        hpp_f.write("};\n")
-        hpp_f.write("} // namespace duckdb\n")
-        cpp_f.write("}\n")
diff --git a/scripts/metrics/emit_profiling_utils_cpp.py b/scripts/metrics/emit_profiling_utils_cpp.py
deleted file mode 100644
index 6838a59f17..0000000000
--- a/scripts/metrics/emit_profiling_utils_cpp.py
+++ /dev/null
@@ -1,250 +0,0 @@
-from collections import namedtuple
-from dataclasses import dataclass
-from pathlib import Path
-from typing import Dict, Optional, Callable
-
-from .inputs import retrieve_template, START_OF_FILE, INSERT_CODE_HERE
-from .model import MetricIndex
-from .paths import PROFILING_HPP_TEMPLATE, PROFILING_CPP_TEMPLATE
-from .writer import IndentedFileWriter, write_warning
-
-HPP_HEADER = """#pragma once
-
-#include "duckdb/common/enums/metric_type.hpp"
-#include "duckdb/main/query_profiler.hpp"
-#include "duckdb/main/profiling_node.hpp"
-
-namespace duckdb_yyjson {
-struct yyjson_mut_doc;
-struct yyjson_mut_val;
-} // namespace duckdb_yyjson
-
-namespace duckdb {
-
-"""
-
-CPP_HEADER = """
-#include "duckdb/main/profiling_utils.hpp"
-#include "duckdb/common/enum_util.hpp"
-#include "duckdb/main/profiling_node.hpp"
-#include "duckdb/main/query_profiler.hpp"
-
-#include "yyjson.hpp"
-
-using namespace duckdb_yyjson; // NOLINT
-
-namespace duckdb {"""
-
-
-def _default_case_logic(t: str) -> Optional[str]:
-    val = "Value::"
-    if t == "Value::MAP":
-        val += "MAP(InsertionOrderPreservingMap<string>())"
-    else:
-        val += "CreateValue"
-        if t == "string":
-            val += "(\"\")"
-        elif t == "double":
-            val += "(0.0)"
-        elif t == "uint64":
-            val += "<uint64_t>(0)"
-        elif t == "uint8":
-            val += "<uint8_t>(0)"
-
-    return f"metrics[type] = {val};"
-
-
-def _metric_to_json_case_logic(t: str) -> Optional[str]:
-    if t == "map":
-        return None
-    elif t == "string":
-        return "yyjson_mut_obj_add_strcpy(doc, dest, key_ptr, metrics[type].GetValue<string>().c_str());"
-    elif t == "double":
-        return "yyjson_mut_obj_add_real(doc, dest, key_ptr, metrics[type].GetValue<double>());"
-    elif t == "uint64":
-        return "yyjson_mut_obj_add_uint(doc, dest, key_ptr, metrics[type].GetValue<uint64_t>());"
-    elif t == "uint8":
-        return "yyjson_mut_obj_add_strcpy(doc, dest, key_ptr, OperatorToString(metrics[type]).c_str());"
-    return None
-
-
-def _write_function(
-    cpp_f: IndentedFileWriter,
-    types: Dict[str, list[str]],
-    class_name: str,
-    function_name: str,
-    case_logic: Callable[[str], Optional[str]],
-) -> None:
-    # set metric to default
-    cpp_f.write_indented(0, f"void {class_name}::{function_name} {{")
-    cpp_f.write_indented(1, "switch(type) {")
-    for t in types:
-        for m in types[t]:
-            cpp_f.write_indented(1, f"case MetricType::{m}:")
-
-        res = case_logic(t)
-        if res is not None:
-            cpp_f.write_indented(2, res)
-        cpp_f.write_indented(2, "break;")
-
-    cpp_f.write_indented(1, "default:")
-    cpp_f.write_indented(2, "throw InternalException(\"Unknown metric type %s\", EnumUtil::ToString(type));")
-    cpp_f.write_indented(1, "}")
-    cpp_f.write_indented(0, "}\n")
-
-
-def _generate_collection_methods(
-    cpp_f: IndentedFileWriter, class_name: str, function_name: str, metric_index: MetricIndex
-) -> None:
-    cpp_f.write_indented(0, f"void {class_name}::{function_name} {{")
-    cpp_f.write_indented(1, "switch(type) {")
-    for c in metric_index.collection_index():
-        for m in metric_index.metrics_per_collection(c):
-            cpp_f.write_indented(1, f"case MetricType::{m}:")
-            if c == "timer":
-                cpp_f.write_indented(2, f"metric = Value::DOUBLE(query_metrics.{m.lower()});")
-            elif c == "child":
-                cpp_f.write_indented(2, f"metric = child_info.metrics[MetricType::{metric_index.metric_child(m)}];")
-            elif c == "cumulative_operators":
-                cpp_f.write_indented(2, f"metric = GetCumulativeOptimizers(node);")
-            elif c == "query_metric":
-                if metric_index.metric_type(m) == "uint64_t":
-                    cpp_f.write_indented(2, f"metric = Value::UBIGINT(query_metrics.{m.lower()});")
-                elif metric_index.metric_type(m) == "string":
-                    cpp_f.write_indented(2, f"metric = query_metrics.{m.lower()};")
-            elif c == "cumulative":
-                cpp_f.write_indented(
-                    2,
-                    f"GetCumulativeMetric<{metric_index.metric_type(m)}>(node, MetricType::{m}, MetricType::{metric_index.metric_child(m)});",
-                )
-            else:
-                raise Exception(f"Unknown collection type {c} or metric {m}")
-            cpp_f.write_indented(2, f"break;")
-
-    cpp_f.write_indented(1, "default:")
-    cpp_f.write_indented(2, "return;")
-    cpp_f.write_indented(1, "}")
-    cpp_f.write_indented(0, "}\n")
-
-
-def _write_query_metric_functions(
-    hpp_f: IndentedFileWriter, query_metric_types: list[tuple[str, str, str]], f_name: str, group: str, action: str
-) -> None:
-    hpp_f.write_indented(1, f"void {f_name} {{")
-    hpp_f.write_indented(2, "switch(type) {")
-    for m, t, d in query_metric_types:
-        if t == group:
-            hpp_f.write_indented(2, f"case MetricType::{m}:")
-            a = action
-            m_lower = m.lower()
-            if action == "GEN_FROM_METRIC":
-                a = f".store({m_lower}.load() + amount)"
-            hpp_f.write_indented(3, f"{m_lower}{a};")
-            hpp_f.write_indented(3, "break;")
-    hpp_f.write_indented(2, "default:")
-    hpp_f.write_indented(3, "return;")
-    hpp_f.write_indented(2, "};")
-    hpp_f.write_indented(1, "}\n")
-
-
-def _generate_query_metrics(hpp_f: IndentedFileWriter, metric_index: MetricIndex) -> None:
-    query_metric_types: list[tuple[str, str, str]] = []
-
-    # if the collection method is timer or query_metric then add to query_metrics
-    for c in metric_index.collection_index():
-        for m in metric_index.metrics_per_collection(c):
-            if c == "timer" or c == "query_metric":
-                t = metric_index.metric_type(m)
-                if t == "uint64_t":
-                    t = "atomic<idx_t>"
-                elif t == "double":
-                    t = "atomic<double>"
-                query_metric_types.append((m, t, metric_index.metric_description(m)))
-                if m == "LATENCY":
-                    query_metric_types.append(("LATENCY_TIMER", "unique_ptr<ActiveTimer>", ""))
-
-    # Move query_name to the front
-    query_name_items = [item for item in query_metric_types if item[0] == "QUERY_NAME"]
-    other_items = [item for item in query_metric_types if item[0] != "QUERY_NAME"]
-    query_metric_types = query_name_items + other_items
-
-    hpp_f.write_indented(0, "//! Top level query metrics.")
-    hpp_f.write_indented(0, "struct QueryMetrics {")
-
-    query_metric_constructor = "QueryMetrics() : "
-    for m, t, d in query_metric_types:
-        if t == "string":
-            query_metric_constructor += f"{m.lower()}(\"\"), "
-        elif t == "unique_ptr<ActiveTimer>":
-            continue
-        else:
-            query_metric_constructor += f"{m.lower()}(0), "
-    # remove trailing comma
-    query_metric_constructor = query_metric_constructor[:-2]
-    query_metric_constructor += " {};\n"
-    hpp_f.write_indented(1, query_metric_constructor)
-
-    hpp_f.write_indented(1, "//! Reset the query metrics")
-    hpp_f.write_indented(1, "void Reset() {")
-    for m, t, d in query_metric_types:
-        if t == "string":
-            hpp_f.write_indented(2, f"{m.lower()} = \"\";")
-        elif t == "unique_ptr<ActiveTimer>":
-            hpp_f.write_indented(2, f"{m.lower()} = nullptr;")
-        else:
-            hpp_f.write_indented(2, f"{m.lower()} = 0;")
-    hpp_f.write_indented(1, "}\n")
-
-    _write_query_metric_functions(
-        hpp_f,
-        query_metric_types,
-        "AddTiming(const MetricType type, const double amount)",
-        "atomic<double>",
-        "GEN_FROM_METRIC",
-    )
-    _write_query_metric_functions(
-        hpp_f,
-        query_metric_types,
-        "AddToCounter(const MetricType type, const idx_t amount)",
-        "atomic<idx_t>",
-        " += amount",
-    )
-
-    hpp_f.write_indented(1, "ProfilingInfo query_global_info;\n")
-
-    for m, t, d in query_metric_types:
-        if len(d) > 0:
-            hpp_f.write_indented(1, f"//! {d}")
-        hpp_f.write_indented(1, f"{t} {m.lower()};")
-
-    hpp_f.write_indented(0, "};")
-
-
-def generate_profiling_utils(
-    out_hpp: Path,
-    out_cpp: Path,
-    metric_index: MetricIndex,
-) -> None:
-    with IndentedFileWriter(out_hpp) as hpp_f, IndentedFileWriter(out_cpp) as cpp_f:
-
-        hpp_f.write_header("duckdb/main/profiling_utils.hpp")
-        hpp_f.write(retrieve_template(PROFILING_HPP_TEMPLATE, START_OF_FILE, INSERT_CODE_HERE))
-        _generate_query_metrics(hpp_f, metric_index)
-        hpp_f.write(retrieve_template(PROFILING_HPP_TEMPLATE, INSERT_CODE_HERE))
-
-        cpp_f.write(write_warning())
-        cpp_f.write(CPP_HEADER)
-        cpp_f.write(retrieve_template(PROFILING_CPP_TEMPLATE))
-
-        class_name = "ProfilingUtils"
-
-        default_function = "SetMetricToDefault(profiler_metrics_t &metrics, const MetricType &type)"
-        metric_to_json = "MetricToJson(duckdb_yyjson::yyjson_mut_doc *doc, duckdb_yyjson::yyjson_mut_val *dest, const char *key_ptr,  profiler_metrics_t &metrics, const MetricType &type)"
-        collect_metrics = "CollectMetrics(const MetricType &type, QueryMetrics &query_metrics, Value &metric, ProfilingNode &node, ProfilingInfo &child_info)"
-
-        _write_function(cpp_f, metric_index.types_index(), class_name, default_function, _default_case_logic)
-        _write_function(cpp_f, metric_index.types_index(), class_name, metric_to_json, _metric_to_json_case_logic)
-
-        _generate_collection_methods(cpp_f, class_name, collect_metrics, metric_index)
-
-        cpp_f.write_indented(0, "}")
diff --git a/scripts/metrics/emit_tests.py b/scripts/metrics/emit_tests.py
deleted file mode 100644
index c691bc5c08..0000000000
--- a/scripts/metrics/emit_tests.py
+++ /dev/null
@@ -1,246 +0,0 @@
-# scripts/metrics/emit_tests.py
-from __future__ import annotations
-
-from pathlib import Path
-from typing import Dict, List
-
-from .paths import REPO_ROOT, path_from_duckdb, format_file
-from .writer import IndentedFileWriter
-
-
-def _write_statement(f, statement_type, statement):
-    f.write(f"statement {statement_type}\n")
-    f.write(statement + "\n\n")
-
-
-def _write_query(f, options, query):
-    f.write(f"query {options}\n")
-    f.write(query + "\n")
-    f.write("----\n")
-
-
-def _write_default_query(f):
-    query = "SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();"
-    _write_statement(f, "ok", query)
-    _write_statement(f, "ok", "PRAGMA disable_profiling;")
-
-
-def _write_get_custom_profiling_settings(f):
-    query = """
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-""".strip()
-    _write_query(f, "I", query)
-
-
-def _write_custom_profiling_optimizer(f):
-    _write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"ALL_OPTIMIZERS\": \"true\"}';")
-
-    _write_default_query(f)
-
-    query = """
-SELECT * FROM (
-    SELECT unnest(res) str FROM (
-        SELECT current_setting('custom_profiling_settings') as raw_setting,
-        raw_setting.trim('{}') AS setting,
-        string_split(setting, ', ') AS res
-    )
-) WHERE '"true"' NOT in str
-ORDER BY ALL
-""".strip()
-    _write_query(f, "I", query)
-    f.write("\n")
-
-    _write_statement(f, "ok", "PRAGMA custom_profiling_settings='{}'")
-    _write_default_query(f)
-
-    _write_get_custom_profiling_settings(f)
-    f.write("(empty)\n\n")
-
-    _write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"OPTIMIZER_JOIN_ORDER\": \"true\"}'")
-    _write_default_query(f)
-
-    _write_get_custom_profiling_settings(f)
-    f.write("\"OPTIMIZER_JOIN_ORDER\": \"true\"\n\n")
-
-    _write_statement(
-        f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
-    )
-
-    query = """
-SELECT
-    CASE WHEN optimizer_join_order > 0 THEN 'true'
-     ELSE 'false' END
-FROM metrics_output;
-""".strip()
-    _write_query(f, "I", query)
-    f.write("true\n\n")
-
-    _write_statement(f, "ok", "SET disabled_optimizers = 'JOIN_ORDER';")
-    _write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"OPTIMIZER_JOIN_ORDER\": \"true\"}'")
-    _write_default_query(f)
-
-    _write_get_custom_profiling_settings(f)
-    f.write("(empty)\n\n")
-
-    _write_statement(f, "ok", "PRAGMA custom_profiling_settings='{\"CUMULATIVE_OPTIMIZER_TIMING\": \"true\"}';")
-    _write_default_query(f)
-
-    _write_statement(
-        f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
-    )
-
-    query = """
-SELECT
-    CASE WHEN cumulative_optimizer_timing > 0 THEN 'true'
-    ELSE 'false' END
-FROM metrics_output;
-""".strip()
-    _write_query(f, "I", query)
-    f.write("true\n\n")
-
-    f.write("# All phase timings must be collected when using detailed profiling mode.\n\n")
-
-    _write_statement(f, "ok", "RESET custom_profiling_settings;")
-    _write_statement(f, "ok", "SET profiling_mode = 'detailed';")
-    _write_default_query(f)
-
-    query = """
-SELECT * FROM (
-    SELECT unnest(res) str FROM (
-        SELECT current_setting('custom_profiling_settings') AS raw_setting,
-        raw_setting.trim('{}') AS setting,
-        string_split(setting, ', ') AS res
-    )
-)
-WHERE '"true"' NOT IN str
-ORDER BY ALL
-""".strip()
-    _write_query(f, "I", query)
-    f.write("\n")
-
-    _write_statement(f, "ok", "RESET custom_profiling_settings;")
-    _write_statement(f, "ok", "SET profiling_mode = 'standard';")
-
-
-def _generate_group_test(f, groups: list[str], all_metrics: Dict[str, List[str]]):
-    _write_statement(f, "ok", "PRAGMA enable_profiling = 'json';")
-    _write_statement(f, "ok", "PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';")
-
-    group_str = ", ".join(f'"{g.upper()}": "true"' for g in groups)
-    _write_statement(f, "ok", f"PRAGMA custom_profiling_settings='{{{group_str}}}';")
-
-    _write_default_query(f)
-    _write_get_custom_profiling_settings(f)
-
-    metrics: list[str] = []
-    for g in groups:
-        metrics += all_metrics[g]
-
-    if "all" not in groups and "ALL_OPTIMIZERS" in metrics:
-        metrics.extend(all_metrics.get("optimizer", []))
-
-    metrics = list(set(metrics))
-    metrics.sort()
-    for m in metrics:
-        f.write(f'"{m}": "true"\n')
-    f.write("\n")
-
-    _write_statement(
-        f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
-    )
-
-    cols: list[str] = []
-    operator_metrics = set(all_metrics.get("operator", []))
-    for m in metrics:
-        if m in operator_metrics and "operator" not in groups:
-            continue
-        cols.append(m)
-
-    select = "SELECT " + ",\n\t".join(cols)
-
-    if "operator" in groups:
-        select += "\nFROM (\n"
-        select += "\tSELECT unnest(children, max_depth := 2)\n"
-        select += "\tFROM metrics_output\n"
-        select += ")"
-    else:
-        select += "\nFROM metrics_output;"
-
-    _write_statement(f, "ok", select)
-
-
-def _generate_metric_group_test_file(out_path, all_metrics: Dict[str, List[str]]):
-    name = path_from_duckdb(out_path)
-    print(f"  * {name}")
-
-    top = f"""# name: {name}
-# description: Test default profiling settings using groups.
-# group: [profiling]
-
-# This file is automatically generated by scripts/generate_metric_enums.py
-# Do not edit this file manually, your changes will be overwritten
-
-require json
-
-"""
-    with IndentedFileWriter(out_path) as f:
-        f.write(top)
-        for group in all_metrics:
-            _generate_group_test(f, [group], all_metrics)
-        _generate_group_test(f, ["default", "file"], all_metrics)
-        _generate_group_test(f, ["file", "optimizer"], all_metrics)
-        _generate_group_test(f, ["phase_timing", "execution", "file"], all_metrics)
-    format_file(out_path)
-
-
-def _generate_profiling_setting_tests(out_dir: Path, all_metrics: Dict[str, List[str]]):
-    test_names = [
-        "test_default_profiling_settings",
-        "test_custom_profiling_optimizer_settings",
-        "test_all_profiling_settings",
-    ]
-    test_descriptions = ["default", "custom optimizer", "all settings"]
-    test_paths = [out_dir / f"{name}.test" for name in test_names]
-    metrics_group = ["default", "default", "all"]
-
-    for test_file, name, description, group in zip(test_paths, test_names, test_descriptions, metrics_group):
-        display_name = path_from_duckdb(test_file)
-        print(f"  * {display_name}")
-        with IndentedFileWriter(test_file) as f:
-            f.write(f"# name: {display_name}\n")
-            f.write(f"# description: Test {description} profiling settings.\n")
-            f.write("# group: [profiling]\n\n")
-            f.write("# This file is automatically generated by scripts/generate_metric_enums.py\n")
-            f.write("# Do not edit this file manually, your changes will be overwritten\n\n")
-            f.write("require json\n\n")
-
-            _write_statement(f, "ok", "PRAGMA enable_profiling = 'json';")
-            _write_statement(f, "ok", "PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';")
-
-            mode = "standard" if group == "default" else group
-            _write_statement(f, "ok", f"SET profiling_mode='{mode}';")
-
-            if name == "test_custom_profiling_optimizer_settings":
-                _write_custom_profiling_optimizer(f)
-
-            _write_default_query(f)
-            _write_get_custom_profiling_settings(f)
-
-            for m in all_metrics[group]:
-                f.write(f'"{m}": "true"\n')
-            f.write("\n")
-
-            _write_statement(
-                f, "ok", "CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';"
-            )
-            _write_statement(f, "ok", "SELECT cpu_time, extra_info, rows_returned, latency FROM metrics_output;")
-        format_file(test_file)
-
-
-def generate_test_files(out_dir: Path, all_metrics: Dict[str, List[str]]):
-    _generate_profiling_setting_tests(out_dir, all_metrics)
-    _generate_metric_group_test_file(out_dir / "test_custom_profiling_using_groups.test", all_metrics)
diff --git a/scripts/metrics/inputs.py b/scripts/metrics/inputs.py
deleted file mode 100644
index d3472325a6..0000000000
--- a/scripts/metrics/inputs.py
+++ /dev/null
@@ -1,71 +0,0 @@
-from __future__ import annotations
-import json
-import re
-from pathlib import Path
-
-IDENT_RE = re.compile(r"^[A-Z_][A-Z0-9_]*$")
-
-START_OF_FILE = "// DUCKDB_START_OF_FILE"
-INSERT_CODE_HERE = "// DUCKDB_INSERT_CODE_HERE"
-
-
-def load_metrics_json(path: Path) -> list[dict]:
-    if not path.exists():
-        raise FileNotFoundError(f"metric_type.json not found at {path}")
-    with path.open("r", encoding="utf-8") as f:
-        return json.load(f)
-
-
-def validate_identifier(name: str, group: str) -> None:
-    if not IDENT_RE.match(name):
-        raise ValueError(f"Invalid metric identifier: {name}, in group {group}")
-
-
-def _to_pascal_case(s: str) -> str:
-    return ''.join(word.capitalize() for word in s.split('_'))
-
-
-def retrieve_optimizers(optimizer_file: Path) -> list[str]:
-    if not optimizer_file.exists():
-        raise FileNotFoundError(f"optimizer_type.hpp not found at {optimizer_file}.")
-    enum_pattern = r"\s*([A-Z_]+)\s*=\s*\d+,?|\s*([A-Z_]+),?"
-    inside_enum = False
-    result: list[str] = []
-    with optimizer_file.open("r", encoding="utf-8") as f:
-        for line in f:
-            line = line.strip()
-            if line.startswith("enum class OptimizerType"):
-                inside_enum = True
-                continue
-
-            if inside_enum and line.startswith("};"):
-                break
-
-            if inside_enum:
-                m = re.match(enum_pattern, line)
-                if not m:
-                    continue
-                name = m[1] if m[1] else m[2]
-                if name == "INVALID":
-                    continue
-                result.append(name)
-
-    result.sort()
-    return result
-
-
-def retrieve_template(profiling_util_file: Path, start: str = START_OF_FILE, end: str = "EOF") -> str:
-    if not profiling_util_file.exists():
-        raise FileNotFoundError(f"file not found at {profiling_util_file}.")
-
-    with profiling_util_file.open("r", encoding="utf-8") as f:
-        result = f.read()
-
-    if start not in result:
-        print(f"Could not find the start of file mark: {start}")
-
-    if end != "EOF":
-        result = result[: result.find(end)]
-        return result.split(start)[1].split(end)[0]
-
-    return result.split(start)[1]
diff --git a/scripts/metrics/model.py b/scripts/metrics/model.py
deleted file mode 100644
index 942eda9635..0000000000
--- a/scripts/metrics/model.py
+++ /dev/null
@@ -1,147 +0,0 @@
-from __future__ import annotations
-from collections import OrderedDict, defaultdict
-from dataclasses import dataclass
-from typing import Dict, List, Tuple, Optional, Iterable
-
-from .inputs import validate_identifier
-
-
-@dataclass(frozen=True)
-class MetricDef:
-    name: str
-    group: str  # e.g., "file", "default", ...
-    type: str  # e.g., "double", "uint64", "string", "map", "uint8"
-    query_root: bool = False
-    is_default: bool = False
-    collection_method: Optional[str] = None
-    child: Optional[str] = None
-    description: str = None
-
-
-class MetricIndex:
-    def __init__(self, defs: Iterable[MetricDef], optimizers: List[str]):
-        self.defs: List[MetricDef] = list(defs)
-
-        # Build group → names (existing contract for emitters)
-        by_group: Dict[str, List[str]] = defaultdict(list)
-        for d in self.defs:
-            by_group[d.group].append(d.name)
-        for g in by_group:
-            by_group[g].sort()
-
-        # Add optimizer group (names only)
-        optimizer_names = [f"OPTIMIZER_{o}" for o in sorted(optimizers)]
-        by_group["optimizer"] = optimizer_names
-
-        # Add "all"
-        all_set = set().union(*by_group.values()) if by_group else set()
-        by_group["all"] = sorted(all_set)
-
-        # Add "default" based on "is_default" flag
-        self.is_default_metrics: List[str] = []
-        for d in self.defs:
-            if d.is_default:
-                self.is_default_metrics.append(d.name)
-        self.is_default_metrics.sort()
-        by_group["default"] = self.is_default_metrics
-
-        # Deterministic order of groups
-        self.metrics_by_group: Dict[str, List[str]] = OrderedDict(sorted(by_group.items()))
-
-        # List of group names from metrics_by_group
-        self.group_names: List[str] = sorted(list(self.metrics_by_group.keys()))
-
-        # Root scope list
-        self.root_scope: List[str] = sorted({d.name for d in self.defs if d.query_root})
-
-        # Type → names (for profiling utils)
-        type_map: Dict[str, List[str]] = defaultdict(list)
-        for d in self.defs:
-            t = d.type if d.name != "OPERATOR_TYPE" else "uint8"  # preserve your special-case
-            type_map[t].append(d.name)
-        for t in type_map:
-            type_map[t].sort()
-        self.type_to_names: Dict[str, List[str]] = dict(type_map)
-
-        # Collection method → names (only for those that have it)
-        coll_map: Dict[str, List[str]] = defaultdict(list)
-        for d in self.defs:
-            if d.collection_method:
-                coll_map[d.collection_method].append(d.name)
-        for c in coll_map:
-            coll_map[c].sort()
-        self.collection_to_names: Dict[str, List[str]] = dict(coll_map)
-
-        # Children mapping (name → child-key)
-        self.child_of: Dict[str, str] = {d.name: d.child for d in self.defs if d.child is not None}
-
-    def all_metrics(self) -> List[str]:
-        return self.metrics_by_group["all"]
-
-    def metrics_per_group(self, group: str) -> List[str]:
-        return self.metrics_by_group[group]
-
-    def root_scope_metrics(self) -> List[str]:
-        return self.root_scope
-
-    def types_index(self) -> Dict[str, List[str]]:
-        return self.type_to_names
-
-    def collection_index(self) -> Dict[str, List[str]]:
-        return self.collection_to_names
-
-    def metrics_per_collection(self, collection: str) -> List[str]:
-        return self.collection_to_names[collection]
-
-    def child_index(self) -> Dict[str, str]:
-        return self.child_of
-
-    def metric_type(self, metric: str) -> str:
-        for d in self.defs:
-            if d.name == metric:
-                if d.type == "uint8":
-                    return "uint8_t"
-                elif d.type == "uint64":
-                    return "uint64_t"
-                return d.type
-        raise Exception(f"Unknown metric: {metric}")
-
-    def metric_child(self, metric: str) -> Optional[str]:
-        for d in self.defs:
-            if d.name == metric:
-                return d.child
-        return None
-
-    def metric_description(self, metric: str) -> Optional[str]:
-        for d in self.defs:
-            if d.name == metric:
-                return d.description
-        return None
-
-
-def build_all_metrics(metrics_json: list[dict], optimizers: list[str]) -> MetricIndex:
-    defs: list[MetricDef] = []
-    for group in metrics_json:
-        gname = group.get("group")
-        for metric in group.get("metrics", []):
-            name = metric["name"]
-            validate_identifier(name, gname)
-            mtype = metric.get("type", "double")
-            is_default = metric.get("is_default", False)
-            query_root = "query_root" in metric
-            collection_method = metric.get("collection_method")
-            child = metric.get("child")
-            description = metric.get("description", "")
-            defs.append(
-                MetricDef(
-                    name=name,
-                    group=gname,
-                    type=mtype if name != "OPERATOR_TYPE" else "uint8",
-                    is_default=is_default,
-                    query_root=query_root,
-                    collection_method=collection_method,
-                    child=child,
-                    description=description,
-                )
-            )
-    return MetricIndex(defs, optimizers)
diff --git a/scripts/metrics/paths.py b/scripts/metrics/paths.py
deleted file mode 100644
index 686accd59e..0000000000
--- a/scripts/metrics/paths.py
+++ /dev/null
@@ -1,44 +0,0 @@
-import os
-import subprocess
-from pathlib import Path
-
-# Repository root inferred relative to this file
-REPO_ROOT = Path(__file__).resolve().parents[2]
-
-# Top-level source directories
-SRC_DIR = REPO_ROOT / "src"
-INCLUDE_ROOT = SRC_DIR / "include" / "duckdb"
-
-# Subdirectories we target
-COMMON_ENUMS_DIR = SRC_DIR / "common" / "enums"
-INCLUDE_ENUMS_DIR = INCLUDE_ROOT / "common" / "enums"
-INCLUDE_MAIN_DIR = INCLUDE_ROOT / "main"
-SRC_MAIN_DIR = SRC_DIR / "main"
-
-# Tests output directory
-TEST_PROFILING_DIR = REPO_ROOT / "test" / "sql" / "pragma" / "profiling"
-
-# Inputs
-METRICS_JSON = COMMON_ENUMS_DIR / "metric_type.json"
-OPTIMIZER_HPP = INCLUDE_ENUMS_DIR / "optimizer_type.hpp"
-PROFILING_HPP_TEMPLATE = INCLUDE_MAIN_DIR / "profiling_utils.hpp.template"
-PROFILING_CPP_TEMPLATE = SRC_MAIN_DIR / "profiling_utils.cpp.template"
-
-# Outputs
-OUT_METRIC_HPP = INCLUDE_ENUMS_DIR / "metric_type.hpp"
-OUT_METRIC_CPP = COMMON_ENUMS_DIR / "metric_type.cpp"
-OUT_PROFILING_HPP = INCLUDE_MAIN_DIR / "profiling_utils.hpp"
-OUT_PROFILING_CPP = SRC_MAIN_DIR / "profiling_utils.cpp"
-
-# Format script
-FORMAT_SCRIPT = REPO_ROOT / "scripts" / "format.py"
-
-
-def path_from_duckdb(path: Path):
-    return str(path).split('duckdb/', 1)[1]
-
-
-def format_file(path: Path):
-    print("    └─ Formatting...", end='', flush=True)
-    subprocess.run(["python3", FORMAT_SCRIPT, OUT_METRIC_HPP, "--fix", "--noconfirm"], stdout=subprocess.DEVNULL)
-    print("\r    └─ Formatted ✓  ")
diff --git a/scripts/metrics/writer.py b/scripts/metrics/writer.py
deleted file mode 100644
index 793de8e599..0000000000
--- a/scripts/metrics/writer.py
+++ /dev/null
@@ -1,45 +0,0 @@
-from pathlib import Path
-
-
-def write_warning():
-    return f'''// This file is automatically generated by scripts/generate_metric_enums.py
-// Do not edit this file manually, your changes will be overwritten
-'''
-
-
-class IndentedFileWriter:
-    """Wrapper around a file object that adds write_indented method."""
-
-    def __init__(self, file_path, read_only=False):
-        mode = 'r' if read_only else 'w'
-        self.file = open(file_path, mode, encoding='utf-8', newline='\n')
-
-    def write_indented(self, indent_level, text):
-        """Write text to file with the specified indentation level."""
-        indent = '\t' * indent_level
-        self.file.write(f"{indent}{text}\n")
-
-    def write(self, text):
-        """Delegate write to the underlying file object, add a new line at the end."""
-        self.file.write(text)
-
-    def write_header(self, file):
-        self.file.write(
-            f'''//===----------------------------------------------------------------------===//
-//
-//                         DuckDB
-//
-// {file}
-//
-{write_warning()}//===----------------------------------------------------------------------===//'''
-        )
-
-    def close(self):
-        """Delegate close to the underlying file object."""
-        self.file.close()
-
-    def __enter__(self):
-        return self
-
-    def __exit__(self, exc_type, exc_value, traceback):
-        self.close()
diff --git a/src/common/enum_util.cpp b/src/common/enum_util.cpp
index fb74659f5a..73fe8bce37 100644
--- a/src/common/enum_util.cpp
+++ b/src/common/enum_util.cpp
@@ -95,6 +95,7 @@
 #include "duckdb/common/types/row/tuple_data_states.hpp"
 #include "duckdb/common/types/timestamp.hpp"
 #include "duckdb/common/types/variant.hpp"
+#include "duckdb/common/types/variant_value.hpp"
 #include "duckdb/common/types/vector.hpp"
 #include "duckdb/common/types/vector_buffer.hpp"
 #include "duckdb/execution/index/art/art.hpp"
@@ -2859,110 +2860,86 @@ MetaPipelineType EnumUtil::FromString<MetaPipelineType>(const char *value) {
 	return static_cast<MetaPipelineType>(StringUtil::StringToEnum(GetMetaPipelineTypeValues(), 2, "MetaPipelineType", value));
 }
 
-const StringUtil::EnumStringLiteral *GetMetricGroupValues() {
-	static constexpr StringUtil::EnumStringLiteral values[] {
-		{ static_cast<uint32_t>(MetricGroup::ALL), "ALL" },
-		{ static_cast<uint32_t>(MetricGroup::CORE), "CORE" },
-		{ static_cast<uint32_t>(MetricGroup::DEFAULT), "DEFAULT" },
-		{ static_cast<uint32_t>(MetricGroup::EXECUTION), "EXECUTION" },
-		{ static_cast<uint32_t>(MetricGroup::FILE), "FILE" },
-		{ static_cast<uint32_t>(MetricGroup::OPERATOR), "OPERATOR" },
-		{ static_cast<uint32_t>(MetricGroup::OPTIMIZER), "OPTIMIZER" },
-		{ static_cast<uint32_t>(MetricGroup::PHASE_TIMING), "PHASE_TIMING" },
-		{ static_cast<uint32_t>(MetricGroup::INVALID), "INVALID" }
-	};
-	return values;
-}
-
-template<>
-const char* EnumUtil::ToChars<MetricGroup>(MetricGroup value) {
-	return StringUtil::EnumToString(GetMetricGroupValues(), 9, "MetricGroup", static_cast<uint32_t>(value));
-}
-
-template<>
-MetricGroup EnumUtil::FromString<MetricGroup>(const char *value) {
-	return static_cast<MetricGroup>(StringUtil::StringToEnum(GetMetricGroupValues(), 9, "MetricGroup", value));
-}
-
-const StringUtil::EnumStringLiteral *GetMetricTypeValues() {
-	static constexpr StringUtil::EnumStringLiteral values[] {
-		{ static_cast<uint32_t>(MetricType::ALL_OPTIMIZERS), "ALL_OPTIMIZERS" },
-		{ static_cast<uint32_t>(MetricType::ATTACH_LOAD_STORAGE_LATENCY), "ATTACH_LOAD_STORAGE_LATENCY" },
-		{ static_cast<uint32_t>(MetricType::ATTACH_REPLAY_WAL_LATENCY), "ATTACH_REPLAY_WAL_LATENCY" },
-		{ static_cast<uint32_t>(MetricType::BLOCKED_THREAD_TIME), "BLOCKED_THREAD_TIME" },
-		{ static_cast<uint32_t>(MetricType::CHECKPOINT_LATENCY), "CHECKPOINT_LATENCY" },
-		{ static_cast<uint32_t>(MetricType::COMMIT_LOCAL_STORAGE_LATENCY), "COMMIT_LOCAL_STORAGE_LATENCY" },
-		{ static_cast<uint32_t>(MetricType::CPU_TIME), "CPU_TIME" },
-		{ static_cast<uint32_t>(MetricType::CUMULATIVE_CARDINALITY), "CUMULATIVE_CARDINALITY" },
-		{ static_cast<uint32_t>(MetricType::CUMULATIVE_OPTIMIZER_TIMING), "CUMULATIVE_OPTIMIZER_TIMING" },
-		{ static_cast<uint32_t>(MetricType::CUMULATIVE_ROWS_SCANNED), "CUMULATIVE_ROWS_SCANNED" },
-		{ static_cast<uint32_t>(MetricType::EXTRA_INFO), "EXTRA_INFO" },
-		{ static_cast<uint32_t>(MetricType::LATENCY), "LATENCY" },
-		{ static_cast<uint32_t>(MetricType::OPERATOR_CARDINALITY), "OPERATOR_CARDINALITY" },
-		{ static_cast<uint32_t>(MetricType::OPERATOR_NAME), "OPERATOR_NAME" },
-		{ static_cast<uint32_t>(MetricType::OPERATOR_ROWS_SCANNED), "OPERATOR_ROWS_SCANNED" },
-		{ static_cast<uint32_t>(MetricType::OPERATOR_TIMING), "OPERATOR_TIMING" },
-		{ static_cast<uint32_t>(MetricType::OPERATOR_TYPE), "OPERATOR_TYPE" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE), "OPTIMIZER_BUILD_SIDE_PROBE_SIDE" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_COLUMN_LIFETIME), "OPTIMIZER_COLUMN_LIFETIME" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_COMMON_AGGREGATE), "OPTIMIZER_COMMON_AGGREGATE" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_COMMON_SUBEXPRESSIONS), "OPTIMIZER_COMMON_SUBEXPRESSIONS" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_COMMON_SUBPLAN), "OPTIMIZER_COMMON_SUBPLAN" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_COMPRESSED_MATERIALIZATION), "OPTIMIZER_COMPRESSED_MATERIALIZATION" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_CTE_FILTER_PUSHER), "OPTIMIZER_CTE_FILTER_PUSHER" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_CTE_INLINING), "OPTIMIZER_CTE_INLINING" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_DELIMINATOR), "OPTIMIZER_DELIMINATOR" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_DUPLICATE_GROUPS), "OPTIMIZER_DUPLICATE_GROUPS" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_EMPTY_RESULT_PULLUP), "OPTIMIZER_EMPTY_RESULT_PULLUP" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_EXPRESSION_REWRITER), "OPTIMIZER_EXPRESSION_REWRITER" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_EXTENSION), "OPTIMIZER_EXTENSION" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_FILTER_PULLUP), "OPTIMIZER_FILTER_PULLUP" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_FILTER_PUSHDOWN), "OPTIMIZER_FILTER_PUSHDOWN" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_IN_CLAUSE), "OPTIMIZER_IN_CLAUSE" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_JOIN_ELIMINATION), "OPTIMIZER_JOIN_ELIMINATION" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_JOIN_FILTER_PUSHDOWN), "OPTIMIZER_JOIN_FILTER_PUSHDOWN" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_JOIN_ORDER), "OPTIMIZER_JOIN_ORDER" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_LATE_MATERIALIZATION), "OPTIMIZER_LATE_MATERIALIZATION" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_LIMIT_PUSHDOWN), "OPTIMIZER_LIMIT_PUSHDOWN" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_MATERIALIZED_CTE), "OPTIMIZER_MATERIALIZED_CTE" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_REGEX_RANGE), "OPTIMIZER_REGEX_RANGE" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_REORDER_FILTER), "OPTIMIZER_REORDER_FILTER" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_SAMPLING_PUSHDOWN), "OPTIMIZER_SAMPLING_PUSHDOWN" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_STATISTICS_PROPAGATION), "OPTIMIZER_STATISTICS_PROPAGATION" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_SUM_REWRITER), "OPTIMIZER_SUM_REWRITER" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_TOP_N), "OPTIMIZER_TOP_N" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION), "OPTIMIZER_TOP_N_WINDOW_ELIMINATION" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_UNNEST_REWRITER), "OPTIMIZER_UNNEST_REWRITER" },
-		{ static_cast<uint32_t>(MetricType::OPTIMIZER_UNUSED_COLUMNS), "OPTIMIZER_UNUSED_COLUMNS" },
-		{ static_cast<uint32_t>(MetricType::PHYSICAL_PLANNER), "PHYSICAL_PLANNER" },
-		{ static_cast<uint32_t>(MetricType::PHYSICAL_PLANNER_COLUMN_BINDING), "PHYSICAL_PLANNER_COLUMN_BINDING" },
-		{ static_cast<uint32_t>(MetricType::PHYSICAL_PLANNER_CREATE_PLAN), "PHYSICAL_PLANNER_CREATE_PLAN" },
-		{ static_cast<uint32_t>(MetricType::PHYSICAL_PLANNER_RESOLVE_TYPES), "PHYSICAL_PLANNER_RESOLVE_TYPES" },
-		{ static_cast<uint32_t>(MetricType::PLANNER), "PLANNER" },
-		{ static_cast<uint32_t>(MetricType::PLANNER_BINDING), "PLANNER_BINDING" },
-		{ static_cast<uint32_t>(MetricType::QUERY_NAME), "QUERY_NAME" },
-		{ static_cast<uint32_t>(MetricType::RESULT_SET_SIZE), "RESULT_SET_SIZE" },
-		{ static_cast<uint32_t>(MetricType::ROWS_RETURNED), "ROWS_RETURNED" },
-		{ static_cast<uint32_t>(MetricType::SYSTEM_PEAK_BUFFER_MEMORY), "SYSTEM_PEAK_BUFFER_MEMORY" },
-		{ static_cast<uint32_t>(MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE), "SYSTEM_PEAK_TEMP_DIR_SIZE" },
-		{ static_cast<uint32_t>(MetricType::TOTAL_BYTES_READ), "TOTAL_BYTES_READ" },
-		{ static_cast<uint32_t>(MetricType::TOTAL_BYTES_WRITTEN), "TOTAL_BYTES_WRITTEN" },
-		{ static_cast<uint32_t>(MetricType::TOTAL_MEMORY_ALLOCATED), "TOTAL_MEMORY_ALLOCATED" },
-		{ static_cast<uint32_t>(MetricType::WAITING_TO_ATTACH_LATENCY), "WAITING_TO_ATTACH_LATENCY" },
-		{ static_cast<uint32_t>(MetricType::WAL_REPLAY_ENTRY_COUNT), "WAL_REPLAY_ENTRY_COUNT" },
-		{ static_cast<uint32_t>(MetricType::WRITE_TO_WAL_LATENCY), "WRITE_TO_WAL_LATENCY" }
-	};
-	return values;
-}
-
-template<>
-const char* EnumUtil::ToChars<MetricType>(MetricType value) {
-	return StringUtil::EnumToString(GetMetricTypeValues(), 65, "MetricType", static_cast<uint32_t>(value));
-}
-
-template<>
-MetricType EnumUtil::FromString<MetricType>(const char *value) {
-	return static_cast<MetricType>(StringUtil::StringToEnum(GetMetricTypeValues(), 65, "MetricType", value));
+const StringUtil::EnumStringLiteral *GetMetricsTypeValues() {
+	static constexpr StringUtil::EnumStringLiteral values[] {
+		{ static_cast<uint32_t>(MetricsType::ATTACH_LOAD_STORAGE_LATENCY), "ATTACH_LOAD_STORAGE_LATENCY" },
+		{ static_cast<uint32_t>(MetricsType::ATTACH_REPLAY_WAL_LATENCY), "ATTACH_REPLAY_WAL_LATENCY" },
+		{ static_cast<uint32_t>(MetricsType::BLOCKED_THREAD_TIME), "BLOCKED_THREAD_TIME" },
+		{ static_cast<uint32_t>(MetricsType::CHECKPOINT_LATENCY), "CHECKPOINT_LATENCY" },
+		{ static_cast<uint32_t>(MetricsType::CPU_TIME), "CPU_TIME" },
+		{ static_cast<uint32_t>(MetricsType::CUMULATIVE_CARDINALITY), "CUMULATIVE_CARDINALITY" },
+		{ static_cast<uint32_t>(MetricsType::CUMULATIVE_ROWS_SCANNED), "CUMULATIVE_ROWS_SCANNED" },
+		{ static_cast<uint32_t>(MetricsType::EXTRA_INFO), "EXTRA_INFO" },
+		{ static_cast<uint32_t>(MetricsType::LATENCY), "LATENCY" },
+		{ static_cast<uint32_t>(MetricsType::OPERATOR_CARDINALITY), "OPERATOR_CARDINALITY" },
+		{ static_cast<uint32_t>(MetricsType::OPERATOR_NAME), "OPERATOR_NAME" },
+		{ static_cast<uint32_t>(MetricsType::OPERATOR_ROWS_SCANNED), "OPERATOR_ROWS_SCANNED" },
+		{ static_cast<uint32_t>(MetricsType::OPERATOR_TIMING), "OPERATOR_TIMING" },
+		{ static_cast<uint32_t>(MetricsType::OPERATOR_TYPE), "OPERATOR_TYPE" },
+		{ static_cast<uint32_t>(MetricsType::QUERY_NAME), "QUERY_NAME" },
+		{ static_cast<uint32_t>(MetricsType::RESULT_SET_SIZE), "RESULT_SET_SIZE" },
+		{ static_cast<uint32_t>(MetricsType::ROWS_RETURNED), "ROWS_RETURNED" },
+		{ static_cast<uint32_t>(MetricsType::SYSTEM_PEAK_BUFFER_MEMORY), "SYSTEM_PEAK_BUFFER_MEMORY" },
+		{ static_cast<uint32_t>(MetricsType::SYSTEM_PEAK_TEMP_DIR_SIZE), "SYSTEM_PEAK_TEMP_DIR_SIZE" },
+		{ static_cast<uint32_t>(MetricsType::TOTAL_BYTES_READ), "TOTAL_BYTES_READ" },
+		{ static_cast<uint32_t>(MetricsType::TOTAL_BYTES_WRITTEN), "TOTAL_BYTES_WRITTEN" },
+		{ static_cast<uint32_t>(MetricsType::TOTAL_MEMORY_ALLOCATED), "TOTAL_MEMORY_ALLOCATED" },
+		{ static_cast<uint32_t>(MetricsType::WAITING_TO_ATTACH_LATENCY), "WAITING_TO_ATTACH_LATENCY" },
+		{ static_cast<uint32_t>(MetricsType::COMMIT_LOCAL_STORAGE_LATENCY), "COMMIT_LOCAL_STORAGE_LATENCY" },
+		{ static_cast<uint32_t>(MetricsType::WRITE_TO_WAL_LATENCY), "WRITE_TO_WAL_LATENCY" },
+		{ static_cast<uint32_t>(MetricsType::WAL_REPLAY_ENTRY_COUNT), "WAL_REPLAY_ENTRY_COUNT" },
+		{ static_cast<uint32_t>(MetricsType::ALL_OPTIMIZERS), "ALL_OPTIMIZERS" },
+		{ static_cast<uint32_t>(MetricsType::CUMULATIVE_OPTIMIZER_TIMING), "CUMULATIVE_OPTIMIZER_TIMING" },
+		{ static_cast<uint32_t>(MetricsType::PHYSICAL_PLANNER), "PHYSICAL_PLANNER" },
+		{ static_cast<uint32_t>(MetricsType::PHYSICAL_PLANNER_COLUMN_BINDING), "PHYSICAL_PLANNER_COLUMN_BINDING" },
+		{ static_cast<uint32_t>(MetricsType::PHYSICAL_PLANNER_CREATE_PLAN), "PHYSICAL_PLANNER_CREATE_PLAN" },
+		{ static_cast<uint32_t>(MetricsType::PHYSICAL_PLANNER_RESOLVE_TYPES), "PHYSICAL_PLANNER_RESOLVE_TYPES" },
+		{ static_cast<uint32_t>(MetricsType::PLANNER), "PLANNER" },
+		{ static_cast<uint32_t>(MetricsType::PLANNER_BINDING), "PLANNER_BINDING" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_EXPRESSION_REWRITER), "OPTIMIZER_EXPRESSION_REWRITER" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_FILTER_PULLUP), "OPTIMIZER_FILTER_PULLUP" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_FILTER_PUSHDOWN), "OPTIMIZER_FILTER_PUSHDOWN" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_EMPTY_RESULT_PULLUP), "OPTIMIZER_EMPTY_RESULT_PULLUP" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_CTE_FILTER_PUSHER), "OPTIMIZER_CTE_FILTER_PUSHER" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_REGEX_RANGE), "OPTIMIZER_REGEX_RANGE" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_IN_CLAUSE), "OPTIMIZER_IN_CLAUSE" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_JOIN_ORDER), "OPTIMIZER_JOIN_ORDER" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_DELIMINATOR), "OPTIMIZER_DELIMINATOR" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_UNNEST_REWRITER), "OPTIMIZER_UNNEST_REWRITER" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_UNUSED_COLUMNS), "OPTIMIZER_UNUSED_COLUMNS" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_STATISTICS_PROPAGATION), "OPTIMIZER_STATISTICS_PROPAGATION" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_COMMON_SUBEXPRESSIONS), "OPTIMIZER_COMMON_SUBEXPRESSIONS" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_COMMON_AGGREGATE), "OPTIMIZER_COMMON_AGGREGATE" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_COLUMN_LIFETIME), "OPTIMIZER_COLUMN_LIFETIME" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE), "OPTIMIZER_BUILD_SIDE_PROBE_SIDE" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_LIMIT_PUSHDOWN), "OPTIMIZER_LIMIT_PUSHDOWN" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_ROW_GROUP_PRUNER), "OPTIMIZER_ROW_GROUP_PRUNER" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_TOP_N), "OPTIMIZER_TOP_N" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION), "OPTIMIZER_TOP_N_WINDOW_ELIMINATION" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_COMPRESSED_MATERIALIZATION), "OPTIMIZER_COMPRESSED_MATERIALIZATION" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_DUPLICATE_GROUPS), "OPTIMIZER_DUPLICATE_GROUPS" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_REORDER_FILTER), "OPTIMIZER_REORDER_FILTER" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_SAMPLING_PUSHDOWN), "OPTIMIZER_SAMPLING_PUSHDOWN" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_JOIN_FILTER_PUSHDOWN), "OPTIMIZER_JOIN_FILTER_PUSHDOWN" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_EXTENSION), "OPTIMIZER_EXTENSION" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_MATERIALIZED_CTE), "OPTIMIZER_MATERIALIZED_CTE" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_SUM_REWRITER), "OPTIMIZER_SUM_REWRITER" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_LATE_MATERIALIZATION), "OPTIMIZER_LATE_MATERIALIZATION" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_CTE_INLINING), "OPTIMIZER_CTE_INLINING" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_COMMON_SUBPLAN), "OPTIMIZER_COMMON_SUBPLAN" },
+		{ static_cast<uint32_t>(MetricsType::OPTIMIZER_JOIN_ELIMINATION), "OPTIMIZER_JOIN_ELIMINATION" }
+	};
+	return values;
+}
+
+template<>
+const char* EnumUtil::ToChars<MetricsType>(MetricsType value) {
+	return StringUtil::EnumToString(GetMetricsTypeValues(), 66, "MetricsType", static_cast<uint32_t>(value));
+}
+
+template<>
+MetricsType EnumUtil::FromString<MetricsType>(const char *value) {
+	return static_cast<MetricsType>(StringUtil::StringToEnum(GetMetricsTypeValues(), 66, "MetricsType", value));
 }
 
 const StringUtil::EnumStringLiteral *GetMultiFileColumnMappingModeValues() {
@@ -3184,6 +3161,7 @@ const StringUtil::EnumStringLiteral *GetOptimizerTypeValues() {
 		{ static_cast<uint32_t>(OptimizerType::COLUMN_LIFETIME), "COLUMN_LIFETIME" },
 		{ static_cast<uint32_t>(OptimizerType::BUILD_SIDE_PROBE_SIDE), "BUILD_SIDE_PROBE_SIDE" },
 		{ static_cast<uint32_t>(OptimizerType::LIMIT_PUSHDOWN), "LIMIT_PUSHDOWN" },
+		{ static_cast<uint32_t>(OptimizerType::ROW_GROUP_PRUNER), "ROW_GROUP_PRUNER" },
 		{ static_cast<uint32_t>(OptimizerType::TOP_N), "TOP_N" },
 		{ static_cast<uint32_t>(OptimizerType::TOP_N_WINDOW_ELIMINATION), "TOP_N_WINDOW_ELIMINATION" },
 		{ static_cast<uint32_t>(OptimizerType::COMPRESSED_MATERIALIZATION), "COMPRESSED_MATERIALIZATION" },
@@ -3204,12 +3182,12 @@ const StringUtil::EnumStringLiteral *GetOptimizerTypeValues() {
 
 template<>
 const char* EnumUtil::ToChars<OptimizerType>(OptimizerType value) {
-	return StringUtil::EnumToString(GetOptimizerTypeValues(), 32, "OptimizerType", static_cast<uint32_t>(value));
+	return StringUtil::EnumToString(GetOptimizerTypeValues(), 33, "OptimizerType", static_cast<uint32_t>(value));
 }
 
 template<>
 OptimizerType EnumUtil::FromString<OptimizerType>(const char *value) {
-	return static_cast<OptimizerType>(StringUtil::StringToEnum(GetOptimizerTypeValues(), 32, "OptimizerType", value));
+	return static_cast<OptimizerType>(StringUtil::StringToEnum(GetOptimizerTypeValues(), 33, "OptimizerType", value));
 }
 
 const StringUtil::EnumStringLiteral *GetOrderByNullTypeValues() {
@@ -4404,19 +4382,20 @@ const StringUtil::EnumStringLiteral *GetStatisticsTypeValues() {
 		{ static_cast<uint32_t>(StatisticsType::STRUCT_STATS), "STRUCT_STATS" },
 		{ static_cast<uint32_t>(StatisticsType::BASE_STATS), "BASE_STATS" },
 		{ static_cast<uint32_t>(StatisticsType::ARRAY_STATS), "ARRAY_STATS" },
-		{ static_cast<uint32_t>(StatisticsType::GEOMETRY_STATS), "GEOMETRY_STATS" }
+		{ static_cast<uint32_t>(StatisticsType::GEOMETRY_STATS), "GEOMETRY_STATS" },
+		{ static_cast<uint32_t>(StatisticsType::VARIANT_STATS), "VARIANT_STATS" }
 	};
 	return values;
 }
 
 template<>
 const char* EnumUtil::ToChars<StatisticsType>(StatisticsType value) {
-	return StringUtil::EnumToString(GetStatisticsTypeValues(), 7, "StatisticsType", static_cast<uint32_t>(value));
+	return StringUtil::EnumToString(GetStatisticsTypeValues(), 8, "StatisticsType", static_cast<uint32_t>(value));
 }
 
 template<>
 StatisticsType EnumUtil::FromString<StatisticsType>(const char *value) {
-	return static_cast<StatisticsType>(StringUtil::StringToEnum(GetStatisticsTypeValues(), 7, "StatisticsType", value));
+	return static_cast<StatisticsType>(StringUtil::StringToEnum(GetStatisticsTypeValues(), 8, "StatisticsType", value));
 }
 
 const StringUtil::EnumStringLiteral *GetStatsInfoValues() {
@@ -5006,6 +4985,26 @@ VariantLogicalType EnumUtil::FromString<VariantLogicalType>(const char *value) {
 	return static_cast<VariantLogicalType>(StringUtil::StringToEnum(GetVariantLogicalTypeValues(), 35, "VariantLogicalType", value));
 }
 
+const StringUtil::EnumStringLiteral *GetVariantValueTypeValues() {
+	static constexpr StringUtil::EnumStringLiteral values[] {
+		{ static_cast<uint32_t>(VariantValueType::PRIMITIVE), "PRIMITIVE" },
+		{ static_cast<uint32_t>(VariantValueType::OBJECT), "OBJECT" },
+		{ static_cast<uint32_t>(VariantValueType::ARRAY), "ARRAY" },
+		{ static_cast<uint32_t>(VariantValueType::MISSING), "MISSING" }
+	};
+	return values;
+}
+
+template<>
+const char* EnumUtil::ToChars<VariantValueType>(VariantValueType value) {
+	return StringUtil::EnumToString(GetVariantValueTypeValues(), 4, "VariantValueType", static_cast<uint32_t>(value));
+}
+
+template<>
+VariantValueType EnumUtil::FromString<VariantValueType>(const char *value) {
+	return static_cast<VariantValueType>(StringUtil::StringToEnum(GetVariantValueTypeValues(), 4, "VariantValueType", value));
+}
+
 const StringUtil::EnumStringLiteral *GetVectorAuxiliaryDataTypeValues() {
 	static constexpr StringUtil::EnumStringLiteral values[] {
 		{ static_cast<uint32_t>(VectorAuxiliaryDataType::ARROW_AUXILIARY), "ARROW_AUXILIARY" }
diff --git a/src/common/enums/metric_type.cpp b/src/common/enums/metric_type.cpp
index 066d2171e5..ff55124073 100644
--- a/src/common/enums/metric_type.cpp
+++ b/src/common/enums/metric_type.cpp
@@ -1,506 +1,278 @@
+//-------------------------------------------------------------------------
+//                         DuckDB
+//
+//
+// duckdb/common/enums/metrics_type.hpp
+// 
 // This file is automatically generated by scripts/generate_metric_enums.py
 // Do not edit this file manually, your changes will be overwritten
+//-------------------------------------------------------------------------
 
 #include "duckdb/common/enums/metric_type.hpp"
-#include "duckdb/common/enum_util.hpp"
-
 namespace duckdb {
 
-profiler_settings_t MetricsUtils::GetAllMetrics() {
-	return {
-		MetricType::ALL_OPTIMIZERS,
-		MetricType::ATTACH_LOAD_STORAGE_LATENCY,
-		MetricType::ATTACH_REPLAY_WAL_LATENCY,
-		MetricType::BLOCKED_THREAD_TIME,
-		MetricType::CHECKPOINT_LATENCY,
-		MetricType::COMMIT_LOCAL_STORAGE_LATENCY,
-		MetricType::CPU_TIME,
-		MetricType::CUMULATIVE_CARDINALITY,
-		MetricType::CUMULATIVE_OPTIMIZER_TIMING,
-		MetricType::CUMULATIVE_ROWS_SCANNED,
-		MetricType::EXTRA_INFO,
-		MetricType::LATENCY,
-		MetricType::OPERATOR_CARDINALITY,
-		MetricType::OPERATOR_NAME,
-		MetricType::OPERATOR_ROWS_SCANNED,
-		MetricType::OPERATOR_TIMING,
-		MetricType::OPERATOR_TYPE,
-		MetricType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE,
-		MetricType::OPTIMIZER_COLUMN_LIFETIME,
-		MetricType::OPTIMIZER_COMMON_AGGREGATE,
-		MetricType::OPTIMIZER_COMMON_SUBEXPRESSIONS,
-		MetricType::OPTIMIZER_COMMON_SUBPLAN,
-		MetricType::OPTIMIZER_COMPRESSED_MATERIALIZATION,
-		MetricType::OPTIMIZER_CTE_FILTER_PUSHER,
-		MetricType::OPTIMIZER_CTE_INLINING,
-		MetricType::OPTIMIZER_DELIMINATOR,
-		MetricType::OPTIMIZER_DUPLICATE_GROUPS,
-		MetricType::OPTIMIZER_EMPTY_RESULT_PULLUP,
-		MetricType::OPTIMIZER_EXPRESSION_REWRITER,
-		MetricType::OPTIMIZER_EXTENSION,
-		MetricType::OPTIMIZER_FILTER_PULLUP,
-		MetricType::OPTIMIZER_FILTER_PUSHDOWN,
-		MetricType::OPTIMIZER_IN_CLAUSE,
-		MetricType::OPTIMIZER_JOIN_ELIMINATION,
-		MetricType::OPTIMIZER_JOIN_FILTER_PUSHDOWN,
-		MetricType::OPTIMIZER_JOIN_ORDER,
-		MetricType::OPTIMIZER_LATE_MATERIALIZATION,
-		MetricType::OPTIMIZER_LIMIT_PUSHDOWN,
-		MetricType::OPTIMIZER_MATERIALIZED_CTE,
-		MetricType::OPTIMIZER_REGEX_RANGE,
-		MetricType::OPTIMIZER_REORDER_FILTER,
-		MetricType::OPTIMIZER_SAMPLING_PUSHDOWN,
-		MetricType::OPTIMIZER_STATISTICS_PROPAGATION,
-		MetricType::OPTIMIZER_SUM_REWRITER,
-		MetricType::OPTIMIZER_TOP_N,
-		MetricType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION,
-		MetricType::OPTIMIZER_UNNEST_REWRITER,
-		MetricType::OPTIMIZER_UNUSED_COLUMNS,
-		MetricType::PHYSICAL_PLANNER,
-		MetricType::PHYSICAL_PLANNER_COLUMN_BINDING,
-		MetricType::PHYSICAL_PLANNER_CREATE_PLAN,
-		MetricType::PHYSICAL_PLANNER_RESOLVE_TYPES,
-		MetricType::PLANNER,
-		MetricType::PLANNER_BINDING,
-		MetricType::QUERY_NAME,
-		MetricType::RESULT_SET_SIZE,
-		MetricType::ROWS_RETURNED,
-		MetricType::SYSTEM_PEAK_BUFFER_MEMORY,
-		MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE,
-		MetricType::TOTAL_BYTES_READ,
-		MetricType::TOTAL_BYTES_WRITTEN,
-		MetricType::TOTAL_MEMORY_ALLOCATED,
-		MetricType::WAITING_TO_ATTACH_LATENCY,
-		MetricType::WAL_REPLAY_ENTRY_COUNT,
-		MetricType::WRITE_TO_WAL_LATENCY,
-	};
-}
-
-profiler_settings_t MetricsUtils::GetMetricsByGroupType(MetricGroup type) {
-	switch(type) {
-	case MetricGroup::ALL:
-		return GetAllMetrics();
-	case MetricGroup::CORE:
-		return GetCoreMetrics();
-	case MetricGroup::DEFAULT:
-		return GetDefaultMetrics();
-	case MetricGroup::EXECUTION:
-		return GetExecutionMetrics();
-	case MetricGroup::FILE:
-		return GetFileMetrics();
-	case MetricGroup::OPERATOR:
-		return GetOperatorMetrics();
-	case MetricGroup::OPTIMIZER:
-		return GetOptimizerMetrics();
-	case MetricGroup::PHASE_TIMING:
-		return GetPhaseTimingMetrics();
-	default:
-		throw InternalException("The MetricGroup passed is invalid");
-	}
-}
-profiler_settings_t MetricsUtils::GetCoreMetrics() {
-	profiler_settings_t result;
-	for (auto metric = MetricType::START_CORE; metric <= MetricType::END_CORE; metric++) {
-		result.insert(metric);
-	}
-	return result;
-}
-
-bool MetricsUtils::IsCoreMetric(MetricType type) {
-	switch(type) {
-	case MetricType::CPU_TIME:
-	case MetricType::CUMULATIVE_CARDINALITY:
-	case MetricType::CUMULATIVE_ROWS_SCANNED:
-	case MetricType::EXTRA_INFO:
-	case MetricType::LATENCY:
-	case MetricType::QUERY_NAME:
-	case MetricType::RESULT_SET_SIZE:
-	case MetricType::ROWS_RETURNED:
-		return true;
-	default:
-		return false;
-	}
-}
-
-profiler_settings_t MetricsUtils::GetDefaultMetrics() {
-	return {
-		MetricType::ATTACH_LOAD_STORAGE_LATENCY,
-		MetricType::ATTACH_REPLAY_WAL_LATENCY,
-		MetricType::BLOCKED_THREAD_TIME,
-		MetricType::CHECKPOINT_LATENCY,
-		MetricType::COMMIT_LOCAL_STORAGE_LATENCY,
-		MetricType::CPU_TIME,
-		MetricType::CUMULATIVE_CARDINALITY,
-		MetricType::CUMULATIVE_ROWS_SCANNED,
-		MetricType::EXTRA_INFO,
-		MetricType::LATENCY,
-		MetricType::OPERATOR_CARDINALITY,
-		MetricType::OPERATOR_NAME,
-		MetricType::OPERATOR_ROWS_SCANNED,
-		MetricType::OPERATOR_TIMING,
-		MetricType::OPERATOR_TYPE,
-		MetricType::QUERY_NAME,
-		MetricType::RESULT_SET_SIZE,
-		MetricType::ROWS_RETURNED,
-		MetricType::SYSTEM_PEAK_BUFFER_MEMORY,
-		MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE,
-		MetricType::TOTAL_BYTES_READ,
-		MetricType::TOTAL_BYTES_WRITTEN,
-		MetricType::TOTAL_MEMORY_ALLOCATED,
-		MetricType::WAITING_TO_ATTACH_LATENCY,
-		MetricType::WAL_REPLAY_ENTRY_COUNT,
-		MetricType::WRITE_TO_WAL_LATENCY,
-	};
-}
-
-bool MetricsUtils::IsDefaultMetric(MetricType type) {
-	switch(type) {
-	case MetricType::ATTACH_LOAD_STORAGE_LATENCY:
-	case MetricType::ATTACH_REPLAY_WAL_LATENCY:
-	case MetricType::BLOCKED_THREAD_TIME:
-	case MetricType::CHECKPOINT_LATENCY:
-	case MetricType::COMMIT_LOCAL_STORAGE_LATENCY:
-	case MetricType::CPU_TIME:
-	case MetricType::CUMULATIVE_CARDINALITY:
-	case MetricType::CUMULATIVE_ROWS_SCANNED:
-	case MetricType::EXTRA_INFO:
-	case MetricType::LATENCY:
-	case MetricType::OPERATOR_CARDINALITY:
-	case MetricType::OPERATOR_NAME:
-	case MetricType::OPERATOR_ROWS_SCANNED:
-	case MetricType::OPERATOR_TIMING:
-	case MetricType::OPERATOR_TYPE:
-	case MetricType::QUERY_NAME:
-	case MetricType::RESULT_SET_SIZE:
-	case MetricType::ROWS_RETURNED:
-	case MetricType::SYSTEM_PEAK_BUFFER_MEMORY:
-	case MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE:
-	case MetricType::TOTAL_BYTES_READ:
-	case MetricType::TOTAL_BYTES_WRITTEN:
-	case MetricType::TOTAL_MEMORY_ALLOCATED:
-	case MetricType::WAITING_TO_ATTACH_LATENCY:
-	case MetricType::WAL_REPLAY_ENTRY_COUNT:
-	case MetricType::WRITE_TO_WAL_LATENCY:
-		return true;
-	default:
-		return false;
-	}
-}
-
-profiler_settings_t MetricsUtils::GetExecutionMetrics() {
-	profiler_settings_t result;
-	for (auto metric = MetricType::START_EXECUTION; metric <= MetricType::END_EXECUTION; metric++) {
-		result.insert(metric);
-	}
-	return result;
-}
-
-bool MetricsUtils::IsExecutionMetric(MetricType type) {
-	switch(type) {
-	case MetricType::BLOCKED_THREAD_TIME:
-	case MetricType::SYSTEM_PEAK_BUFFER_MEMORY:
-	case MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE:
-	case MetricType::TOTAL_MEMORY_ALLOCATED:
-		return true;
-	default:
-		return false;
-	}
-}
-
-profiler_settings_t MetricsUtils::GetFileMetrics() {
-	profiler_settings_t result;
-	for (auto metric = MetricType::START_FILE; metric <= MetricType::END_FILE; metric++) {
-		result.insert(metric);
-	}
-	return result;
-}
-
-bool MetricsUtils::IsFileMetric(MetricType type) {
-	switch(type) {
-	case MetricType::ATTACH_LOAD_STORAGE_LATENCY:
-	case MetricType::ATTACH_REPLAY_WAL_LATENCY:
-	case MetricType::CHECKPOINT_LATENCY:
-	case MetricType::COMMIT_LOCAL_STORAGE_LATENCY:
-	case MetricType::TOTAL_BYTES_READ:
-	case MetricType::TOTAL_BYTES_WRITTEN:
-	case MetricType::WAITING_TO_ATTACH_LATENCY:
-	case MetricType::WAL_REPLAY_ENTRY_COUNT:
-	case MetricType::WRITE_TO_WAL_LATENCY:
-		return true;
-	default:
-		return false;
-	}
-}
-
-profiler_settings_t MetricsUtils::GetOperatorMetrics() {
-	profiler_settings_t result;
-	for (auto metric = MetricType::START_OPERATOR; metric <= MetricType::END_OPERATOR; metric++) {
-		result.insert(metric);
-	}
-	return result;
-}
-
-bool MetricsUtils::IsOperatorMetric(MetricType type) {
-	switch(type) {
-	case MetricType::OPERATOR_CARDINALITY:
-	case MetricType::OPERATOR_NAME:
-	case MetricType::OPERATOR_ROWS_SCANNED:
-	case MetricType::OPERATOR_TIMING:
-	case MetricType::OPERATOR_TYPE:
-		return true;
-	default:
-		return false;
-	}
-}
-
 profiler_settings_t MetricsUtils::GetOptimizerMetrics() {
-	profiler_settings_t result;
-	for (auto metric = MetricType::START_OPTIMIZER; metric <= MetricType::END_OPTIMIZER; metric++) {
-		result.insert(metric);
-	}
-	return result;
-}
-
-bool MetricsUtils::IsOptimizerMetric(MetricType type) {
-	switch(type) {
-	case MetricType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE:
-	case MetricType::OPTIMIZER_COLUMN_LIFETIME:
-	case MetricType::OPTIMIZER_COMMON_AGGREGATE:
-	case MetricType::OPTIMIZER_COMMON_SUBEXPRESSIONS:
-	case MetricType::OPTIMIZER_COMMON_SUBPLAN:
-	case MetricType::OPTIMIZER_COMPRESSED_MATERIALIZATION:
-	case MetricType::OPTIMIZER_CTE_FILTER_PUSHER:
-	case MetricType::OPTIMIZER_CTE_INLINING:
-	case MetricType::OPTIMIZER_DELIMINATOR:
-	case MetricType::OPTIMIZER_DUPLICATE_GROUPS:
-	case MetricType::OPTIMIZER_EMPTY_RESULT_PULLUP:
-	case MetricType::OPTIMIZER_EXPRESSION_REWRITER:
-	case MetricType::OPTIMIZER_EXTENSION:
-	case MetricType::OPTIMIZER_FILTER_PULLUP:
-	case MetricType::OPTIMIZER_FILTER_PUSHDOWN:
-	case MetricType::OPTIMIZER_IN_CLAUSE:
-	case MetricType::OPTIMIZER_JOIN_ELIMINATION:
-	case MetricType::OPTIMIZER_JOIN_FILTER_PUSHDOWN:
-	case MetricType::OPTIMIZER_JOIN_ORDER:
-	case MetricType::OPTIMIZER_LATE_MATERIALIZATION:
-	case MetricType::OPTIMIZER_LIMIT_PUSHDOWN:
-	case MetricType::OPTIMIZER_MATERIALIZED_CTE:
-	case MetricType::OPTIMIZER_REGEX_RANGE:
-	case MetricType::OPTIMIZER_REORDER_FILTER:
-	case MetricType::OPTIMIZER_SAMPLING_PUSHDOWN:
-	case MetricType::OPTIMIZER_STATISTICS_PROPAGATION:
-	case MetricType::OPTIMIZER_SUM_REWRITER:
-	case MetricType::OPTIMIZER_TOP_N:
-	case MetricType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION:
-	case MetricType::OPTIMIZER_UNNEST_REWRITER:
-	case MetricType::OPTIMIZER_UNUSED_COLUMNS:
-		return true;
-	default:
-		return false;
-	}
+    return {
+        MetricsType::OPTIMIZER_EXPRESSION_REWRITER,
+        MetricsType::OPTIMIZER_FILTER_PULLUP,
+        MetricsType::OPTIMIZER_FILTER_PUSHDOWN,
+        MetricsType::OPTIMIZER_EMPTY_RESULT_PULLUP,
+        MetricsType::OPTIMIZER_CTE_FILTER_PUSHER,
+        MetricsType::OPTIMIZER_REGEX_RANGE,
+        MetricsType::OPTIMIZER_IN_CLAUSE,
+        MetricsType::OPTIMIZER_JOIN_ORDER,
+        MetricsType::OPTIMIZER_DELIMINATOR,
+        MetricsType::OPTIMIZER_UNNEST_REWRITER,
+        MetricsType::OPTIMIZER_UNUSED_COLUMNS,
+        MetricsType::OPTIMIZER_STATISTICS_PROPAGATION,
+        MetricsType::OPTIMIZER_COMMON_SUBEXPRESSIONS,
+        MetricsType::OPTIMIZER_COMMON_AGGREGATE,
+        MetricsType::OPTIMIZER_COLUMN_LIFETIME,
+        MetricsType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE,
+        MetricsType::OPTIMIZER_LIMIT_PUSHDOWN,
+        MetricsType::OPTIMIZER_ROW_GROUP_PRUNER,
+        MetricsType::OPTIMIZER_TOP_N,
+        MetricsType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION,
+        MetricsType::OPTIMIZER_COMPRESSED_MATERIALIZATION,
+        MetricsType::OPTIMIZER_DUPLICATE_GROUPS,
+        MetricsType::OPTIMIZER_REORDER_FILTER,
+        MetricsType::OPTIMIZER_SAMPLING_PUSHDOWN,
+        MetricsType::OPTIMIZER_JOIN_FILTER_PUSHDOWN,
+        MetricsType::OPTIMIZER_EXTENSION,
+        MetricsType::OPTIMIZER_MATERIALIZED_CTE,
+        MetricsType::OPTIMIZER_SUM_REWRITER,
+        MetricsType::OPTIMIZER_LATE_MATERIALIZATION,
+        MetricsType::OPTIMIZER_CTE_INLINING,
+        MetricsType::OPTIMIZER_COMMON_SUBPLAN,
+        MetricsType::OPTIMIZER_JOIN_ELIMINATION,
+    };
 }
 
-MetricType MetricsUtils::GetOptimizerMetricByType(OptimizerType type) {
-	switch(type) {
-	case OptimizerType::BUILD_SIDE_PROBE_SIDE:
-		return MetricType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE;
-	case OptimizerType::COLUMN_LIFETIME:
-		return MetricType::OPTIMIZER_COLUMN_LIFETIME;
-	case OptimizerType::COMMON_AGGREGATE:
-		return MetricType::OPTIMIZER_COMMON_AGGREGATE;
-	case OptimizerType::COMMON_SUBEXPRESSIONS:
-		return MetricType::OPTIMIZER_COMMON_SUBEXPRESSIONS;
-	case OptimizerType::COMMON_SUBPLAN:
-		return MetricType::OPTIMIZER_COMMON_SUBPLAN;
-	case OptimizerType::COMPRESSED_MATERIALIZATION:
-		return MetricType::OPTIMIZER_COMPRESSED_MATERIALIZATION;
-	case OptimizerType::CTE_FILTER_PUSHER:
-		return MetricType::OPTIMIZER_CTE_FILTER_PUSHER;
-	case OptimizerType::CTE_INLINING:
-		return MetricType::OPTIMIZER_CTE_INLINING;
-	case OptimizerType::DELIMINATOR:
-		return MetricType::OPTIMIZER_DELIMINATOR;
-	case OptimizerType::DUPLICATE_GROUPS:
-		return MetricType::OPTIMIZER_DUPLICATE_GROUPS;
-	case OptimizerType::EMPTY_RESULT_PULLUP:
-		return MetricType::OPTIMIZER_EMPTY_RESULT_PULLUP;
-	case OptimizerType::EXPRESSION_REWRITER:
-		return MetricType::OPTIMIZER_EXPRESSION_REWRITER;
-	case OptimizerType::EXTENSION:
-		return MetricType::OPTIMIZER_EXTENSION;
-	case OptimizerType::FILTER_PULLUP:
-		return MetricType::OPTIMIZER_FILTER_PULLUP;
-	case OptimizerType::FILTER_PUSHDOWN:
-		return MetricType::OPTIMIZER_FILTER_PUSHDOWN;
-	case OptimizerType::IN_CLAUSE:
-		return MetricType::OPTIMIZER_IN_CLAUSE;
-	case OptimizerType::JOIN_ELIMINATION:
-		return MetricType::OPTIMIZER_JOIN_ELIMINATION;
-	case OptimizerType::JOIN_FILTER_PUSHDOWN:
-		return MetricType::OPTIMIZER_JOIN_FILTER_PUSHDOWN;
-	case OptimizerType::JOIN_ORDER:
-		return MetricType::OPTIMIZER_JOIN_ORDER;
-	case OptimizerType::LATE_MATERIALIZATION:
-		return MetricType::OPTIMIZER_LATE_MATERIALIZATION;
-	case OptimizerType::LIMIT_PUSHDOWN:
-		return MetricType::OPTIMIZER_LIMIT_PUSHDOWN;
-	case OptimizerType::MATERIALIZED_CTE:
-		return MetricType::OPTIMIZER_MATERIALIZED_CTE;
-	case OptimizerType::REGEX_RANGE:
-		return MetricType::OPTIMIZER_REGEX_RANGE;
-	case OptimizerType::REORDER_FILTER:
-		return MetricType::OPTIMIZER_REORDER_FILTER;
-	case OptimizerType::SAMPLING_PUSHDOWN:
-		return MetricType::OPTIMIZER_SAMPLING_PUSHDOWN;
-	case OptimizerType::STATISTICS_PROPAGATION:
-		return MetricType::OPTIMIZER_STATISTICS_PROPAGATION;
-	case OptimizerType::SUM_REWRITER:
-		return MetricType::OPTIMIZER_SUM_REWRITER;
-	case OptimizerType::TOP_N:
-		return MetricType::OPTIMIZER_TOP_N;
-	case OptimizerType::TOP_N_WINDOW_ELIMINATION:
-		return MetricType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION;
-	case OptimizerType::UNNEST_REWRITER:
-		return MetricType::OPTIMIZER_UNNEST_REWRITER;
-	case OptimizerType::UNUSED_COLUMNS:
-		return MetricType::OPTIMIZER_UNUSED_COLUMNS;
-	default:
-		throw InternalException("OptimizerType %s cannot be converted to a MetricType", EnumUtil::ToString(type));
-	}
+profiler_settings_t MetricsUtils::GetPhaseTimingMetrics() {
+    return {
+        MetricsType::ALL_OPTIMIZERS,
+        MetricsType::CUMULATIVE_OPTIMIZER_TIMING,
+        MetricsType::PHYSICAL_PLANNER,
+        MetricsType::PHYSICAL_PLANNER_COLUMN_BINDING,
+        MetricsType::PHYSICAL_PLANNER_CREATE_PLAN,
+        MetricsType::PHYSICAL_PLANNER_RESOLVE_TYPES,
+        MetricsType::PLANNER,
+        MetricsType::PLANNER_BINDING,
+    };
 }
 
-OptimizerType MetricsUtils::GetOptimizerTypeByMetric(MetricType type) {
-	switch(type) {
-	case MetricType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE:
-		return OptimizerType::BUILD_SIDE_PROBE_SIDE;
-	case MetricType::OPTIMIZER_COLUMN_LIFETIME:
-		return OptimizerType::COLUMN_LIFETIME;
-	case MetricType::OPTIMIZER_COMMON_AGGREGATE:
-		return OptimizerType::COMMON_AGGREGATE;
-	case MetricType::OPTIMIZER_COMMON_SUBEXPRESSIONS:
-		return OptimizerType::COMMON_SUBEXPRESSIONS;
-	case MetricType::OPTIMIZER_COMMON_SUBPLAN:
-		return OptimizerType::COMMON_SUBPLAN;
-	case MetricType::OPTIMIZER_COMPRESSED_MATERIALIZATION:
-		return OptimizerType::COMPRESSED_MATERIALIZATION;
-	case MetricType::OPTIMIZER_CTE_FILTER_PUSHER:
-		return OptimizerType::CTE_FILTER_PUSHER;
-	case MetricType::OPTIMIZER_CTE_INLINING:
-		return OptimizerType::CTE_INLINING;
-	case MetricType::OPTIMIZER_DELIMINATOR:
-		return OptimizerType::DELIMINATOR;
-	case MetricType::OPTIMIZER_DUPLICATE_GROUPS:
-		return OptimizerType::DUPLICATE_GROUPS;
-	case MetricType::OPTIMIZER_EMPTY_RESULT_PULLUP:
-		return OptimizerType::EMPTY_RESULT_PULLUP;
-	case MetricType::OPTIMIZER_EXPRESSION_REWRITER:
-		return OptimizerType::EXPRESSION_REWRITER;
-	case MetricType::OPTIMIZER_EXTENSION:
-		return OptimizerType::EXTENSION;
-	case MetricType::OPTIMIZER_FILTER_PULLUP:
-		return OptimizerType::FILTER_PULLUP;
-	case MetricType::OPTIMIZER_FILTER_PUSHDOWN:
-		return OptimizerType::FILTER_PUSHDOWN;
-	case MetricType::OPTIMIZER_IN_CLAUSE:
-		return OptimizerType::IN_CLAUSE;
-	case MetricType::OPTIMIZER_JOIN_ELIMINATION:
-		return OptimizerType::JOIN_ELIMINATION;
-	case MetricType::OPTIMIZER_JOIN_FILTER_PUSHDOWN:
-		return OptimizerType::JOIN_FILTER_PUSHDOWN;
-	case MetricType::OPTIMIZER_JOIN_ORDER:
-		return OptimizerType::JOIN_ORDER;
-	case MetricType::OPTIMIZER_LATE_MATERIALIZATION:
-		return OptimizerType::LATE_MATERIALIZATION;
-	case MetricType::OPTIMIZER_LIMIT_PUSHDOWN:
-		return OptimizerType::LIMIT_PUSHDOWN;
-	case MetricType::OPTIMIZER_MATERIALIZED_CTE:
-		return OptimizerType::MATERIALIZED_CTE;
-	case MetricType::OPTIMIZER_REGEX_RANGE:
-		return OptimizerType::REGEX_RANGE;
-	case MetricType::OPTIMIZER_REORDER_FILTER:
-		return OptimizerType::REORDER_FILTER;
-	case MetricType::OPTIMIZER_SAMPLING_PUSHDOWN:
-		return OptimizerType::SAMPLING_PUSHDOWN;
-	case MetricType::OPTIMIZER_STATISTICS_PROPAGATION:
-		return OptimizerType::STATISTICS_PROPAGATION;
-	case MetricType::OPTIMIZER_SUM_REWRITER:
-		return OptimizerType::SUM_REWRITER;
-	case MetricType::OPTIMIZER_TOP_N:
-		return OptimizerType::TOP_N;
-	case MetricType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION:
-		return OptimizerType::TOP_N_WINDOW_ELIMINATION;
-	case MetricType::OPTIMIZER_UNNEST_REWRITER:
-		return OptimizerType::UNNEST_REWRITER;
-	case MetricType::OPTIMIZER_UNUSED_COLUMNS:
-		return OptimizerType::UNUSED_COLUMNS;
-	default:
-		return OptimizerType::INVALID;
-	}
+MetricsType MetricsUtils::GetOptimizerMetricByType(OptimizerType type) {
+    switch(type) {
+        case OptimizerType::EXPRESSION_REWRITER:
+            return MetricsType::OPTIMIZER_EXPRESSION_REWRITER;
+        case OptimizerType::FILTER_PULLUP:
+            return MetricsType::OPTIMIZER_FILTER_PULLUP;
+        case OptimizerType::FILTER_PUSHDOWN:
+            return MetricsType::OPTIMIZER_FILTER_PUSHDOWN;
+        case OptimizerType::EMPTY_RESULT_PULLUP:
+            return MetricsType::OPTIMIZER_EMPTY_RESULT_PULLUP;
+        case OptimizerType::CTE_FILTER_PUSHER:
+            return MetricsType::OPTIMIZER_CTE_FILTER_PUSHER;
+        case OptimizerType::REGEX_RANGE:
+            return MetricsType::OPTIMIZER_REGEX_RANGE;
+        case OptimizerType::IN_CLAUSE:
+            return MetricsType::OPTIMIZER_IN_CLAUSE;
+        case OptimizerType::JOIN_ORDER:
+            return MetricsType::OPTIMIZER_JOIN_ORDER;
+        case OptimizerType::DELIMINATOR:
+            return MetricsType::OPTIMIZER_DELIMINATOR;
+        case OptimizerType::UNNEST_REWRITER:
+            return MetricsType::OPTIMIZER_UNNEST_REWRITER;
+        case OptimizerType::UNUSED_COLUMNS:
+            return MetricsType::OPTIMIZER_UNUSED_COLUMNS;
+        case OptimizerType::STATISTICS_PROPAGATION:
+            return MetricsType::OPTIMIZER_STATISTICS_PROPAGATION;
+        case OptimizerType::COMMON_SUBEXPRESSIONS:
+            return MetricsType::OPTIMIZER_COMMON_SUBEXPRESSIONS;
+        case OptimizerType::COMMON_AGGREGATE:
+            return MetricsType::OPTIMIZER_COMMON_AGGREGATE;
+        case OptimizerType::COLUMN_LIFETIME:
+            return MetricsType::OPTIMIZER_COLUMN_LIFETIME;
+        case OptimizerType::BUILD_SIDE_PROBE_SIDE:
+            return MetricsType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE;
+        case OptimizerType::LIMIT_PUSHDOWN:
+            return MetricsType::OPTIMIZER_LIMIT_PUSHDOWN;
+        case OptimizerType::ROW_GROUP_PRUNER:
+            return MetricsType::OPTIMIZER_ROW_GROUP_PRUNER;
+        case OptimizerType::TOP_N:
+            return MetricsType::OPTIMIZER_TOP_N;
+        case OptimizerType::TOP_N_WINDOW_ELIMINATION:
+            return MetricsType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION;
+        case OptimizerType::COMPRESSED_MATERIALIZATION:
+            return MetricsType::OPTIMIZER_COMPRESSED_MATERIALIZATION;
+        case OptimizerType::DUPLICATE_GROUPS:
+            return MetricsType::OPTIMIZER_DUPLICATE_GROUPS;
+        case OptimizerType::REORDER_FILTER:
+            return MetricsType::OPTIMIZER_REORDER_FILTER;
+        case OptimizerType::SAMPLING_PUSHDOWN:
+            return MetricsType::OPTIMIZER_SAMPLING_PUSHDOWN;
+        case OptimizerType::JOIN_FILTER_PUSHDOWN:
+            return MetricsType::OPTIMIZER_JOIN_FILTER_PUSHDOWN;
+        case OptimizerType::EXTENSION:
+            return MetricsType::OPTIMIZER_EXTENSION;
+        case OptimizerType::MATERIALIZED_CTE:
+            return MetricsType::OPTIMIZER_MATERIALIZED_CTE;
+        case OptimizerType::SUM_REWRITER:
+            return MetricsType::OPTIMIZER_SUM_REWRITER;
+        case OptimizerType::LATE_MATERIALIZATION:
+            return MetricsType::OPTIMIZER_LATE_MATERIALIZATION;
+        case OptimizerType::CTE_INLINING:
+            return MetricsType::OPTIMIZER_CTE_INLINING;
+        case OptimizerType::COMMON_SUBPLAN:
+            return MetricsType::OPTIMIZER_COMMON_SUBPLAN;
+        case OptimizerType::JOIN_ELIMINATION:
+            return MetricsType::OPTIMIZER_JOIN_ELIMINATION;
+       default:
+            throw InternalException("OptimizerType %s cannot be converted to a MetricsType", EnumUtil::ToString(type));
+    };
 }
 
-profiler_settings_t MetricsUtils::GetPhaseTimingMetrics() {
-	profiler_settings_t result;
-	for (auto metric = MetricType::START_PHASE_TIMING; metric <= MetricType::END_PHASE_TIMING; metric++) {
-		result.insert(metric);
-	}
-	return result;
+OptimizerType MetricsUtils::GetOptimizerTypeByMetric(MetricsType type) {
+    switch(type) {
+        case MetricsType::OPTIMIZER_EXPRESSION_REWRITER:
+            return OptimizerType::EXPRESSION_REWRITER;
+        case MetricsType::OPTIMIZER_FILTER_PULLUP:
+            return OptimizerType::FILTER_PULLUP;
+        case MetricsType::OPTIMIZER_FILTER_PUSHDOWN:
+            return OptimizerType::FILTER_PUSHDOWN;
+        case MetricsType::OPTIMIZER_EMPTY_RESULT_PULLUP:
+            return OptimizerType::EMPTY_RESULT_PULLUP;
+        case MetricsType::OPTIMIZER_CTE_FILTER_PUSHER:
+            return OptimizerType::CTE_FILTER_PUSHER;
+        case MetricsType::OPTIMIZER_REGEX_RANGE:
+            return OptimizerType::REGEX_RANGE;
+        case MetricsType::OPTIMIZER_IN_CLAUSE:
+            return OptimizerType::IN_CLAUSE;
+        case MetricsType::OPTIMIZER_JOIN_ORDER:
+            return OptimizerType::JOIN_ORDER;
+        case MetricsType::OPTIMIZER_DELIMINATOR:
+            return OptimizerType::DELIMINATOR;
+        case MetricsType::OPTIMIZER_UNNEST_REWRITER:
+            return OptimizerType::UNNEST_REWRITER;
+        case MetricsType::OPTIMIZER_UNUSED_COLUMNS:
+            return OptimizerType::UNUSED_COLUMNS;
+        case MetricsType::OPTIMIZER_STATISTICS_PROPAGATION:
+            return OptimizerType::STATISTICS_PROPAGATION;
+        case MetricsType::OPTIMIZER_COMMON_SUBEXPRESSIONS:
+            return OptimizerType::COMMON_SUBEXPRESSIONS;
+        case MetricsType::OPTIMIZER_COMMON_AGGREGATE:
+            return OptimizerType::COMMON_AGGREGATE;
+        case MetricsType::OPTIMIZER_COLUMN_LIFETIME:
+            return OptimizerType::COLUMN_LIFETIME;
+        case MetricsType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE:
+            return OptimizerType::BUILD_SIDE_PROBE_SIDE;
+        case MetricsType::OPTIMIZER_LIMIT_PUSHDOWN:
+            return OptimizerType::LIMIT_PUSHDOWN;
+        case MetricsType::OPTIMIZER_ROW_GROUP_PRUNER:
+            return OptimizerType::ROW_GROUP_PRUNER;
+        case MetricsType::OPTIMIZER_TOP_N:
+            return OptimizerType::TOP_N;
+        case MetricsType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION:
+            return OptimizerType::TOP_N_WINDOW_ELIMINATION;
+        case MetricsType::OPTIMIZER_COMPRESSED_MATERIALIZATION:
+            return OptimizerType::COMPRESSED_MATERIALIZATION;
+        case MetricsType::OPTIMIZER_DUPLICATE_GROUPS:
+            return OptimizerType::DUPLICATE_GROUPS;
+        case MetricsType::OPTIMIZER_REORDER_FILTER:
+            return OptimizerType::REORDER_FILTER;
+        case MetricsType::OPTIMIZER_SAMPLING_PUSHDOWN:
+            return OptimizerType::SAMPLING_PUSHDOWN;
+        case MetricsType::OPTIMIZER_JOIN_FILTER_PUSHDOWN:
+            return OptimizerType::JOIN_FILTER_PUSHDOWN;
+        case MetricsType::OPTIMIZER_EXTENSION:
+            return OptimizerType::EXTENSION;
+        case MetricsType::OPTIMIZER_MATERIALIZED_CTE:
+            return OptimizerType::MATERIALIZED_CTE;
+        case MetricsType::OPTIMIZER_SUM_REWRITER:
+            return OptimizerType::SUM_REWRITER;
+        case MetricsType::OPTIMIZER_LATE_MATERIALIZATION:
+            return OptimizerType::LATE_MATERIALIZATION;
+        case MetricsType::OPTIMIZER_CTE_INLINING:
+            return OptimizerType::CTE_INLINING;
+        case MetricsType::OPTIMIZER_COMMON_SUBPLAN:
+            return OptimizerType::COMMON_SUBPLAN;
+        case MetricsType::OPTIMIZER_JOIN_ELIMINATION:
+            return OptimizerType::JOIN_ELIMINATION;
+    default:
+            return OptimizerType::INVALID;
+    };
 }
 
-bool MetricsUtils::IsPhaseTimingMetric(MetricType type) {
-	switch(type) {
-	case MetricType::ALL_OPTIMIZERS:
-	case MetricType::CUMULATIVE_OPTIMIZER_TIMING:
-	case MetricType::PHYSICAL_PLANNER:
-	case MetricType::PHYSICAL_PLANNER_COLUMN_BINDING:
-	case MetricType::PHYSICAL_PLANNER_CREATE_PLAN:
-	case MetricType::PHYSICAL_PLANNER_RESOLVE_TYPES:
-	case MetricType::PLANNER:
-	case MetricType::PLANNER_BINDING:
-		return true;
-	default:
-		return false;
-	}
+bool MetricsUtils::IsOptimizerMetric(MetricsType type) {
+    switch(type) {
+        case MetricsType::OPTIMIZER_EXPRESSION_REWRITER:
+        case MetricsType::OPTIMIZER_FILTER_PULLUP:
+        case MetricsType::OPTIMIZER_FILTER_PUSHDOWN:
+        case MetricsType::OPTIMIZER_EMPTY_RESULT_PULLUP:
+        case MetricsType::OPTIMIZER_CTE_FILTER_PUSHER:
+        case MetricsType::OPTIMIZER_REGEX_RANGE:
+        case MetricsType::OPTIMIZER_IN_CLAUSE:
+        case MetricsType::OPTIMIZER_JOIN_ORDER:
+        case MetricsType::OPTIMIZER_DELIMINATOR:
+        case MetricsType::OPTIMIZER_UNNEST_REWRITER:
+        case MetricsType::OPTIMIZER_UNUSED_COLUMNS:
+        case MetricsType::OPTIMIZER_STATISTICS_PROPAGATION:
+        case MetricsType::OPTIMIZER_COMMON_SUBEXPRESSIONS:
+        case MetricsType::OPTIMIZER_COMMON_AGGREGATE:
+        case MetricsType::OPTIMIZER_COLUMN_LIFETIME:
+        case MetricsType::OPTIMIZER_BUILD_SIDE_PROBE_SIDE:
+        case MetricsType::OPTIMIZER_LIMIT_PUSHDOWN:
+        case MetricsType::OPTIMIZER_ROW_GROUP_PRUNER:
+        case MetricsType::OPTIMIZER_TOP_N:
+        case MetricsType::OPTIMIZER_TOP_N_WINDOW_ELIMINATION:
+        case MetricsType::OPTIMIZER_COMPRESSED_MATERIALIZATION:
+        case MetricsType::OPTIMIZER_DUPLICATE_GROUPS:
+        case MetricsType::OPTIMIZER_REORDER_FILTER:
+        case MetricsType::OPTIMIZER_SAMPLING_PUSHDOWN:
+        case MetricsType::OPTIMIZER_JOIN_FILTER_PUSHDOWN:
+        case MetricsType::OPTIMIZER_EXTENSION:
+        case MetricsType::OPTIMIZER_MATERIALIZED_CTE:
+        case MetricsType::OPTIMIZER_SUM_REWRITER:
+        case MetricsType::OPTIMIZER_LATE_MATERIALIZATION:
+        case MetricsType::OPTIMIZER_CTE_INLINING:
+        case MetricsType::OPTIMIZER_COMMON_SUBPLAN:
+        case MetricsType::OPTIMIZER_JOIN_ELIMINATION:
+            return true;
+        default:
+            return false;
+    };
 }
 
-profiler_settings_t MetricsUtils::GetRootScopeMetrics() {
-	return {
-		MetricType::ATTACH_LOAD_STORAGE_LATENCY,
-		MetricType::ATTACH_REPLAY_WAL_LATENCY,
-		MetricType::BLOCKED_THREAD_TIME,
-		MetricType::CHECKPOINT_LATENCY,
-		MetricType::COMMIT_LOCAL_STORAGE_LATENCY,
-		MetricType::LATENCY,
-		MetricType::QUERY_NAME,
-		MetricType::ROWS_RETURNED,
-		MetricType::TOTAL_BYTES_READ,
-		MetricType::TOTAL_BYTES_WRITTEN,
-		MetricType::TOTAL_MEMORY_ALLOCATED,
-		MetricType::WAITING_TO_ATTACH_LATENCY,
-		MetricType::WAL_REPLAY_ENTRY_COUNT,
-		MetricType::WRITE_TO_WAL_LATENCY,
-	};
+bool MetricsUtils::IsPhaseTimingMetric(MetricsType type) {
+    switch(type) {
+        case MetricsType::ALL_OPTIMIZERS:
+        case MetricsType::CUMULATIVE_OPTIMIZER_TIMING:
+        case MetricsType::PHYSICAL_PLANNER:
+        case MetricsType::PHYSICAL_PLANNER_COLUMN_BINDING:
+        case MetricsType::PHYSICAL_PLANNER_CREATE_PLAN:
+        case MetricsType::PHYSICAL_PLANNER_RESOLVE_TYPES:
+        case MetricsType::PLANNER:
+        case MetricsType::PLANNER_BINDING:
+            return true;
+        default:
+            return false;
+    };
 }
 
-bool MetricsUtils::IsRootScopeMetric(MetricType type) {
-	switch(type) {
-	case MetricType::ATTACH_LOAD_STORAGE_LATENCY:
-	case MetricType::ATTACH_REPLAY_WAL_LATENCY:
-	case MetricType::BLOCKED_THREAD_TIME:
-	case MetricType::CHECKPOINT_LATENCY:
-	case MetricType::COMMIT_LOCAL_STORAGE_LATENCY:
-	case MetricType::LATENCY:
-	case MetricType::QUERY_NAME:
-	case MetricType::ROWS_RETURNED:
-	case MetricType::TOTAL_BYTES_READ:
-	case MetricType::TOTAL_BYTES_WRITTEN:
-	case MetricType::TOTAL_MEMORY_ALLOCATED:
-	case MetricType::WAITING_TO_ATTACH_LATENCY:
-	case MetricType::WAL_REPLAY_ENTRY_COUNT:
-	case MetricType::WRITE_TO_WAL_LATENCY:
-		return true;
-	default:
-		return false;
-	}
+bool MetricsUtils::IsQueryGlobalMetric(MetricsType type) {
+    switch(type) {
+        case MetricsType::ATTACH_LOAD_STORAGE_LATENCY:
+        case MetricsType::ATTACH_REPLAY_WAL_LATENCY:
+        case MetricsType::BLOCKED_THREAD_TIME:
+        case MetricsType::CHECKPOINT_LATENCY:
+        case MetricsType::SYSTEM_PEAK_BUFFER_MEMORY:
+        case MetricsType::SYSTEM_PEAK_TEMP_DIR_SIZE:
+        case MetricsType::TOTAL_MEMORY_ALLOCATED:
+        case MetricsType::WAITING_TO_ATTACH_LATENCY:
+            return true;
+        default:
+            return false;
+    };
 }
 
-}
+} // namespace duckdb
diff --git a/src/common/enums/metric_type.json b/src/common/enums/metric_type.json
deleted file mode 100644
index 4d28fb9a6a..0000000000
--- a/src/common/enums/metric_type.json
+++ /dev/null
@@ -1,299 +0,0 @@
-[
-  {
-    "group": "core",
-    "description": "core metrics",
-    "metrics": [
-      {
-        "name": "CPU_TIME",
-        "description": "CPU time spent on the query",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true,
-        "collection_method": "cumulative",
-        "child": "OPERATOR_TIMING"
-      },
-      {
-        "name": "CUMULATIVE_CARDINALITY",
-        "description": "Cumulative cardinality of the query",
-        "type": "uint64",
-        "unit": "absolute",
-        "is_default": true,
-        "collection_method": "cumulative",
-        "child": "OPERATOR_CARDINALITY"
-      },
-      {
-        "name": "CUMULATIVE_ROWS_SCANNED",
-        "description": "Cumulative number of rows scanned by the query",
-        "type": "uint64",
-        "unit": "absolute",
-        "is_default": true,
-        "collection_method": "cumulative",
-        "child": "OPERATOR_ROWS_SCANNED"
-      },
-      {
-        "name": "EXTRA_INFO",
-        "description": "Unique operator metrics",
-        "type": "Value::MAP",
-        "is_default": true
-      },
-      {
-        "name": "LATENCY",
-        "description": "Time spent executing the entire query",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "timer"
-      },
-      {
-        "name": "QUERY_NAME",
-        "description": "The SQL string of the query",
-        "type": "string",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "query_metric"
-      },
-      {
-        "name": "RESULT_SET_SIZE",
-        "description": "The size of the result",
-        "type": "uint64",
-        "unit": "bytes",
-        "is_default": true,
-        "collection_method": "child",
-        "child": "RESULT_SET_SIZE"
-      },
-      {
-        "name": "ROWS_RETURNED",
-        "description": "The number of rows returned by the query",
-        "type": "uint64",
-        "unit": "absolute",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "child",
-        "child": "OPERATOR_CARDINALITY"
-      }
-    ]
-  },
-  {
-    "group": "execution",
-    "description": "metrics that are collected during query execution",
-    "metrics": [
-      {
-        "name": "BLOCKED_THREAD_TIME",
-        "description": "Time spent waiting for a thread to become available",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true,
-        "query_root": true
-      },
-      {
-        "name": "SYSTEM_PEAK_BUFFER_MEMORY",
-        "description": "Peak memory usage of the system",
-        "type": "uint64",
-        "unit": "bytes",
-        "is_default": true
-      },
-      {
-        "name": "SYSTEM_PEAK_TEMP_DIR_SIZE",
-        "description": "Peak size of the temporary directory",
-        "type": "uint64",
-        "unit": "bytes",
-        "is_default": true
-      },
-      {
-        "name": "TOTAL_MEMORY_ALLOCATED",
-        "description": "The total memory allocated by the buffer manager.",
-        "type": "uint64",
-        "unit": "bytes",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "query_metric"
-      }
-    ]
-  },
-  {
-    "group": "file",
-    "description": "metrics that are collected during file operations",
-    "metrics": [
-      {
-        "name": "ATTACH_LOAD_STORAGE_LATENCY",
-        "description": "Time spent loading from storage.",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "timer"
-      },
-      {
-        "name": "ATTACH_REPLAY_WAL_LATENCY",
-        "description": "Time spent replaying the WAL file.",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "timer"
-      },
-      {
-        "name": "CHECKPOINT_LATENCY",
-        "description": "Time spent running checkpoints",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "timer"
-      },
-      {
-        "name": "COMMIT_LOCAL_STORAGE_LATENCY",
-        "description": "Time spent committing the transaction-local storage.",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "timer"
-      },
-      {
-        "name": "TOTAL_BYTES_READ",
-        "description": "The total bytes read by the file system.",
-        "type": "uint64",
-        "unit": "bytes",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "query_metric"
-      },
-      {
-        "name": "TOTAL_BYTES_WRITTEN",
-        "description": "The total bytes written by the file system.",
-        "type": "uint64",
-        "unit": "bytes",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "query_metric"
-      },
-      {
-        "name": "WAITING_TO_ATTACH_LATENCY",
-        "description": "Time spent waiting to ATTACH a file.",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "timer"
-      },
-      {
-        "name": "WAL_REPLAY_ENTRY_COUNT",
-        "description": "The total number of entries to replay in the WAL.",
-        "type": "uint64",
-        "unit": "absolute",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "query_metric"
-      },
-      {
-        "name": "WRITE_TO_WAL_LATENCY",
-        "description": "Time spent writing to the WAL.",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true,
-        "query_root": true,
-        "collection_method": "timer"
-      }
-    ]
-  },
-  {
-    "group": "phase_timing",
-    "description": "",
-    "metrics": [
-      {
-        "name": "ALL_OPTIMIZERS",
-        "description": "Enables all optimizers"
-      },
-      {
-        "name": "CUMULATIVE_OPTIMIZER_TIMING",
-        "description": "Time spent in all optimizers",
-        "type": "double",
-        "unit": "milliseconds",
-        "collection_method": "cumulative_operators"
-      },
-      {
-        "name": "PHYSICAL_PLANNER",
-        "description": "The time spent generating the physical plan",
-        "type": "double",
-        "unit": "milliseconds"
-      },
-      {
-        "name": "PHYSICAL_PLANNER_COLUMN_BINDING",
-        "description": "The time spent binding the columns in the logical plan to physical columns",
-        "type": "double",
-        "unit": "milliseconds"
-      },
-      {
-        "name": "PHYSICAL_PLANNER_CREATE_PLAN",
-        "description": "The time spent creating the physical plan",
-        "type": "double",
-        "unit": "milliseconds"
-      },
-      {
-        "name": "PHYSICAL_PLANNER_RESOLVE_TYPES",
-        "description": "The time spent resolving the types in the logical plan to physical types",
-        "type": "double",
-        "unit": "milliseconds"
-      },
-      {
-        "name": "PLANNER",
-        "description": "The time to generate the logical plan from the parsed SQL nodes.",
-        "type": "double",
-        "unit": "milliseconds"
-      },
-      {
-        "name": "PLANNER_BINDING",
-        "description": "The time taken to bind the logical plan.",
-        "type": "double",
-        "unit": "milliseconds"
-      }
-    ]
-  },
-  {
-    "group": "operator",
-    "description": "metrics that are collected for each operator",
-    "metrics": [
-      {
-        "name": "OPERATOR_CARDINALITY",
-        "description": "Cardinality of the operator",
-        "type": "uint64",
-        "unit": "absolute",
-        "is_default": true
-      },
-      {
-        "name": "OPERATOR_NAME",
-        "description": "Name of the operator",
-        "type": "string",
-        "is_default": true
-      },
-      {
-        "name": "OPERATOR_ROWS_SCANNED",
-        "description": "Number of rows scanned by the operator",
-        "type": "uint64",
-        "unit": "absolute",
-        "is_default": true
-      },
-      {
-        "name": "OPERATOR_TIMING",
-        "description": "Time spent in the operator",
-        "type": "double",
-        "unit": "seconds",
-        "is_default": true
-      },
-      {
-        "name": "OPERATOR_TYPE",
-        "description": "Type of the operator",
-        "type": "string",
-        "is_default": true
-      }
-    ]
-  },
-  {
-    "group": "optimizer",
-    "description": "metrics that are collected for each optimizer",
-    "generated": true,
-    "metrics": []
-  }
-]
\ No newline at end of file
diff --git a/src/common/file_system.cpp b/src/common/file_system.cpp
index 537e9b76d5..1161b1142a 100644
--- a/src/common/file_system.cpp
+++ b/src/common/file_system.cpp
@@ -695,7 +695,7 @@ int64_t FileHandle::Read(void *buffer, idx_t nr_bytes) {
 
 int64_t FileHandle::Read(QueryContext context, void *buffer, idx_t nr_bytes) {
 	if (context.GetClientContext() != nullptr) {
-		context.GetClientContext()->client_data->profiler->AddToCounter(MetricType::TOTAL_BYTES_READ, nr_bytes);
+		context.GetClientContext()->client_data->profiler->AddToCounter(MetricsType::TOTAL_BYTES_READ, nr_bytes);
 	}
 
 	return file_system.Read(*this, buffer, UnsafeNumericCast<int64_t>(nr_bytes));
@@ -715,7 +715,7 @@ void FileHandle::Read(void *buffer, idx_t nr_bytes, idx_t location) {
 
 void FileHandle::Read(QueryContext context, void *buffer, idx_t nr_bytes, idx_t location) {
 	if (context.GetClientContext() != nullptr) {
-		context.GetClientContext()->client_data->profiler->AddToCounter(MetricType::TOTAL_BYTES_READ, nr_bytes);
+		context.GetClientContext()->client_data->profiler->AddToCounter(MetricsType::TOTAL_BYTES_READ, nr_bytes);
 	}
 
 	file_system.Read(*this, buffer, UnsafeNumericCast<int64_t>(nr_bytes), location);
@@ -723,7 +723,7 @@ void FileHandle::Read(QueryContext context, void *buffer, idx_t nr_bytes, idx_t
 
 void FileHandle::Write(QueryContext context, void *buffer, idx_t nr_bytes, idx_t location) {
 	if (context.GetClientContext() != nullptr) {
-		context.GetClientContext()->client_data->profiler->AddToCounter(MetricType::TOTAL_BYTES_WRITTEN, nr_bytes);
+		context.GetClientContext()->client_data->profiler->AddToCounter(MetricsType::TOTAL_BYTES_WRITTEN, nr_bytes);
 	}
 
 	file_system.Write(*this, buffer, UnsafeNumericCast<int64_t>(nr_bytes), location);
diff --git a/src/common/render_tree.cpp b/src/common/render_tree.cpp
index f3bb9d54af..ee96218145 100644
--- a/src/common/render_tree.cpp
+++ b/src/common/render_tree.cpp
@@ -102,22 +102,22 @@ static unique_ptr<RenderTreeNode> CreateNode(const PipelineRenderNode &op) {
 static unique_ptr<RenderTreeNode> CreateNode(const ProfilingNode &op) {
 	auto &info = op.GetProfilingInfo();
 	InsertionOrderPreservingMap<string> extra_info;
-	if (info.Enabled(info.settings, MetricType::EXTRA_INFO)) {
-		extra_info = op.GetProfilingInfo().GetMetricValue<InsertionOrderPreservingMap<string>>(MetricType::EXTRA_INFO);
+	if (info.Enabled(info.settings, MetricsType::EXTRA_INFO)) {
+		extra_info = op.GetProfilingInfo().GetMetricValue<InsertionOrderPreservingMap<string>>(MetricsType::EXTRA_INFO);
 	}
 
 	string node_name = "QUERY";
 	if (op.depth > 0) {
-		node_name = info.GetMetricAsString(MetricType::OPERATOR_TYPE);
+		node_name = info.GetMetricAsString(MetricsType::OPERATOR_TYPE);
 	}
 
 	auto result = make_uniq<RenderTreeNode>(node_name, extra_info);
-	if (info.Enabled(info.settings, MetricType::OPERATOR_CARDINALITY)) {
-		auto cardinality = info.GetMetricAsString(MetricType::OPERATOR_CARDINALITY);
+	if (info.Enabled(info.settings, MetricsType::OPERATOR_CARDINALITY)) {
+		auto cardinality = info.GetMetricAsString(MetricsType::OPERATOR_CARDINALITY);
 		result->extra_text[RenderTreeNode::CARDINALITY] = cardinality;
 	}
-	if (info.Enabled(info.settings, MetricType::OPERATOR_TIMING)) {
-		auto value = info.metrics.at(MetricType::OPERATOR_TIMING).GetValue<double>();
+	if (info.Enabled(info.settings, MetricsType::OPERATOR_TIMING)) {
+		auto value = info.metrics.at(MetricsType::OPERATOR_TIMING).GetValue<double>();
 		string timing = StringUtil::Format("%.2f", value);
 		result->extra_text[RenderTreeNode::TIMING] = timing + "s";
 	}
diff --git a/src/common/tree_renderer/text_tree_renderer.cpp b/src/common/tree_renderer/text_tree_renderer.cpp
index 09dcb0356a..251736dd4f 100644
--- a/src/common/tree_renderer/text_tree_renderer.cpp
+++ b/src/common/tree_renderer/text_tree_renderer.cpp
@@ -491,7 +491,7 @@ void TextTreeRenderer::SplitUpExtraInfo(const InsertionOrderPreservingMap<string
 			if (extra_info.find(RenderTreeNode::TIMING) != extra_info.end()) {
 				result.emplace_back();
 			}
-			continue;
+			break;
 		}
 		if (item.first == RenderTreeNode::ESTIMATED_CARDINALITY) {
 			// estimated cardinality - reserve space for estimate
@@ -501,7 +501,7 @@ void TextTreeRenderer::SplitUpExtraInfo(const InsertionOrderPreservingMap<string
 				continue;
 			}
 			result.emplace_back();
-			continue;
+			break;
 		}
 		auto splits = StringUtil::Split(str, "\n");
 		if (splits.size() > max_lines) {
diff --git a/src/execution/physical_plan_generator.cpp b/src/execution/physical_plan_generator.cpp
index 74b420a34a..58469efe45 100644
--- a/src/execution/physical_plan_generator.cpp
+++ b/src/execution/physical_plan_generator.cpp
@@ -30,18 +30,18 @@ PhysicalOperator &PhysicalPlanGenerator::ResolveAndPlan(unique_ptr<LogicalOperat
 	auto &profiler = QueryProfiler::Get(context);
 
 	// Resolve the types of each operator.
-	profiler.StartPhase(MetricType::PHYSICAL_PLANNER_RESOLVE_TYPES);
+	profiler.StartPhase(MetricsType::PHYSICAL_PLANNER_RESOLVE_TYPES);
 	op->ResolveOperatorTypes();
 	profiler.EndPhase();
 
 	// Resolve the column references.
-	profiler.StartPhase(MetricType::PHYSICAL_PLANNER_COLUMN_BINDING);
+	profiler.StartPhase(MetricsType::PHYSICAL_PLANNER_COLUMN_BINDING);
 	ColumnBindingResolver resolver;
 	resolver.VisitOperator(*op);
 	profiler.EndPhase();
 
 	// Create the main physical plan.
-	profiler.StartPhase(MetricType::PHYSICAL_PLANNER_CREATE_PLAN);
+	profiler.StartPhase(MetricsType::PHYSICAL_PLANNER_CREATE_PLAN);
 	physical_plan = PlanInternal(*op);
 	profiler.EndPhase();
 
diff --git a/src/include/duckdb/common/enum_util.hpp b/src/include/duckdb/common/enum_util.hpp
index 527af3a9a6..667c977d6c 100644
--- a/src/include/duckdb/common/enum_util.hpp
+++ b/src/include/duckdb/common/enum_util.hpp
@@ -264,9 +264,7 @@ enum class MergeActionType : uint8_t;
 
 enum class MetaPipelineType : uint8_t;
 
-enum class MetricGroup : uint8_t;
-
-enum class MetricType : uint8_t;
+enum class MetricsType : uint8_t;
 
 enum class MultiFileColumnMappingMode : uint8_t;
 
@@ -820,10 +818,7 @@ template<>
 const char* EnumUtil::ToChars<MetaPipelineType>(MetaPipelineType value);
 
 template<>
-const char* EnumUtil::ToChars<MetricGroup>(MetricGroup value);
-
-template<>
-const char* EnumUtil::ToChars<MetricType>(MetricType value);
+const char* EnumUtil::ToChars<MetricsType>(MetricsType value);
 
 template<>
 const char* EnumUtil::ToChars<MultiFileColumnMappingMode>(MultiFileColumnMappingMode value);
@@ -1478,10 +1473,7 @@ template<>
 MetaPipelineType EnumUtil::FromString<MetaPipelineType>(const char *value);
 
 template<>
-MetricGroup EnumUtil::FromString<MetricGroup>(const char *value);
-
-template<>
-MetricType EnumUtil::FromString<MetricType>(const char *value);
+MetricsType EnumUtil::FromString<MetricsType>(const char *value);
 
 template<>
 MultiFileColumnMappingMode EnumUtil::FromString<MultiFileColumnMappingMode>(const char *value);
diff --git a/src/include/duckdb/common/enums/metric_type.hpp b/src/include/duckdb/common/enums/metric_type.hpp
index 71cb7ee63f..8d040d1813 100644
--- a/src/include/duckdb/common/enums/metric_type.hpp
+++ b/src/include/duckdb/common/enums/metric_type.hpp
@@ -1,187 +1,113 @@
-//===----------------------------------------------------------------------===//
-//
+//-------------------------------------------------------------------------
 //                         DuckDB
 //
-// duckdb/common/enums/metric_type.hpp
 //
+// duckdb/common/enums/metrics_type.hpp
+// 
 // This file is automatically generated by scripts/generate_metric_enums.py
 // Do not edit this file manually, your changes will be overwritten
-//===----------------------------------------------------------------------===//
+//-------------------------------------------------------------------------
 
 #pragma once
 
 #include "duckdb/common/types/value.hpp"
 #include "duckdb/common/unordered_set.hpp"
+#include "duckdb/common/unordered_map.hpp"
 #include "duckdb/common/constants.hpp"
+#include "duckdb/common/enum_util.hpp"
 #include "duckdb/common/enums/optimizer_type.hpp"
 
 namespace duckdb {
 
-enum class MetricGroup : uint8_t {
-	ALL,
-	CORE,
-	DEFAULT,
-	EXECUTION,
-	FILE,
-	OPERATOR,
-	OPTIMIZER,
-	PHASE_TIMING,
-	INVALID,
-};
-
-enum class MetricType : uint8_t {
-	// CORE
-	START_CORE = 0,
-	CPU_TIME = START_CORE,
-	CUMULATIVE_CARDINALITY,
-	CUMULATIVE_ROWS_SCANNED,
-	EXTRA_INFO,
-	LATENCY,
-	QUERY_NAME,
-	RESULT_SET_SIZE,
-	ROWS_RETURNED,
-	END_CORE = ROWS_RETURNED,
-	// EXECUTION
-	START_EXECUTION,
-	BLOCKED_THREAD_TIME = START_EXECUTION,
-	SYSTEM_PEAK_BUFFER_MEMORY,
-	SYSTEM_PEAK_TEMP_DIR_SIZE,
-	TOTAL_MEMORY_ALLOCATED,
-	END_EXECUTION = TOTAL_MEMORY_ALLOCATED,
-	// FILE
-	START_FILE,
-	ATTACH_LOAD_STORAGE_LATENCY = START_FILE,
-	ATTACH_REPLAY_WAL_LATENCY,
-	CHECKPOINT_LATENCY,
-	COMMIT_LOCAL_STORAGE_LATENCY,
-	TOTAL_BYTES_READ,
-	TOTAL_BYTES_WRITTEN,
-	WAITING_TO_ATTACH_LATENCY,
-	WAL_REPLAY_ENTRY_COUNT,
-	WRITE_TO_WAL_LATENCY,
-	END_FILE = WRITE_TO_WAL_LATENCY,
-	// OPERATOR
-	START_OPERATOR,
-	OPERATOR_CARDINALITY = START_OPERATOR,
-	OPERATOR_NAME,
-	OPERATOR_ROWS_SCANNED,
-	OPERATOR_TIMING,
-	OPERATOR_TYPE,
-	END_OPERATOR = OPERATOR_TYPE,
-	// OPTIMIZER
-	START_OPTIMIZER,
-	OPTIMIZER_BUILD_SIDE_PROBE_SIDE = START_OPTIMIZER,
-	OPTIMIZER_COLUMN_LIFETIME,
-	OPTIMIZER_COMMON_AGGREGATE,
-	OPTIMIZER_COMMON_SUBEXPRESSIONS,
-	OPTIMIZER_COMMON_SUBPLAN,
-	OPTIMIZER_COMPRESSED_MATERIALIZATION,
-	OPTIMIZER_CTE_FILTER_PUSHER,
-	OPTIMIZER_CTE_INLINING,
-	OPTIMIZER_DELIMINATOR,
-	OPTIMIZER_DUPLICATE_GROUPS,
-	OPTIMIZER_EMPTY_RESULT_PULLUP,
-	OPTIMIZER_EXPRESSION_REWRITER,
-	OPTIMIZER_EXTENSION,
-	OPTIMIZER_FILTER_PULLUP,
-	OPTIMIZER_FILTER_PUSHDOWN,
-	OPTIMIZER_IN_CLAUSE,
-	OPTIMIZER_JOIN_ELIMINATION,
-	OPTIMIZER_JOIN_FILTER_PUSHDOWN,
-	OPTIMIZER_JOIN_ORDER,
-	OPTIMIZER_LATE_MATERIALIZATION,
-	OPTIMIZER_LIMIT_PUSHDOWN,
-	OPTIMIZER_MATERIALIZED_CTE,
-	OPTIMIZER_REGEX_RANGE,
-	OPTIMIZER_REORDER_FILTER,
-	OPTIMIZER_SAMPLING_PUSHDOWN,
-	OPTIMIZER_STATISTICS_PROPAGATION,
-	OPTIMIZER_SUM_REWRITER,
-	OPTIMIZER_TOP_N,
-	OPTIMIZER_TOP_N_WINDOW_ELIMINATION,
-	OPTIMIZER_UNNEST_REWRITER,
-	OPTIMIZER_UNUSED_COLUMNS,
-	END_OPTIMIZER = OPTIMIZER_UNUSED_COLUMNS,
-	// PHASE_TIMING
-	START_PHASE_TIMING,
-	ALL_OPTIMIZERS = START_PHASE_TIMING,
-	CUMULATIVE_OPTIMIZER_TIMING,
-	PHYSICAL_PLANNER,
-	PHYSICAL_PLANNER_COLUMN_BINDING,
-	PHYSICAL_PLANNER_CREATE_PLAN,
-	PHYSICAL_PLANNER_RESOLVE_TYPES,
-	PLANNER,
-	PLANNER_BINDING,
-	END_PHASE_TIMING = PLANNER_BINDING,
+enum class MetricsType : uint8_t {
+    ATTACH_LOAD_STORAGE_LATENCY,
+    ATTACH_REPLAY_WAL_LATENCY,
+    BLOCKED_THREAD_TIME,
+    CHECKPOINT_LATENCY,
+    CPU_TIME,
+    CUMULATIVE_CARDINALITY,
+    CUMULATIVE_ROWS_SCANNED,
+    EXTRA_INFO,
+    LATENCY,
+    OPERATOR_CARDINALITY,
+    OPERATOR_NAME,
+    OPERATOR_ROWS_SCANNED,
+    OPERATOR_TIMING,
+    OPERATOR_TYPE,
+    QUERY_NAME,
+    RESULT_SET_SIZE,
+    ROWS_RETURNED,
+    SYSTEM_PEAK_BUFFER_MEMORY,
+    SYSTEM_PEAK_TEMP_DIR_SIZE,
+    TOTAL_BYTES_READ,
+    TOTAL_BYTES_WRITTEN,
+    TOTAL_MEMORY_ALLOCATED,
+    WAITING_TO_ATTACH_LATENCY,
+    COMMIT_LOCAL_STORAGE_LATENCY,
+    WRITE_TO_WAL_LATENCY,
+    WAL_REPLAY_ENTRY_COUNT,
+    ALL_OPTIMIZERS,
+    CUMULATIVE_OPTIMIZER_TIMING,
+    PHYSICAL_PLANNER,
+    PHYSICAL_PLANNER_COLUMN_BINDING,
+    PHYSICAL_PLANNER_CREATE_PLAN,
+    PHYSICAL_PLANNER_RESOLVE_TYPES,
+    PLANNER,
+    PLANNER_BINDING,
+    OPTIMIZER_EXPRESSION_REWRITER,
+    OPTIMIZER_FILTER_PULLUP,
+    OPTIMIZER_FILTER_PUSHDOWN,
+    OPTIMIZER_EMPTY_RESULT_PULLUP,
+    OPTIMIZER_CTE_FILTER_PUSHER,
+    OPTIMIZER_REGEX_RANGE,
+    OPTIMIZER_IN_CLAUSE,
+    OPTIMIZER_JOIN_ORDER,
+    OPTIMIZER_DELIMINATOR,
+    OPTIMIZER_UNNEST_REWRITER,
+    OPTIMIZER_UNUSED_COLUMNS,
+    OPTIMIZER_STATISTICS_PROPAGATION,
+    OPTIMIZER_COMMON_SUBEXPRESSIONS,
+    OPTIMIZER_COMMON_AGGREGATE,
+    OPTIMIZER_COLUMN_LIFETIME,
+    OPTIMIZER_BUILD_SIDE_PROBE_SIDE,
+    OPTIMIZER_LIMIT_PUSHDOWN,
+    OPTIMIZER_ROW_GROUP_PRUNER,
+    OPTIMIZER_TOP_N,
+    OPTIMIZER_TOP_N_WINDOW_ELIMINATION,
+    OPTIMIZER_COMPRESSED_MATERIALIZATION,
+    OPTIMIZER_DUPLICATE_GROUPS,
+    OPTIMIZER_REORDER_FILTER,
+    OPTIMIZER_SAMPLING_PUSHDOWN,
+    OPTIMIZER_JOIN_FILTER_PUSHDOWN,
+    OPTIMIZER_EXTENSION,
+    OPTIMIZER_MATERIALIZED_CTE,
+    OPTIMIZER_SUM_REWRITER,
+    OPTIMIZER_LATE_MATERIALIZATION,
+    OPTIMIZER_CTE_INLINING,
+    OPTIMIZER_COMMON_SUBPLAN,
+    OPTIMIZER_JOIN_ELIMINATION,
 };
 
-inline MetricType &operator++(MetricType &metric) {
-	metric = static_cast<MetricType>(static_cast<uint8_t>(metric) + 1);
-	return metric;
-}
-
-inline MetricType operator++(MetricType &metric, int) {
-	const MetricType tmp = metric;
-	++metric;
-	return tmp;
-}
-
-struct MetricTypeHashFunction {
-    uint64_t operator()(const MetricType &index) const {
-        return std::hash<uint8_t>()(static_cast<uint8_t>(index));
-    }
+struct MetricsTypeHashFunction {
+	uint64_t operator()(const MetricsType &index) const {
+		return std::hash<uint8_t>()(static_cast<uint8_t>(index));
+	}
 };
 
-typedef unordered_set<MetricType, MetricTypeHashFunction> profiler_settings_t;
-typedef unordered_map<MetricType, Value, MetricTypeHashFunction> profiler_metrics_t;
+typedef unordered_set<MetricsType, MetricsTypeHashFunction> profiler_settings_t;
+typedef unordered_map<MetricsType, Value, MetricsTypeHashFunction> profiler_metrics_t;
 
 class MetricsUtils {
 public:
-	static constexpr const idx_t CORE_METRIC_COUNT = 8;
-	static constexpr const idx_t EXECUTION_METRIC_COUNT = 4;
-	static constexpr const idx_t FILE_METRIC_COUNT = 9;
-	static constexpr const idx_t OPERATOR_METRIC_COUNT = 5;
-	static constexpr const idx_t OPTIMIZER_METRIC_COUNT = 31;
-	static constexpr const idx_t PHASE_TIMING_METRIC_COUNT = 8;
-
-public:
-
-	// All metrics
-	static profiler_settings_t GetAllMetrics();
-	static profiler_settings_t GetMetricsByGroupType(MetricGroup type);
+    static profiler_settings_t GetOptimizerMetrics();
+    static profiler_settings_t GetPhaseTimingMetrics();
 
-	// Core metrics
-	static profiler_settings_t GetCoreMetrics();
-	static bool IsCoreMetric(MetricType type);
+    static MetricsType GetOptimizerMetricByType(OptimizerType type);
+    static OptimizerType GetOptimizerTypeByMetric(MetricsType type);
 
-	// Default metrics
-	static profiler_settings_t GetDefaultMetrics();
-	static bool IsDefaultMetric(MetricType type);
-
-	// Execution metrics
-	static profiler_settings_t GetExecutionMetrics();
-	static bool IsExecutionMetric(MetricType type);
-
-	// File metrics
-	static profiler_settings_t GetFileMetrics();
-	static bool IsFileMetric(MetricType type);
-
-	// Operator metrics
-	static profiler_settings_t GetOperatorMetrics();
-	static bool IsOperatorMetric(MetricType type);
-
-	// Optimizer metrics
-	static profiler_settings_t GetOptimizerMetrics();
-	static bool IsOptimizerMetric(MetricType type);
-	static MetricType GetOptimizerMetricByType(OptimizerType type);
-	static OptimizerType GetOptimizerTypeByMetric(MetricType type);
-
-	// PhaseTiming metrics
-	static profiler_settings_t GetPhaseTimingMetrics();
-	static bool IsPhaseTimingMetric(MetricType type);
-
-	// RootScope metrics
-	static profiler_settings_t GetRootScopeMetrics();
-	static bool IsRootScopeMetric(MetricType type);
+    static bool IsOptimizerMetric(MetricsType type);
+    static bool IsPhaseTimingMetric(MetricsType type);
+    static bool IsQueryGlobalMetric(MetricsType type);
 };
+
 } // namespace duckdb
diff --git a/src/include/duckdb/logging/log_type.hpp b/src/include/duckdb/logging/log_type.hpp
index dae62f3b48..c2fefc68ca 100644
--- a/src/include/duckdb/logging/log_type.hpp
+++ b/src/include/duckdb/logging/log_type.hpp
@@ -20,7 +20,7 @@ class PhysicalOperator;
 class AttachedDatabase;
 class RowGroup;
 struct DataTableInfo;
-enum class MetricType : uint8_t;
+enum class MetricsType : uint8_t;
 
 //! Log types provide some structure to the formats that the different log messages can have
 //! For now, this holds a type that the VARCHAR value will be auto-cast into.
@@ -117,7 +117,7 @@ public:
 
 	static LogicalType GetLogType();
 
-	static string ConstructLogMessage(const MetricType &type, const Value &value);
+	static string ConstructLogMessage(const MetricsType &type, const Value &value);
 };
 
 class CheckpointLogType : public LogType {
diff --git a/src/include/duckdb/main/client_config.hpp b/src/include/duckdb/main/client_config.hpp
index 2485ffdf49..284e63ce95 100644
--- a/src/include/duckdb/main/client_config.hpp
+++ b/src/include/duckdb/main/client_config.hpp
@@ -40,7 +40,7 @@ struct ClientConfig {
 	string profiler_save_location;
 	//! The custom settings for the profiler
 	//! (empty = use the default settings)
-	profiler_settings_t profiler_settings = MetricsUtils::GetDefaultMetrics();
+	profiler_settings_t profiler_settings = ProfilingInfo::DefaultSettings();
 
 	//! Allows suppressing profiler output, even if enabled. We turn on the profiler on all test runs but don't want
 	//! to output anything
diff --git a/src/include/duckdb/main/profiling_info.hpp b/src/include/duckdb/main/profiling_info.hpp
index a3f160957c..554c6cafeb 100644
--- a/src/include/duckdb/main/profiling_info.hpp
+++ b/src/include/duckdb/main/profiling_info.hpp
@@ -39,27 +39,32 @@ public:
 	ProfilingInfo(ProfilingInfo &) = default;
 	ProfilingInfo &operator=(ProfilingInfo const &) = default;
 
+public:
+	static profiler_settings_t DefaultSettings();
+	static profiler_settings_t RootScopeSettings();
+	static profiler_settings_t OperatorScopeSettings();
+
 public:
 	void ResetMetrics();
 	//! Returns true, if the query profiler must collect this metric.
-	static bool Enabled(const profiler_settings_t &settings, const MetricType metric);
+	static bool Enabled(const profiler_settings_t &settings, const MetricsType metric);
 	//! Expand metrics depending on the collection of other metrics.
-	static void Expand(profiler_settings_t &settings, const MetricType metric);
+	static void Expand(profiler_settings_t &settings, const MetricsType metric);
 
 public:
-	string GetMetricAsString(const MetricType metric) const;
+	string GetMetricAsString(const MetricsType metric) const;
 	void WriteMetricsToLog(ClientContext &context);
 	void WriteMetricsToJSON(duckdb_yyjson::yyjson_mut_doc *doc, duckdb_yyjson::yyjson_mut_val *destination);
 
 public:
 	template <class METRIC_TYPE>
-	METRIC_TYPE GetMetricValue(const MetricType type) const {
+	METRIC_TYPE GetMetricValue(const MetricsType type) const {
 		auto val = metrics.at(type);
 		return val.GetValue<METRIC_TYPE>();
 	}
 
 	template <class METRIC_TYPE>
-	void MetricUpdate(const MetricType type, const Value &value,
+	void MetricUpdate(const MetricsType type, const Value &value,
 	                  const std::function<METRIC_TYPE(const METRIC_TYPE &, const METRIC_TYPE &)> &update_fun) {
 		if (metrics.find(type) == metrics.end()) {
 			metrics[type] = value;
@@ -70,34 +75,34 @@ public:
 	}
 
 	template <class METRIC_TYPE>
-	void MetricUpdate(const MetricType type, const METRIC_TYPE &value,
+	void MetricUpdate(const MetricsType type, const METRIC_TYPE &value,
 	                  const std::function<METRIC_TYPE(const METRIC_TYPE &, const METRIC_TYPE &)> &update_fun) {
 		auto new_value = Value::CreateValue(value);
 		MetricUpdate<METRIC_TYPE>(type, new_value, update_fun);
 	}
 
 	template <class METRIC_TYPE>
-	void MetricSum(const MetricType type, const Value &value) {
+	void MetricSum(const MetricsType type, const Value &value) {
 		MetricUpdate<METRIC_TYPE>(type, value, [](const METRIC_TYPE &old_value, const METRIC_TYPE &new_value) {
 			return old_value + new_value;
 		});
 	}
 
 	template <class METRIC_TYPE>
-	void MetricSum(const MetricType type, const METRIC_TYPE &value) {
+	void MetricSum(const MetricsType type, const METRIC_TYPE &value) {
 		auto new_value = Value::CreateValue(value);
 		return MetricSum<METRIC_TYPE>(type, new_value);
 	}
 
 	template <class METRIC_TYPE>
-	void MetricMax(const MetricType type, const Value &value) {
+	void MetricMax(const MetricsType type, const Value &value) {
 		MetricUpdate<METRIC_TYPE>(type, value, [](const METRIC_TYPE &old_value, const METRIC_TYPE &new_value) {
 			return MaxValue(old_value, new_value);
 		});
 	}
 
 	template <class METRIC_TYPE>
-	void MetricMax(const MetricType type, const METRIC_TYPE &value) {
+	void MetricMax(const MetricsType type, const METRIC_TYPE &value) {
 		auto new_value = Value::CreateValue(value);
 		return MetricMax<METRIC_TYPE>(type, new_value);
 	}
@@ -106,7 +111,7 @@ public:
 // Specialization for InsertionOrderPreservingMap<string>
 template <>
 inline InsertionOrderPreservingMap<string>
-ProfilingInfo::GetMetricValue<InsertionOrderPreservingMap<string>>(const MetricType type) const {
+ProfilingInfo::GetMetricValue<InsertionOrderPreservingMap<string>>(const MetricsType type) const {
 	auto val = metrics.at(type);
 	InsertionOrderPreservingMap<string> result;
 	auto children = MapValue::GetChildren(val);
diff --git a/src/include/duckdb/main/profiling_utils.hpp b/src/include/duckdb/main/profiling_utils.hpp
deleted file mode 100644
index e5aab662a5..0000000000
--- a/src/include/duckdb/main/profiling_utils.hpp
+++ /dev/null
@@ -1,174 +0,0 @@
-//===----------------------------------------------------------------------===//
-//
-//                         DuckDB
-//
-// duckdb/main/profiling_utils.hpp
-//
-// This file is automatically generated by scripts/generate_metric_enums.py
-// Do not edit this file manually, your changes will be overwritten
-//===----------------------------------------------------------------------===//
-
-#pragma once
-
-#include "duckdb/common/enums/metric_type.hpp"
-#include "duckdb/main/query_profiler.hpp"
-#include "duckdb/main/profiling_node.hpp"
-
-namespace duckdb_yyjson {
-struct yyjson_mut_doc;
-struct yyjson_mut_val;
-} // namespace duckdb_yyjson
-
-namespace duckdb {
-
-struct ActiveTimer;
-
-//! Top level query metrics.
-struct QueryMetrics {
-	QueryMetrics() : query_name(""), attach_load_storage_latency(0), attach_replay_wal_latency(0), checkpoint_latency(0), commit_local_storage_latency(0), latency(0), waiting_to_attach_latency(0), write_to_wal_latency(0), total_bytes_read(0), total_bytes_written(0), total_memory_allocated(0), wal_replay_entry_count(0) {};
-
-	//! Reset the query metrics
-	void Reset() {
-		query_name = "";
-		attach_load_storage_latency = 0;
-		attach_replay_wal_latency = 0;
-		checkpoint_latency = 0;
-		commit_local_storage_latency = 0;
-		latency = 0;
-		latency_timer = nullptr;
-		waiting_to_attach_latency = 0;
-		write_to_wal_latency = 0;
-		total_bytes_read = 0;
-		total_bytes_written = 0;
-		total_memory_allocated = 0;
-		wal_replay_entry_count = 0;
-	}
-
-	void AddTiming(const MetricType type, const double amount) {
-		switch(type) {
-		case MetricType::ATTACH_LOAD_STORAGE_LATENCY:
-			attach_load_storage_latency.store(attach_load_storage_latency.load() + amount);
-			break;
-		case MetricType::ATTACH_REPLAY_WAL_LATENCY:
-			attach_replay_wal_latency.store(attach_replay_wal_latency.load() + amount);
-			break;
-		case MetricType::CHECKPOINT_LATENCY:
-			checkpoint_latency.store(checkpoint_latency.load() + amount);
-			break;
-		case MetricType::COMMIT_LOCAL_STORAGE_LATENCY:
-			commit_local_storage_latency.store(commit_local_storage_latency.load() + amount);
-			break;
-		case MetricType::LATENCY:
-			latency.store(latency.load() + amount);
-			break;
-		case MetricType::WAITING_TO_ATTACH_LATENCY:
-			waiting_to_attach_latency.store(waiting_to_attach_latency.load() + amount);
-			break;
-		case MetricType::WRITE_TO_WAL_LATENCY:
-			write_to_wal_latency.store(write_to_wal_latency.load() + amount);
-			break;
-		default:
-			return;
-		};
-	}
-
-	void AddToCounter(const MetricType type, const idx_t amount) {
-		switch(type) {
-		case MetricType::TOTAL_BYTES_READ:
-			total_bytes_read += amount;
-			break;
-		case MetricType::TOTAL_BYTES_WRITTEN:
-			total_bytes_written += amount;
-			break;
-		case MetricType::TOTAL_MEMORY_ALLOCATED:
-			total_memory_allocated += amount;
-			break;
-		case MetricType::WAL_REPLAY_ENTRY_COUNT:
-			wal_replay_entry_count += amount;
-			break;
-		default:
-			return;
-		};
-	}
-
-	ProfilingInfo query_global_info;
-
-	//! The SQL string of the query
-	string query_name;
-	//! Time spent loading from storage.
-	atomic<double> attach_load_storage_latency;
-	//! Time spent replaying the WAL file.
-	atomic<double> attach_replay_wal_latency;
-	//! Time spent running checkpoints
-	atomic<double> checkpoint_latency;
-	//! Time spent committing the transaction-local storage.
-	atomic<double> commit_local_storage_latency;
-	//! Time spent executing the entire query
-	atomic<double> latency;
-	unique_ptr<ActiveTimer> latency_timer;
-	//! Time spent waiting to ATTACH a file.
-	atomic<double> waiting_to_attach_latency;
-	//! Time spent writing to the WAL.
-	atomic<double> write_to_wal_latency;
-	//! The total bytes read by the file system.
-	atomic<idx_t> total_bytes_read;
-	//! The total bytes written by the file system.
-	atomic<idx_t> total_bytes_written;
-	//! The total memory allocated by the buffer manager.
-	atomic<idx_t> total_memory_allocated;
-	//! The total number of entries to replay in the WAL.
-	atomic<idx_t> wal_replay_entry_count;
-};
-
-
-class ProfilingUtils {
-public:
-	static void SetMetricToDefault(profiler_metrics_t &metrics, const MetricType &type);
-	static void MetricToJson(duckdb_yyjson::yyjson_mut_doc *doc, duckdb_yyjson::yyjson_mut_val *dest, const char *key_ptr,  profiler_metrics_t &metrics, const MetricType &type);
-	static void CollectMetrics(const MetricType &type, QueryMetrics &query_metrics, Value &metric, ProfilingNode &node, ProfilingInfo &child_info);
-};
-
-struct ActiveTimer {
-public:
-	ActiveTimer(QueryMetrics &query_metrics, const MetricType metric, const bool is_active = true) : query_metrics(query_metrics), metric(metric), is_active(is_active) {
-		// start on constructor
-		if (!is_active) {
-			return;
-		}
-		profiler.Start();
-	}
-
-	~ActiveTimer() {
-		if (is_active) {
-			// automatically end in destructor
-			EndTimer();
-		}
-	}
-
-	// Automatically called in the destructor.
-	void EndTimer() {
-		if (!is_active) {
-			return;
-		}
-		// stop profiling and report
-		is_active = false;
-		profiler.End();
-		query_metrics.AddTiming(metric, profiler.Elapsed());
-	}
-
-	void Reset() {
-	    if (!is_active) {
-			return;
-		}
-		profiler.Reset();
-		is_active = false;
-	}
-
-private:
-	QueryMetrics &query_metrics;
-	const MetricType metric;
-	Profiler profiler;
-	bool is_active;
-};
-
-}
diff --git a/src/include/duckdb/main/profiling_utils.hpp.template b/src/include/duckdb/main/profiling_utils.hpp.template
deleted file mode 100644
index 88ee94958b..0000000000
--- a/src/include/duckdb/main/profiling_utils.hpp.template
+++ /dev/null
@@ -1,75 +0,0 @@
-// !!!!!!!
-// WARNING: this file is used for header generation by scripts/generate_metric_enums.py after modifying the code below, rerun
-//          the script to apply changes to the generated files
-// !!!!!!!
-
-// DUCKDB_START_OF_FILE
-
-#pragma once
-
-#include "duckdb/common/enums/metric_type.hpp"
-#include "duckdb/main/query_profiler.hpp"
-#include "duckdb/main/profiling_node.hpp"
-
-namespace duckdb_yyjson {
-struct yyjson_mut_doc;
-struct yyjson_mut_val;
-} // namespace duckdb_yyjson
-
-namespace duckdb {
-
-struct ActiveTimer;
-
-// DUCKDB_INSERT_CODE_HERE
-
-class ProfilingUtils {
-public:
-	static void SetMetricToDefault(profiler_metrics_t &metrics, const MetricType &type);
-	static void MetricToJson(duckdb_yyjson::yyjson_mut_doc *doc, duckdb_yyjson::yyjson_mut_val *dest, const char *key_ptr,  profiler_metrics_t &metrics, const MetricType &type);
-	static void CollectMetrics(const MetricType &type, QueryMetrics &query_metrics, Value &metric, ProfilingNode &node, ProfilingInfo &child_info);
-};
-
-struct ActiveTimer {
-public:
-	ActiveTimer(QueryMetrics &query_metrics, const MetricType metric, const bool is_active = true) : query_metrics(query_metrics), metric(metric), is_active(is_active) {
-		// start on constructor
-		if (!is_active) {
-			return;
-		}
-		profiler.Start();
-	}
-
-	~ActiveTimer() {
-		if (is_active) {
-			// automatically end in destructor
-			EndTimer();
-		}
-	}
-
-	// Automatically called in the destructor.
-	void EndTimer() {
-		if (!is_active) {
-			return;
-		}
-		// stop profiling and report
-		is_active = false;
-		profiler.End();
-		query_metrics.AddTiming(metric, profiler.Elapsed());
-	}
-
-	void Reset() {
-	    if (!is_active) {
-			return;
-		}
-		profiler.Reset();
-		is_active = false;
-	}
-
-private:
-	QueryMetrics &query_metrics;
-	const MetricType metric;
-	Profiler profiler;
-	bool is_active;
-};
-
-}
diff --git a/src/include/duckdb/main/query_profiler.hpp b/src/include/duckdb/main/query_profiler.hpp
index 5d62465909..71bf3dafbc 100644
--- a/src/include/duckdb/main/query_profiler.hpp
+++ b/src/include/duckdb/main/query_profiler.hpp
@@ -23,7 +23,6 @@
 #include "duckdb/execution/physical_operator.hpp"
 #include "duckdb/main/profiling_info.hpp"
 #include "duckdb/main/profiling_node.hpp"
-#include "duckdb/main/profiling_utils.hpp"
 
 #include <stack>
 
@@ -34,7 +33,6 @@ class ExpressionExecutor;
 class ProfilingNode;
 class PhysicalOperator;
 class SQLStatement;
-struct QueryMetrics;
 
 enum class ProfilingCoverage : uint8_t { SELECT = 0, ALL = 1 };
 
@@ -114,6 +112,54 @@ private:
 	reference_map_t<const PhysicalOperator, OperatorInformation> operator_infos;
 };
 
+//! Top level query metrics.
+struct QueryMetrics {
+	QueryMetrics() : total_bytes_read(0), total_bytes_written(0), total_memory_allocated(0) {};
+
+	//! Reset the query metrics.
+	void Reset() {
+		query = "";
+		latency.Reset();
+		waiting_to_attach_latency.Reset();
+		attach_load_storage_latency.Reset();
+		attach_replay_wal_latency.Reset();
+		checkpoint_latency.Reset();
+		commit_local_storage_latency.Reset();
+		write_to_wal_latency.Reset();
+		wal_replay_entry_count = 0;
+		total_bytes_read = 0;
+		total_bytes_written = 0;
+		total_memory_allocated = 0;
+	}
+
+	ProfilingInfo query_global_info;
+
+	//! The SQL string of the query.
+	string query;
+	//! The timer of the execution of the entire query.
+	Profiler latency;
+	//! The timer of the delay when waiting to ATTACH a file.
+	Profiler waiting_to_attach_latency;
+	//! The timer for loading from storage.
+	Profiler attach_load_storage_latency;
+	//! The timer for replaying the WAL file.
+	Profiler attach_replay_wal_latency;
+	//! The timer for running checkpoints.
+	Profiler checkpoint_latency;
+	//! The timer for committing the transaction-local storage.
+	Profiler commit_local_storage_latency;
+	//! The timer for the WAL writes.
+	Profiler write_to_wal_latency;
+	//! The total number of entries to replay in the WAL.
+	atomic<idx_t> wal_replay_entry_count;
+	//! The total bytes read by the file system.
+	atomic<idx_t> total_bytes_read;
+	//! The total bytes written by the file system.
+	atomic<idx_t> total_bytes_written;
+	//! The total memory allocated by the buffer manager.
+	atomic<idx_t> total_memory_allocated;
+};
+
 //! QueryProfiler collects the profiling metrics of a query.
 class QueryProfiler {
 public:
@@ -137,10 +183,11 @@ public:
 	DUCKDB_API void EndQuery();
 
 	//! Adds amount to a specific metric type.
-	DUCKDB_API void AddToCounter(MetricType type, const idx_t amount);
+	DUCKDB_API void AddToCounter(MetricsType type, const idx_t amount);
 
 	//! Start/End a timer for a specific metric type.
-	DUCKDB_API ActiveTimer StartTimer(MetricType type);
+	DUCKDB_API void StartTimer(MetricsType type);
+	DUCKDB_API void EndTimer(MetricsType type);
 
 	DUCKDB_API void StartExplainAnalyze();
 
@@ -149,7 +196,7 @@ public:
 	//! Adds the top level query information to the global profiler.
 	DUCKDB_API void SetBlockedTime(const double &blocked_thread_time);
 
-	DUCKDB_API void StartPhase(MetricType phase_metric);
+	DUCKDB_API void StartPhase(MetricsType phase_metric);
 	DUCKDB_API void EndPhase();
 
 	DUCKDB_API void Initialize(const PhysicalOperator &root);
@@ -228,11 +275,11 @@ private:
 	//! The timer used to time the individual phases of the planning process
 	Profiler phase_profiler;
 	//! A mapping of the phase names to the timings
-	using PhaseTimingStorage = unordered_map<MetricType, double, MetricTypeHashFunction>;
+	using PhaseTimingStorage = unordered_map<MetricsType, double, MetricsTypeHashFunction>;
 	PhaseTimingStorage phase_timings;
 	using PhaseTimingItem = PhaseTimingStorage::value_type;
 	//! The stack of currently active phases
-	vector<MetricType> phase_stack;
+	vector<MetricsType> phase_stack;
 
 private:
 	void MoveOptimizerPhasesToRoot();
diff --git a/src/logging/log_types.cpp b/src/logging/log_types.cpp
index 27c4b1eb38..4441581be2 100644
--- a/src/logging/log_types.cpp
+++ b/src/logging/log_types.cpp
@@ -168,7 +168,7 @@ LogicalType MetricsLogType::GetLogType() {
 	return LogicalType::STRUCT(child_list);
 }
 
-string MetricsLogType::ConstructLogMessage(const MetricType &metric, const Value &value) {
+string MetricsLogType::ConstructLogMessage(const MetricsType &metric, const Value &value) {
 	child_list_t<Value> child_list = {
 	    {"metric", EnumUtil::ToString(metric)},
 	    {"value", value.ToString()},
diff --git a/src/main/CMakeLists.txt b/src/main/CMakeLists.txt
index 1067ca5dd3..e5f305f003 100644
--- a/src/main/CMakeLists.txt
+++ b/src/main/CMakeLists.txt
@@ -42,7 +42,6 @@ add_library_unity(
   prepared_statement.cpp
   prepared_statement_data.cpp
   profiling_info.cpp
-  profiling_utils.cpp
   relation.cpp
   query_profiler.cpp
   query_result.cpp
diff --git a/src/main/capi/profiling_info-c.cpp b/src/main/capi/profiling_info-c.cpp
index c8aa47f2f4..5dc06e22f8 100644
--- a/src/main/capi/profiling_info-c.cpp
+++ b/src/main/capi/profiling_info-c.cpp
@@ -3,7 +3,7 @@
 using duckdb::Connection;
 using duckdb::DuckDB;
 using duckdb::EnumUtil;
-using duckdb::MetricType;
+using duckdb::MetricsType;
 using duckdb::optional_ptr;
 using duckdb::ProfilingNode;
 
@@ -31,7 +31,7 @@ duckdb_value duckdb_profiling_info_get_value(duckdb_profiling_info info, const c
 	}
 	auto &node = *reinterpret_cast<duckdb::ProfilingNode *>(info);
 	auto &profiling_info = node.GetProfilingInfo();
-	auto key_enum = EnumUtil::FromString<MetricType>(duckdb::StringUtil::Upper(key));
+	auto key_enum = EnumUtil::FromString<MetricsType>(duckdb::StringUtil::Upper(key));
 	if (!profiling_info.Enabled(profiling_info.settings, key_enum)) {
 		return nullptr;
 	}
@@ -55,7 +55,7 @@ duckdb_value duckdb_profiling_info_get_metrics(duckdb_profiling_info info) {
 			continue;
 		}
 
-		if (key == EnumUtil::ToString(MetricType::OPERATOR_TYPE)) {
+		if (key == EnumUtil::ToString(MetricsType::OPERATOR_TYPE)) {
 			auto type = duckdb::PhysicalOperatorType(metric.second.GetValue<uint8_t>());
 			metrics_map[key] = EnumUtil::ToString(type);
 		} else {
diff --git a/src/main/client_context.cpp b/src/main/client_context.cpp
index 6c179f106c..bdb517cc00 100644
--- a/src/main/client_context.cpp
+++ b/src/main/client_context.cpp
@@ -368,7 +368,7 @@ shared_ptr<PreparedStatementData> ClientContext::CreatePreparedStatementInternal
 
 	auto &profiler = QueryProfiler::Get(*this);
 	profiler.StartQuery(query, IsExplainAnalyze(statement.get()), true);
-	profiler.StartPhase(MetricType::PLANNER);
+	profiler.StartPhase(MetricsType::PLANNER);
 	Planner logical_planner(*this);
 	if (parameters.parameters) {
 		auto &parameter_values = *parameters.parameters;
@@ -394,7 +394,7 @@ shared_ptr<PreparedStatementData> ClientContext::CreatePreparedStatementInternal
 	logical_plan->Verify(*this);
 #endif
 	if (config.enable_optimizer && logical_plan->RequireOptimizer()) {
-		profiler.StartPhase(MetricType::ALL_OPTIMIZERS);
+		profiler.StartPhase(MetricsType::ALL_OPTIMIZERS);
 		Optimizer optimizer(*logical_planner.binder, *this);
 		logical_plan = optimizer.Optimize(std::move(logical_plan));
 		D_ASSERT(logical_plan);
@@ -406,7 +406,7 @@ shared_ptr<PreparedStatementData> ClientContext::CreatePreparedStatementInternal
 	}
 
 	// Convert the logical query plan into a physical query plan.
-	profiler.StartPhase(MetricType::PHYSICAL_PLANNER);
+	profiler.StartPhase(MetricsType::PHYSICAL_PLANNER);
 	PhysicalPlanGenerator physical_planner(*this);
 	result->physical_plan = physical_planner.Plan(std::move(logical_plan));
 	profiler.EndPhase();
diff --git a/src/main/client_data.cpp b/src/main/client_data.cpp
index c0dc0cf140..74ba325da3 100644
--- a/src/main/client_data.cpp
+++ b/src/main/client_data.cpp
@@ -208,7 +208,7 @@ private:
 			auto &profiler = QueryProfiler::Get(context);
 			// Track allocations even if profiler isn't running yet - they'll be included when the query starts
 			// AddToCounter already checks IsEnabled(), so we don't need to check here
-			profiler.AddToCounter(MetricType::TOTAL_MEMORY_ALLOCATED, size);
+			profiler.AddToCounter(MetricsType::TOTAL_MEMORY_ALLOCATED, size);
 		}
 	}
 
diff --git a/src/main/database_manager.cpp b/src/main/database_manager.cpp
index 71130574a2..c5ac5ac6f1 100644
--- a/src/main/database_manager.cpp
+++ b/src/main/database_manager.cpp
@@ -86,7 +86,8 @@ shared_ptr<AttachedDatabase> DatabaseManager::AttachDatabase(ClientContext &cont
                                                              AttachOptions &options) {
 	if (options.db_type.empty() || StringUtil::CIEquals(options.db_type, "duckdb")) {
 		// Start timing the ATTACH-delay step.
-		auto profiler = context.client_data->profiler->StartTimer(MetricType::WAITING_TO_ATTACH_LATENCY);
+		auto profiler = context.client_data->profiler;
+		profiler->StartTimer(MetricsType::WAITING_TO_ATTACH_LATENCY);
 
 		while (InsertDatabasePath(info, options) == InsertDatabasePathResult::ALREADY_EXISTS) {
 			// database with this name and path already exists
@@ -94,6 +95,7 @@ shared_ptr<AttachedDatabase> DatabaseManager::AttachDatabase(ClientContext &cont
 			auto &meta_transaction = MetaTransaction::Get(context);
 			auto existing_db = meta_transaction.GetReferencedDatabaseOwning(info.name);
 			if (existing_db) {
+				profiler->EndTimer(MetricsType::WAITING_TO_ATTACH_LATENCY);
 				// it does! return it
 				return existing_db;
 			}
@@ -104,12 +106,15 @@ shared_ptr<AttachedDatabase> DatabaseManager::AttachDatabase(ClientContext &cont
 			auto entry = databases.find(info.name);
 			if (entry != databases.end()) {
 				// The database ACTUALLY exists, so we return it.
+				profiler->EndTimer(MetricsType::WAITING_TO_ATTACH_LATENCY);
 				return entry->second;
 			}
 			if (context.interrupted) {
+				profiler->EndTimer(MetricsType::WAITING_TO_ATTACH_LATENCY);
 				throw InterruptException();
 			}
 		}
+		profiler->EndTimer(MetricsType::WAITING_TO_ATTACH_LATENCY);
 	}
 
 	auto &config = DBConfig::GetConfig(context);
diff --git a/src/main/profiling_info.cpp b/src/main/profiling_info.cpp
index 55c40fdcec..d2cf133440 100644
--- a/src/main/profiling_info.cpp
+++ b/src/main/profiling_info.cpp
@@ -1,7 +1,7 @@
 #include "duckdb/main/profiling_info.hpp"
 
 #include "duckdb/common/enum_util.hpp"
-#include "duckdb/main/profiling_utils.hpp"
+#include "duckdb/main/query_profiler.hpp"
 #include "duckdb/logging/log_manager.hpp"
 
 #include "yyjson.hpp"
@@ -13,10 +13,10 @@ namespace duckdb {
 ProfilingInfo::ProfilingInfo(const profiler_settings_t &n_settings, const idx_t depth) : settings(n_settings) {
 	// Expand.
 	if (depth == 0) {
-		settings.insert(MetricType::QUERY_NAME);
+		settings.insert(MetricsType::QUERY_NAME);
 	} else {
-		settings.insert(MetricType::OPERATOR_NAME);
-		settings.insert(MetricType::OPERATOR_TYPE);
+		settings.insert(MetricsType::OPERATOR_NAME);
+		settings.insert(MetricsType::OPERATOR_TYPE);
 	}
 	for (const auto &metric : settings) {
 		Expand(expanded_settings, metric);
@@ -24,12 +24,12 @@ ProfilingInfo::ProfilingInfo(const profiler_settings_t &n_settings, const idx_t
 
 	// Reduce.
 	if (depth == 0) {
-		auto op_metrics = MetricsUtils::GetOperatorMetrics();
+		auto op_metrics = OperatorScopeSettings();
 		for (const auto metric : op_metrics) {
 			settings.erase(metric);
 		}
 	} else {
-		auto root_metrics = MetricsUtils::GetRootScopeMetrics();
+		auto root_metrics = RootScopeSettings();
 		for (const auto metric : root_metrics) {
 			settings.erase(metric);
 		}
@@ -37,6 +37,56 @@ ProfilingInfo::ProfilingInfo(const profiler_settings_t &n_settings, const idx_t
 	ResetMetrics();
 }
 
+profiler_settings_t ProfilingInfo::DefaultSettings() {
+	return {MetricsType::ATTACH_LOAD_STORAGE_LATENCY,
+	        MetricsType::ATTACH_REPLAY_WAL_LATENCY,
+	        MetricsType::BLOCKED_THREAD_TIME,
+	        MetricsType::CHECKPOINT_LATENCY,
+	        MetricsType::CPU_TIME,
+	        MetricsType::CUMULATIVE_CARDINALITY,
+	        MetricsType::CUMULATIVE_ROWS_SCANNED,
+	        MetricsType::EXTRA_INFO,
+	        MetricsType::LATENCY,
+	        MetricsType::OPERATOR_CARDINALITY,
+	        MetricsType::OPERATOR_NAME,
+	        MetricsType::OPERATOR_ROWS_SCANNED,
+	        MetricsType::OPERATOR_TIMING,
+	        MetricsType::OPERATOR_TYPE,
+	        MetricsType::RESULT_SET_SIZE,
+	        MetricsType::ROWS_RETURNED,
+	        MetricsType::SYSTEM_PEAK_BUFFER_MEMORY,
+	        MetricsType::SYSTEM_PEAK_TEMP_DIR_SIZE,
+	        MetricsType::TOTAL_BYTES_READ,
+	        MetricsType::TOTAL_BYTES_WRITTEN,
+	        MetricsType::TOTAL_MEMORY_ALLOCATED,
+	        MetricsType::WAITING_TO_ATTACH_LATENCY,
+	        MetricsType::WAL_REPLAY_ENTRY_COUNT,
+	        MetricsType::COMMIT_LOCAL_STORAGE_LATENCY,
+	        MetricsType::WRITE_TO_WAL_LATENCY,
+	        MetricsType::QUERY_NAME};
+}
+
+profiler_settings_t ProfilingInfo::RootScopeSettings() {
+	return {MetricsType::ATTACH_LOAD_STORAGE_LATENCY,
+	        MetricsType::ATTACH_REPLAY_WAL_LATENCY,
+	        MetricsType::BLOCKED_THREAD_TIME,
+	        MetricsType::CHECKPOINT_LATENCY,
+	        MetricsType::LATENCY,
+	        MetricsType::ROWS_RETURNED,
+	        MetricsType::TOTAL_BYTES_READ,
+	        MetricsType::TOTAL_BYTES_WRITTEN,
+	        MetricsType::WAITING_TO_ATTACH_LATENCY,
+	        MetricsType::WAL_REPLAY_ENTRY_COUNT,
+	        MetricsType::COMMIT_LOCAL_STORAGE_LATENCY,
+	        MetricsType::WRITE_TO_WAL_LATENCY,
+	        MetricsType::QUERY_NAME};
+}
+
+profiler_settings_t ProfilingInfo::OperatorScopeSettings() {
+	return {MetricsType::OPERATOR_CARDINALITY, MetricsType::OPERATOR_ROWS_SCANNED, MetricsType::OPERATOR_TIMING,
+	        MetricsType::OPERATOR_NAME, MetricsType::OPERATOR_TYPE};
+}
+
 void ProfilingInfo::ResetMetrics() {
 	metrics.clear();
 	for (auto &metric : expanded_settings) {
@@ -45,32 +95,73 @@ void ProfilingInfo::ResetMetrics() {
 			continue;
 		}
 
-		ProfilingUtils::SetMetricToDefault(metrics, metric);
+		switch (metric) {
+		case MetricsType::QUERY_NAME:
+			metrics[metric] = Value::CreateValue("");
+			break;
+		case MetricsType::LATENCY:
+		case MetricsType::BLOCKED_THREAD_TIME:
+		case MetricsType::CPU_TIME:
+		case MetricsType::OPERATOR_TIMING:
+		case MetricsType::WAITING_TO_ATTACH_LATENCY:
+		case MetricsType::ATTACH_LOAD_STORAGE_LATENCY:
+		case MetricsType::ATTACH_REPLAY_WAL_LATENCY:
+		case MetricsType::CHECKPOINT_LATENCY:
+		case MetricsType::COMMIT_LOCAL_STORAGE_LATENCY:
+		case MetricsType::WRITE_TO_WAL_LATENCY:
+			metrics[metric] = Value::CreateValue(0.0);
+			break;
+		case MetricsType::OPERATOR_NAME:
+			metrics[metric] = Value::CreateValue("");
+			break;
+		case MetricsType::OPERATOR_TYPE:
+			metrics[metric] = Value::CreateValue<uint8_t>(0);
+			break;
+		case MetricsType::ROWS_RETURNED:
+		case MetricsType::RESULT_SET_SIZE:
+		case MetricsType::CUMULATIVE_CARDINALITY:
+		case MetricsType::OPERATOR_CARDINALITY:
+		case MetricsType::CUMULATIVE_ROWS_SCANNED:
+		case MetricsType::OPERATOR_ROWS_SCANNED:
+		case MetricsType::SYSTEM_PEAK_BUFFER_MEMORY:
+		case MetricsType::SYSTEM_PEAK_TEMP_DIR_SIZE:
+		case MetricsType::TOTAL_BYTES_READ:
+		case MetricsType::TOTAL_BYTES_WRITTEN:
+		case MetricsType::TOTAL_MEMORY_ALLOCATED:
+		case MetricsType::WAL_REPLAY_ENTRY_COUNT:
+			metrics[metric] = Value::CreateValue<uint64_t>(0);
+			break;
+		case MetricsType::EXTRA_INFO:
+			metrics[metric] = Value::MAP(InsertionOrderPreservingMap<string>());
+			break;
+		default:
+			throw InternalException("MetricsType" + EnumUtil::ToString(metric) + "not implemented");
+		}
 	}
 }
 
-bool ProfilingInfo::Enabled(const profiler_settings_t &settings, const MetricType metric) {
+bool ProfilingInfo::Enabled(const profiler_settings_t &settings, const MetricsType metric) {
 	if (settings.find(metric) != settings.end()) {
 		return true;
 	}
 	return false;
 }
 
-void ProfilingInfo::Expand(profiler_settings_t &settings, const MetricType metric) {
+void ProfilingInfo::Expand(profiler_settings_t &settings, const MetricsType metric) {
 	settings.insert(metric);
 
 	switch (metric) {
-	case MetricType::CPU_TIME:
-		settings.insert(MetricType::OPERATOR_TIMING);
+	case MetricsType::CPU_TIME:
+		settings.insert(MetricsType::OPERATOR_TIMING);
 		return;
-	case MetricType::CUMULATIVE_CARDINALITY:
-		settings.insert(MetricType::OPERATOR_CARDINALITY);
+	case MetricsType::CUMULATIVE_CARDINALITY:
+		settings.insert(MetricsType::OPERATOR_CARDINALITY);
 		return;
-	case MetricType::CUMULATIVE_ROWS_SCANNED:
-		settings.insert(MetricType::OPERATOR_ROWS_SCANNED);
+	case MetricsType::CUMULATIVE_ROWS_SCANNED:
+		settings.insert(MetricsType::OPERATOR_ROWS_SCANNED);
 		return;
-	case MetricType::CUMULATIVE_OPTIMIZER_TIMING:
-	case MetricType::ALL_OPTIMIZERS: {
+	case MetricsType::CUMULATIVE_OPTIMIZER_TIMING:
+	case MetricsType::ALL_OPTIMIZERS: {
 		auto optimizer_metrics = MetricsUtils::GetOptimizerMetrics();
 		for (const auto optimizer_metric : optimizer_metrics) {
 			settings.insert(optimizer_metric);
@@ -82,14 +173,14 @@ void ProfilingInfo::Expand(profiler_settings_t &settings, const MetricType metri
 	}
 }
 
-string ProfilingInfo::GetMetricAsString(const MetricType metric) const {
+string ProfilingInfo::GetMetricAsString(const MetricsType metric) const {
 	if (!Enabled(settings, metric)) {
 		throw InternalException("Metric %s not enabled", EnumUtil::ToString(metric));
 	}
 
 	// The metric cannot be NULL and must be initialized.
 	D_ASSERT(!metrics.at(metric).IsNull());
-	if (metric == MetricType::OPERATOR_TYPE) {
+	if (metric == MetricsType::OPERATOR_TYPE) {
 		const auto type = PhysicalOperatorType(metrics.at(metric).GetValue<uint8_t>());
 		return EnumUtil::ToString(type);
 	}
@@ -112,7 +203,7 @@ void ProfilingInfo::WriteMetricsToJSON(yyjson_mut_doc *doc, yyjson_mut_val *dest
 		auto key_val = yyjson_mut_strcpy(doc, metric_str.c_str());
 		auto key_ptr = yyjson_mut_get_str(key_val);
 
-		if (metric == MetricType::EXTRA_INFO) {
+		if (metric == MetricsType::EXTRA_INFO) {
 			auto extra_info_obj = yyjson_mut_obj(doc);
 
 			auto extra_info = metrics.at(metric);
@@ -148,7 +239,46 @@ void ProfilingInfo::WriteMetricsToJSON(yyjson_mut_doc *doc, yyjson_mut_val *dest
 			continue;
 		}
 
-		ProfilingUtils::MetricToJson(doc, dest, key_ptr, metrics, metric);
+		switch (metric) {
+		case MetricsType::QUERY_NAME:
+		case MetricsType::OPERATOR_NAME:
+			yyjson_mut_obj_add_strcpy(doc, dest, key_ptr, metrics[metric].GetValue<string>().c_str());
+			break;
+		case MetricsType::LATENCY:
+		case MetricsType::BLOCKED_THREAD_TIME:
+		case MetricsType::CPU_TIME:
+		case MetricsType::OPERATOR_TIMING:
+		case MetricsType::WAITING_TO_ATTACH_LATENCY:
+		case MetricsType::ATTACH_LOAD_STORAGE_LATENCY:
+		case MetricsType::ATTACH_REPLAY_WAL_LATENCY:
+		case MetricsType::COMMIT_LOCAL_STORAGE_LATENCY:
+		case MetricsType::WRITE_TO_WAL_LATENCY:
+		case MetricsType::CHECKPOINT_LATENCY: {
+			yyjson_mut_obj_add_real(doc, dest, key_ptr, metrics[metric].GetValue<double>());
+			break;
+		}
+		case MetricsType::OPERATOR_TYPE: {
+			yyjson_mut_obj_add_strcpy(doc, dest, key_ptr, GetMetricAsString(metric).c_str());
+			break;
+		}
+		case MetricsType::ROWS_RETURNED:
+		case MetricsType::RESULT_SET_SIZE:
+		case MetricsType::CUMULATIVE_CARDINALITY:
+		case MetricsType::OPERATOR_CARDINALITY:
+		case MetricsType::CUMULATIVE_ROWS_SCANNED:
+		case MetricsType::OPERATOR_ROWS_SCANNED:
+		case MetricsType::SYSTEM_PEAK_BUFFER_MEMORY:
+		case MetricsType::SYSTEM_PEAK_TEMP_DIR_SIZE:
+		case MetricsType::WAL_REPLAY_ENTRY_COUNT:
+		case MetricsType::TOTAL_BYTES_READ:
+		case MetricsType::TOTAL_BYTES_WRITTEN:
+		case MetricsType::TOTAL_MEMORY_ALLOCATED: {
+			yyjson_mut_obj_add_uint(doc, dest, key_ptr, metrics[metric].GetValue<uint64_t>());
+			break;
+		}
+		default:
+			throw NotImplementedException("MetricsType %s not implemented", EnumUtil::ToString(metric));
+		}
 	}
 }
 
diff --git a/src/main/profiling_utils.cpp b/src/main/profiling_utils.cpp
deleted file mode 100644
index bf71fec93e..0000000000
--- a/src/main/profiling_utils.cpp
+++ /dev/null
@@ -1,215 +0,0 @@
-// This file is automatically generated by scripts/generate_metric_enums.py
-// Do not edit this file manually, your changes will be overwritten
-
-#include "duckdb/main/profiling_utils.hpp"
-#include "duckdb/common/enum_util.hpp"
-#include "duckdb/main/profiling_node.hpp"
-#include "duckdb/main/query_profiler.hpp"
-
-#include "yyjson.hpp"
-
-using namespace duckdb_yyjson; // NOLINT
-
-namespace duckdb {
-
-static string OperatorToString(const Value &val) {
-    const auto type = static_cast<PhysicalOperatorType>(val.GetValue<uint8_t>());
-    return EnumUtil::ToString(type);
-}
-
-template <class METRIC_TYPE>
-static void AggregateMetric(ProfilingNode &node, MetricType aggregated_metric, MetricType child_metric, const std::function<METRIC_TYPE(const METRIC_TYPE &, const METRIC_TYPE &)> &update_fun) {
-	auto &info = node.GetProfilingInfo();
-	info.metrics[aggregated_metric] = info.metrics[child_metric];
-
-	for (idx_t i = 0; i < node.GetChildCount(); i++) {
-		auto child = node.GetChild(i);
-		AggregateMetric<METRIC_TYPE>(*child, aggregated_metric, child_metric, update_fun);
-
-		auto &child_info = child->GetProfilingInfo();
-		auto value = child_info.GetMetricValue<METRIC_TYPE>(aggregated_metric);
-		info.MetricUpdate<METRIC_TYPE>(aggregated_metric, value, update_fun);
-	}
-}
-
-template <class METRIC_TYPE>
-static void GetCumulativeMetric(ProfilingNode &node, MetricType cumulative_metric, MetricType child_metric) {
-	AggregateMetric<METRIC_TYPE>(
-	    node, cumulative_metric, child_metric,
-	    [](const METRIC_TYPE &old_value, const METRIC_TYPE &new_value) { return old_value + new_value; });
-}
-
-static Value GetCumulativeOptimizers(ProfilingNode &node) {
-	auto &metrics = node.GetProfilingInfo().metrics;
-	double count = 0;
-	for (auto &metric : metrics) {
-		if (MetricsUtils::IsOptimizerMetric(metric.first)) {
-			count += metric.second.GetValue<double>();
-		}
-	}
-	return Value::CreateValue(count);
-}
-
-void ProfilingUtils::SetMetricToDefault(profiler_metrics_t &metrics, const MetricType &type) {
-	switch(type) {
-	case MetricType::ALL_OPTIMIZERS:
-	case MetricType::ATTACH_LOAD_STORAGE_LATENCY:
-	case MetricType::ATTACH_REPLAY_WAL_LATENCY:
-	case MetricType::BLOCKED_THREAD_TIME:
-	case MetricType::CHECKPOINT_LATENCY:
-	case MetricType::COMMIT_LOCAL_STORAGE_LATENCY:
-	case MetricType::CPU_TIME:
-	case MetricType::CUMULATIVE_OPTIMIZER_TIMING:
-	case MetricType::LATENCY:
-	case MetricType::OPERATOR_TIMING:
-	case MetricType::PHYSICAL_PLANNER:
-	case MetricType::PHYSICAL_PLANNER_COLUMN_BINDING:
-	case MetricType::PHYSICAL_PLANNER_CREATE_PLAN:
-	case MetricType::PHYSICAL_PLANNER_RESOLVE_TYPES:
-	case MetricType::PLANNER:
-	case MetricType::PLANNER_BINDING:
-	case MetricType::WAITING_TO_ATTACH_LATENCY:
-	case MetricType::WRITE_TO_WAL_LATENCY:
-		metrics[type] = Value::CreateValue(0.0);
-		break;
-	case MetricType::CUMULATIVE_CARDINALITY:
-	case MetricType::CUMULATIVE_ROWS_SCANNED:
-	case MetricType::OPERATOR_CARDINALITY:
-	case MetricType::OPERATOR_ROWS_SCANNED:
-	case MetricType::RESULT_SET_SIZE:
-	case MetricType::ROWS_RETURNED:
-	case MetricType::SYSTEM_PEAK_BUFFER_MEMORY:
-	case MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE:
-	case MetricType::TOTAL_BYTES_READ:
-	case MetricType::TOTAL_BYTES_WRITTEN:
-	case MetricType::TOTAL_MEMORY_ALLOCATED:
-	case MetricType::WAL_REPLAY_ENTRY_COUNT:
-		metrics[type] = Value::CreateValue<uint64_t>(0);
-		break;
-	case MetricType::EXTRA_INFO:
-		metrics[type] = Value::MAP(InsertionOrderPreservingMap<string>());
-		break;
-	case MetricType::OPERATOR_NAME:
-	case MetricType::QUERY_NAME:
-		metrics[type] = Value::CreateValue("");
-		break;
-	case MetricType::OPERATOR_TYPE:
-		metrics[type] = Value::CreateValue<uint8_t>(0);
-		break;
-	default:
-		throw InternalException("Unknown metric type %s", EnumUtil::ToString(type));
-	}
-}
-
-void ProfilingUtils::MetricToJson(duckdb_yyjson::yyjson_mut_doc *doc, duckdb_yyjson::yyjson_mut_val *dest, const char *key_ptr,  profiler_metrics_t &metrics, const MetricType &type) {
-	switch(type) {
-	case MetricType::ALL_OPTIMIZERS:
-	case MetricType::ATTACH_LOAD_STORAGE_LATENCY:
-	case MetricType::ATTACH_REPLAY_WAL_LATENCY:
-	case MetricType::BLOCKED_THREAD_TIME:
-	case MetricType::CHECKPOINT_LATENCY:
-	case MetricType::COMMIT_LOCAL_STORAGE_LATENCY:
-	case MetricType::CPU_TIME:
-	case MetricType::CUMULATIVE_OPTIMIZER_TIMING:
-	case MetricType::LATENCY:
-	case MetricType::OPERATOR_TIMING:
-	case MetricType::PHYSICAL_PLANNER:
-	case MetricType::PHYSICAL_PLANNER_COLUMN_BINDING:
-	case MetricType::PHYSICAL_PLANNER_CREATE_PLAN:
-	case MetricType::PHYSICAL_PLANNER_RESOLVE_TYPES:
-	case MetricType::PLANNER:
-	case MetricType::PLANNER_BINDING:
-	case MetricType::WAITING_TO_ATTACH_LATENCY:
-	case MetricType::WRITE_TO_WAL_LATENCY:
-		yyjson_mut_obj_add_real(doc, dest, key_ptr, metrics[type].GetValue<double>());
-		break;
-	case MetricType::CUMULATIVE_CARDINALITY:
-	case MetricType::CUMULATIVE_ROWS_SCANNED:
-	case MetricType::OPERATOR_CARDINALITY:
-	case MetricType::OPERATOR_ROWS_SCANNED:
-	case MetricType::RESULT_SET_SIZE:
-	case MetricType::ROWS_RETURNED:
-	case MetricType::SYSTEM_PEAK_BUFFER_MEMORY:
-	case MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE:
-	case MetricType::TOTAL_BYTES_READ:
-	case MetricType::TOTAL_BYTES_WRITTEN:
-	case MetricType::TOTAL_MEMORY_ALLOCATED:
-	case MetricType::WAL_REPLAY_ENTRY_COUNT:
-		yyjson_mut_obj_add_uint(doc, dest, key_ptr, metrics[type].GetValue<uint64_t>());
-		break;
-	case MetricType::EXTRA_INFO:
-		break;
-	case MetricType::OPERATOR_NAME:
-	case MetricType::QUERY_NAME:
-		yyjson_mut_obj_add_strcpy(doc, dest, key_ptr, metrics[type].GetValue<string>().c_str());
-		break;
-	case MetricType::OPERATOR_TYPE:
-		yyjson_mut_obj_add_strcpy(doc, dest, key_ptr, OperatorToString(metrics[type]).c_str());
-		break;
-	default:
-		throw InternalException("Unknown metric type %s", EnumUtil::ToString(type));
-	}
-}
-
-void ProfilingUtils::CollectMetrics(const MetricType &type, QueryMetrics &query_metrics, Value &metric, ProfilingNode &node, ProfilingInfo &child_info) {
-	switch(type) {
-	case MetricType::CPU_TIME:
-		GetCumulativeMetric<double>(node, MetricType::CPU_TIME, MetricType::OPERATOR_TIMING);
-		break;
-	case MetricType::CUMULATIVE_CARDINALITY:
-		GetCumulativeMetric<uint64_t>(node, MetricType::CUMULATIVE_CARDINALITY, MetricType::OPERATOR_CARDINALITY);
-		break;
-	case MetricType::CUMULATIVE_ROWS_SCANNED:
-		GetCumulativeMetric<uint64_t>(node, MetricType::CUMULATIVE_ROWS_SCANNED, MetricType::OPERATOR_ROWS_SCANNED);
-		break;
-	case MetricType::ATTACH_LOAD_STORAGE_LATENCY:
-		metric = Value::DOUBLE(query_metrics.attach_load_storage_latency);
-		break;
-	case MetricType::ATTACH_REPLAY_WAL_LATENCY:
-		metric = Value::DOUBLE(query_metrics.attach_replay_wal_latency);
-		break;
-	case MetricType::CHECKPOINT_LATENCY:
-		metric = Value::DOUBLE(query_metrics.checkpoint_latency);
-		break;
-	case MetricType::COMMIT_LOCAL_STORAGE_LATENCY:
-		metric = Value::DOUBLE(query_metrics.commit_local_storage_latency);
-		break;
-	case MetricType::LATENCY:
-		metric = Value::DOUBLE(query_metrics.latency);
-		break;
-	case MetricType::WAITING_TO_ATTACH_LATENCY:
-		metric = Value::DOUBLE(query_metrics.waiting_to_attach_latency);
-		break;
-	case MetricType::WRITE_TO_WAL_LATENCY:
-		metric = Value::DOUBLE(query_metrics.write_to_wal_latency);
-		break;
-	case MetricType::QUERY_NAME:
-		metric = query_metrics.query_name;
-		break;
-	case MetricType::TOTAL_BYTES_READ:
-		metric = Value::UBIGINT(query_metrics.total_bytes_read);
-		break;
-	case MetricType::TOTAL_BYTES_WRITTEN:
-		metric = Value::UBIGINT(query_metrics.total_bytes_written);
-		break;
-	case MetricType::TOTAL_MEMORY_ALLOCATED:
-		metric = Value::UBIGINT(query_metrics.total_memory_allocated);
-		break;
-	case MetricType::WAL_REPLAY_ENTRY_COUNT:
-		metric = Value::UBIGINT(query_metrics.wal_replay_entry_count);
-		break;
-	case MetricType::RESULT_SET_SIZE:
-		metric = child_info.metrics[MetricType::RESULT_SET_SIZE];
-		break;
-	case MetricType::ROWS_RETURNED:
-		metric = child_info.metrics[MetricType::OPERATOR_CARDINALITY];
-		break;
-	case MetricType::CUMULATIVE_OPTIMIZER_TIMING:
-		metric = GetCumulativeOptimizers(node);
-		break;
-	default:
-		return;
-	}
-}
-
-}
diff --git a/src/main/profiling_utils.cpp.template b/src/main/profiling_utils.cpp.template
deleted file mode 100644
index 03da483ffd..0000000000
--- a/src/main/profiling_utils.cpp.template
+++ /dev/null
@@ -1,45 +0,0 @@
-// !!!!!!!
-// WARNING: this file is used for function generation by scripts/generate_metric_enums.py after modifying the code below, rerun
-//          the script to apply changes to the generated files
-// !!!!!!!
-
-// DUCKDB_START_OF_FILE
-
-static string OperatorToString(const Value &val) {
-    const auto type = static_cast<PhysicalOperatorType>(val.GetValue<uint8_t>());
-    return EnumUtil::ToString(type);
-}
-
-template <class METRIC_TYPE>
-static void AggregateMetric(ProfilingNode &node, MetricType aggregated_metric, MetricType child_metric, const std::function<METRIC_TYPE(const METRIC_TYPE &, const METRIC_TYPE &)> &update_fun) {
-	auto &info = node.GetProfilingInfo();
-	info.metrics[aggregated_metric] = info.metrics[child_metric];
-
-	for (idx_t i = 0; i < node.GetChildCount(); i++) {
-		auto child = node.GetChild(i);
-		AggregateMetric<METRIC_TYPE>(*child, aggregated_metric, child_metric, update_fun);
-
-		auto &child_info = child->GetProfilingInfo();
-		auto value = child_info.GetMetricValue<METRIC_TYPE>(aggregated_metric);
-		info.MetricUpdate<METRIC_TYPE>(aggregated_metric, value, update_fun);
-	}
-}
-
-template <class METRIC_TYPE>
-static void GetCumulativeMetric(ProfilingNode &node, MetricType cumulative_metric, MetricType child_metric) {
-	AggregateMetric<METRIC_TYPE>(
-	    node, cumulative_metric, child_metric,
-	    [](const METRIC_TYPE &old_value, const METRIC_TYPE &new_value) { return old_value + new_value; });
-}
-
-static Value GetCumulativeOptimizers(ProfilingNode &node) {
-	auto &metrics = node.GetProfilingInfo().metrics;
-	double count = 0;
-	for (auto &metric : metrics) {
-		if (MetricsUtils::IsOptimizerMetric(metric.first)) {
-			count += metric.second.GetValue<double>();
-		}
-	}
-	return Value::CreateValue(count);
-}
-
diff --git a/src/main/query_profiler.cpp b/src/main/query_profiler.cpp
index ae8324b483..3a40231c20 100644
--- a/src/main/query_profiler.cpp
+++ b/src/main/query_profiler.cpp
@@ -13,7 +13,6 @@
 #include "duckdb/main/client_config.hpp"
 #include "duckdb/main/client_context.hpp"
 #include "duckdb/main/client_data.hpp"
-#include "duckdb/main/profiling_utils.hpp"
 #include "duckdb/planner/expression/bound_function_expression.hpp"
 #include "duckdb/storage/buffer/buffer_pool.hpp"
 #include "yyjson.hpp"
@@ -98,8 +97,8 @@ QueryProfiler &QueryProfiler::Get(ClientContext &context) {
 void QueryProfiler::Start(const string &query) {
 	Reset();
 	running = true;
-	query_metrics.query_name = query;
-	query_metrics.latency_timer = make_uniq<ActiveTimer>(query_metrics, MetricType::LATENCY);
+	query_metrics.query = query;
+	query_metrics.latency.Start();
 }
 
 void QueryProfiler::Reset() {
@@ -181,12 +180,12 @@ void QueryProfiler::Finalize(ProfilingNode &node) {
 		Finalize(*child);
 
 		auto &info = node.GetProfilingInfo();
-		auto type = PhysicalOperatorType(info.GetMetricValue<uint8_t>(MetricType::OPERATOR_TYPE));
+		auto type = PhysicalOperatorType(info.GetMetricValue<uint8_t>(MetricsType::OPERATOR_TYPE));
 		if (type == PhysicalOperatorType::UNION &&
-		    info.Enabled(info.expanded_settings, MetricType::OPERATOR_CARDINALITY)) {
+		    info.Enabled(info.expanded_settings, MetricsType::OPERATOR_CARDINALITY)) {
 			auto &child_info = child->GetProfilingInfo();
-			auto value = child_info.metrics[MetricType::OPERATOR_CARDINALITY].GetValue<idx_t>();
-			info.MetricSum(MetricType::OPERATOR_CARDINALITY, value);
+			auto value = child_info.metrics[MetricsType::OPERATOR_CARDINALITY].GetValue<idx_t>();
+			info.MetricSum(MetricsType::OPERATOR_CARDINALITY, value);
 		}
 	}
 }
@@ -195,16 +194,50 @@ void QueryProfiler::StartExplainAnalyze() {
 	is_explain_analyze = true;
 }
 
+template <class METRIC_TYPE>
+static void AggregateMetric(ProfilingNode &node, MetricsType aggregated_metric, MetricsType child_metric,
+                            const std::function<METRIC_TYPE(const METRIC_TYPE &, const METRIC_TYPE &)> &update_fun) {
+	auto &info = node.GetProfilingInfo();
+	info.metrics[aggregated_metric] = info.metrics[child_metric];
+
+	for (idx_t i = 0; i < node.GetChildCount(); i++) {
+		auto child = node.GetChild(i);
+		AggregateMetric<METRIC_TYPE>(*child, aggregated_metric, child_metric, update_fun);
+
+		auto &child_info = child->GetProfilingInfo();
+		auto value = child_info.GetMetricValue<METRIC_TYPE>(aggregated_metric);
+		info.MetricUpdate<METRIC_TYPE>(aggregated_metric, value, update_fun);
+	}
+}
+
+template <class METRIC_TYPE>
+static void GetCumulativeMetric(ProfilingNode &node, MetricsType cumulative_metric, MetricsType child_metric) {
+	AggregateMetric<METRIC_TYPE>(
+	    node, cumulative_metric, child_metric,
+	    [](const METRIC_TYPE &old_value, const METRIC_TYPE &new_value) { return old_value + new_value; });
+}
+
+Value GetCumulativeOptimizers(ProfilingNode &node) {
+	auto &metrics = node.GetProfilingInfo().metrics;
+	double count = 0;
+	for (auto &metric : metrics) {
+		if (MetricsUtils::IsOptimizerMetric(metric.first)) {
+			count += metric.second.GetValue<double>();
+		}
+	}
+	return Value::CreateValue(count);
+}
+
 void QueryProfiler::EndQuery() {
 	unique_lock<std::mutex> guard(lock);
 	if (!IsEnabled() || !running) {
 		return;
 	}
 
-	query_metrics.latency_timer->EndTimer();
+	query_metrics.latency.End();
 	if (root) {
 		auto &info = root->GetProfilingInfo();
-		if (info.Enabled(info.expanded_settings, MetricType::OPERATOR_CARDINALITY)) {
+		if (info.Enabled(info.expanded_settings, MetricsType::OPERATOR_CARDINALITY)) {
 			Finalize(*root->GetChild(0));
 		}
 	}
@@ -218,18 +251,72 @@ void QueryProfiler::EndQuery() {
 			auto &info = root->GetProfilingInfo();
 			info = ProfilingInfo(ClientConfig::GetConfig(context).profiler_settings);
 			auto &child_info = root->children[0]->GetProfilingInfo();
-			info.metrics[MetricType::QUERY_NAME] = query_metrics.query_name;
+			info.metrics[MetricsType::QUERY_NAME] = query_metrics.query;
 
-			const auto &settings = info.expanded_settings;
+			auto &settings = info.expanded_settings;
 			for (const auto &global_info_entry : query_metrics.query_global_info.metrics) {
 				info.metrics[global_info_entry.first] = global_info_entry.second;
 			}
+			if (info.Enabled(settings, MetricsType::LATENCY)) {
+				info.metrics[MetricsType::LATENCY] = query_metrics.latency.Elapsed();
+			}
+			if (info.Enabled(settings, MetricsType::TOTAL_BYTES_READ)) {
+				info.metrics[MetricsType::TOTAL_BYTES_READ] = Value::UBIGINT(query_metrics.total_bytes_read);
+			}
+			if (info.Enabled(settings, MetricsType::TOTAL_BYTES_WRITTEN)) {
+				info.metrics[MetricsType::TOTAL_BYTES_WRITTEN] = Value::UBIGINT(query_metrics.total_bytes_written);
+			}
+			if (info.Enabled(settings, MetricsType::TOTAL_MEMORY_ALLOCATED)) {
+				info.metrics[MetricsType::TOTAL_MEMORY_ALLOCATED] =
+				    Value::UBIGINT(query_metrics.total_memory_allocated);
+			}
+			if (info.Enabled(settings, MetricsType::ROWS_RETURNED)) {
+				info.metrics[MetricsType::ROWS_RETURNED] = child_info.metrics[MetricsType::OPERATOR_CARDINALITY];
+			}
+			if (info.Enabled(settings, MetricsType::CPU_TIME)) {
+				GetCumulativeMetric<double>(*root, MetricsType::CPU_TIME, MetricsType::OPERATOR_TIMING);
+			}
+			if (info.Enabled(settings, MetricsType::CUMULATIVE_CARDINALITY)) {
+				GetCumulativeMetric<idx_t>(*root, MetricsType::CUMULATIVE_CARDINALITY,
+				                           MetricsType::OPERATOR_CARDINALITY);
+			}
+			if (info.Enabled(settings, MetricsType::CUMULATIVE_ROWS_SCANNED)) {
+				GetCumulativeMetric<idx_t>(*root, MetricsType::CUMULATIVE_ROWS_SCANNED,
+				                           MetricsType::OPERATOR_ROWS_SCANNED);
+			}
+			if (info.Enabled(settings, MetricsType::RESULT_SET_SIZE)) {
+				info.metrics[MetricsType::RESULT_SET_SIZE] = child_info.metrics[MetricsType::RESULT_SET_SIZE];
+			}
+			if (info.Enabled(settings, MetricsType::WAITING_TO_ATTACH_LATENCY)) {
+				info.metrics[MetricsType::WAITING_TO_ATTACH_LATENCY] =
+				    query_metrics.waiting_to_attach_latency.Elapsed();
+			}
+			if (info.Enabled(settings, MetricsType::ATTACH_LOAD_STORAGE_LATENCY)) {
+				info.metrics[MetricsType::ATTACH_LOAD_STORAGE_LATENCY] =
+				    query_metrics.attach_load_storage_latency.Elapsed();
+			}
+			if (info.Enabled(settings, MetricsType::ATTACH_REPLAY_WAL_LATENCY)) {
+				info.metrics[MetricsType::ATTACH_REPLAY_WAL_LATENCY] =
+				    query_metrics.attach_replay_wal_latency.Elapsed();
+			}
+			if (info.Enabled(settings, MetricsType::COMMIT_LOCAL_STORAGE_LATENCY)) {
+				info.metrics[MetricsType::COMMIT_LOCAL_STORAGE_LATENCY] =
+				    query_metrics.commit_local_storage_latency.Elapsed();
+			}
+			if (info.Enabled(settings, MetricsType::WRITE_TO_WAL_LATENCY)) {
+				info.metrics[MetricsType::WRITE_TO_WAL_LATENCY] = query_metrics.write_to_wal_latency.Elapsed();
+			}
+			if (info.Enabled(settings, MetricsType::WAL_REPLAY_ENTRY_COUNT)) {
+				info.metrics[MetricsType::WAL_REPLAY_ENTRY_COUNT] =
+				    Value::UBIGINT(query_metrics.wal_replay_entry_count);
+			}
+			if (info.Enabled(settings, MetricsType::CHECKPOINT_LATENCY)) {
+				info.metrics[MetricsType::CHECKPOINT_LATENCY] = query_metrics.checkpoint_latency.Elapsed();
+			}
 
 			MoveOptimizerPhasesToRoot();
-			for (auto &metric : info.metrics) {
-				if (info.Enabled(settings, metric.first)) {
-					ProfilingUtils::CollectMetrics(metric.first, query_metrics, metric.second, *root, child_info);
-				}
+			if (info.Enabled(settings, MetricsType::CUMULATIVE_OPTIMIZER_TIMING)) {
+				info.metrics.at(MetricsType::CUMULATIVE_OPTIMIZER_TIMING) = GetCumulativeOptimizers(*root);
 			}
 		}
 
@@ -258,9 +345,26 @@ void QueryProfiler::EndQuery() {
 	}
 }
 
-void QueryProfiler::AddToCounter(const MetricType type, const idx_t amount) {
-	if (IsEnabled()) {
-		query_metrics.AddToCounter(type, amount);
+void QueryProfiler::AddToCounter(const MetricsType type, const idx_t amount) {
+	if (!IsEnabled()) {
+		return;
+	}
+
+	switch (type) {
+	case MetricsType::TOTAL_BYTES_READ:
+		query_metrics.total_bytes_read += amount;
+		return;
+	case MetricsType::TOTAL_BYTES_WRITTEN:
+		query_metrics.total_bytes_written += amount;
+		return;
+	case MetricsType::TOTAL_MEMORY_ALLOCATED:
+		query_metrics.total_memory_allocated += amount;
+		return;
+	case MetricsType::WAL_REPLAY_ENTRY_COUNT:
+		query_metrics.wal_replay_entry_count += amount;
+		return;
+	default:
+		return;
 	}
 }
 
@@ -272,8 +376,62 @@ idx_t QueryProfiler::GetBytesWritten() const {
 	return query_metrics.total_bytes_written;
 }
 
-ActiveTimer QueryProfiler::StartTimer(const MetricType type) {
-	return ActiveTimer(query_metrics, type, IsEnabled());
+void QueryProfiler::StartTimer(const MetricsType type) {
+	if (!IsEnabled()) {
+		return;
+	}
+
+	switch (type) {
+	case MetricsType::WAITING_TO_ATTACH_LATENCY:
+		query_metrics.waiting_to_attach_latency.Start();
+		return;
+	case MetricsType::ATTACH_LOAD_STORAGE_LATENCY:
+		query_metrics.attach_load_storage_latency.Start();
+		return;
+	case MetricsType::ATTACH_REPLAY_WAL_LATENCY:
+		query_metrics.attach_replay_wal_latency.Start();
+		return;
+	case MetricsType::CHECKPOINT_LATENCY:
+		query_metrics.checkpoint_latency.Start();
+		return;
+	case MetricsType::COMMIT_LOCAL_STORAGE_LATENCY:
+		query_metrics.commit_local_storage_latency.Start();
+		return;
+	case MetricsType::WRITE_TO_WAL_LATENCY:
+		query_metrics.write_to_wal_latency.Start();
+		return;
+	default:
+		return;
+	}
+}
+
+void QueryProfiler::EndTimer(MetricsType type) {
+	if (!IsEnabled()) {
+		return;
+	}
+
+	switch (type) {
+	case MetricsType::WAITING_TO_ATTACH_LATENCY:
+		query_metrics.waiting_to_attach_latency.End();
+		return;
+	case MetricsType::ATTACH_LOAD_STORAGE_LATENCY:
+		query_metrics.attach_load_storage_latency.End();
+		return;
+	case MetricsType::ATTACH_REPLAY_WAL_LATENCY:
+		query_metrics.attach_replay_wal_latency.End();
+		return;
+	case MetricsType::CHECKPOINT_LATENCY:
+		query_metrics.checkpoint_latency.End();
+		return;
+	case MetricsType::COMMIT_LOCAL_STORAGE_LATENCY:
+		query_metrics.commit_local_storage_latency.End();
+		return;
+	case MetricsType::WRITE_TO_WAL_LATENCY:
+		query_metrics.write_to_wal_latency.End();
+		return;
+	default:
+		return;
+	}
 }
 
 string QueryProfiler::ToString(ExplainFormat explain_format) const {
@@ -298,11 +456,15 @@ string QueryProfiler::ToString(ProfilerPrintFormat format) const {
 		lock_guard<std::mutex> guard(lock);
 		// checking the tree to ensure the query is really empty
 		// the query string is empty when a logical plan is deserialized
-		if (query_metrics.query_name.empty() && !root) {
+		if (query_metrics.query.empty() && !root) {
 			return "";
 		}
 		auto renderer = TreeRenderer::CreateRenderer(GetExplainFormat(format));
-		stringstream str;
+		duckdb::stringstream str;
+		auto &info = root->GetProfilingInfo();
+		if (info.Enabled(info.expanded_settings, MetricsType::OPERATOR_TIMING)) {
+			info.metrics[MetricsType::OPERATOR_TIMING] = query_metrics.latency.Elapsed();
+		}
 		renderer->Render(*root, str);
 		return str.str();
 	}
@@ -311,7 +473,7 @@ string QueryProfiler::ToString(ProfilerPrintFormat format) const {
 	}
 }
 
-void QueryProfiler::StartPhase(MetricType phase_metric) {
+void QueryProfiler::StartPhase(MetricsType phase_metric) {
 	lock_guard<std::mutex> guard(lock);
 	if (!IsEnabled() || !running) {
 		return;
@@ -355,7 +517,7 @@ OperatorProfiler::OperatorProfiler(ClientContext &context) : context(context) {
 	}
 
 	// Reduce.
-	auto root_metrics = MetricsUtils::GetRootScopeMetrics();
+	auto root_metrics = ProfilingInfo::RootScopeSettings();
 	for (const auto metric : root_metrics) {
 		settings.erase(metric);
 	}
@@ -371,7 +533,7 @@ void OperatorProfiler::StartOperator(optional_ptr<const PhysicalOperator> phys_o
 	active_operator = phys_op;
 
 	if (!settings.empty()) {
-		if (ProfilingInfo::Enabled(settings, MetricType::EXTRA_INFO)) {
+		if (ProfilingInfo::Enabled(settings, MetricsType::EXTRA_INFO)) {
 			if (!OperatorInfoIsInitialized(*active_operator)) {
 				// first time calling into this operator - fetch the info
 				auto &info = GetOperatorInfo(*active_operator);
@@ -381,7 +543,7 @@ void OperatorProfiler::StartOperator(optional_ptr<const PhysicalOperator> phys_o
 		}
 
 		// Start the timing of the current operator.
-		if (ProfilingInfo::Enabled(settings, MetricType::OPERATOR_TIMING)) {
+		if (ProfilingInfo::Enabled(settings, MetricsType::OPERATOR_TIMING)) {
 			op.Start();
 		}
 	}
@@ -397,22 +559,22 @@ void OperatorProfiler::EndOperator(optional_ptr<DataChunk> chunk) {
 
 	if (!settings.empty()) {
 		auto &info = GetOperatorInfo(*active_operator);
-		if (ProfilingInfo::Enabled(settings, MetricType::OPERATOR_TIMING)) {
+		if (ProfilingInfo::Enabled(settings, MetricsType::OPERATOR_TIMING)) {
 			op.End();
 			info.AddTime(op.Elapsed());
 		}
-		if (ProfilingInfo::Enabled(settings, MetricType::OPERATOR_CARDINALITY) && chunk) {
+		if (ProfilingInfo::Enabled(settings, MetricsType::OPERATOR_CARDINALITY) && chunk) {
 			info.AddReturnedElements(chunk->size());
 		}
-		if (ProfilingInfo::Enabled(settings, MetricType::RESULT_SET_SIZE) && chunk) {
+		if (ProfilingInfo::Enabled(settings, MetricsType::RESULT_SET_SIZE) && chunk) {
 			auto result_set_size = chunk->GetAllocationSize();
 			info.AddResultSetSize(result_set_size);
 		}
-		if (ProfilingInfo::Enabled(settings, MetricType::SYSTEM_PEAK_BUFFER_MEMORY)) {
+		if (ProfilingInfo::Enabled(settings, MetricsType::SYSTEM_PEAK_BUFFER_MEMORY)) {
 			auto used_memory = BufferManager::GetBufferManager(context).GetBufferPool().GetUsedMemory(false);
 			info.UpdateSystemPeakBufferManagerMemory(used_memory);
 		}
-		if (ProfilingInfo::Enabled(settings, MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE)) {
+		if (ProfilingInfo::Enabled(settings, MetricsType::SYSTEM_PEAK_TEMP_DIR_SIZE)) {
 			auto used_swap = BufferManager::GetBufferManager(context).GetUsedSwap();
 			info.UpdateSystemPeakTempDirectorySize(used_swap);
 		}
@@ -428,7 +590,7 @@ void OperatorProfiler::FinishSource(GlobalSourceState &gstate, LocalSourceState
 		throw InternalException("OperatorProfiler: Attempting to call FinishSource while no operator is active");
 	}
 	if (!settings.empty()) {
-		if (ProfilingInfo::Enabled(settings, MetricType::EXTRA_INFO)) {
+		if (ProfilingInfo::Enabled(settings, MetricsType::EXTRA_INFO)) {
 			// we're emitting extra info - get the extra source info
 			auto &info = GetOperatorInfo(*active_operator);
 			auto extra_info = active_operator->ExtraSourceParams(gstate, lstate);
@@ -485,13 +647,13 @@ void QueryProfiler::Flush(OperatorProfiler &profiler) {
 		auto &tree_node = entry->second.get();
 		auto &info = tree_node.GetProfilingInfo();
 
-		if (ProfilingInfo::Enabled(profiler.settings, MetricType::OPERATOR_TIMING)) {
-			info.MetricSum<double>(MetricType::OPERATOR_TIMING, node.second.time);
+		if (ProfilingInfo::Enabled(profiler.settings, MetricsType::OPERATOR_TIMING)) {
+			info.MetricSum<double>(MetricsType::OPERATOR_TIMING, node.second.time);
 		}
-		if (ProfilingInfo::Enabled(profiler.settings, MetricType::OPERATOR_CARDINALITY)) {
-			info.MetricSum<idx_t>(MetricType::OPERATOR_CARDINALITY, node.second.elements_returned);
+		if (ProfilingInfo::Enabled(profiler.settings, MetricsType::OPERATOR_CARDINALITY)) {
+			info.MetricSum<idx_t>(MetricsType::OPERATOR_CARDINALITY, node.second.elements_returned);
 		}
-		if (ProfilingInfo::Enabled(profiler.settings, MetricType::OPERATOR_ROWS_SCANNED)) {
+		if (ProfilingInfo::Enabled(profiler.settings, MetricsType::OPERATOR_ROWS_SCANNED)) {
 			if (op.type == PhysicalOperatorType::TABLE_SCAN) {
 				auto &scan_op = op.Cast<PhysicalTableScan>();
 				auto &bind_data = scan_op.bind_data;
@@ -499,23 +661,23 @@ void QueryProfiler::Flush(OperatorProfiler &profiler) {
 				if (bind_data && scan_op.function.cardinality) {
 					auto cardinality = scan_op.function.cardinality(context, &(*bind_data));
 					if (cardinality && cardinality->has_estimated_cardinality) {
-						info.MetricSum<idx_t>(MetricType::OPERATOR_ROWS_SCANNED, cardinality->estimated_cardinality);
+						info.MetricSum<idx_t>(MetricsType::OPERATOR_ROWS_SCANNED, cardinality->estimated_cardinality);
 					}
 				}
 			}
 		}
-		if (ProfilingInfo::Enabled(profiler.settings, MetricType::RESULT_SET_SIZE)) {
-			info.MetricSum<idx_t>(MetricType::RESULT_SET_SIZE, node.second.result_set_size);
+		if (ProfilingInfo::Enabled(profiler.settings, MetricsType::RESULT_SET_SIZE)) {
+			info.MetricSum<idx_t>(MetricsType::RESULT_SET_SIZE, node.second.result_set_size);
 		}
-		if (ProfilingInfo::Enabled(profiler.settings, MetricType::EXTRA_INFO)) {
-			info.metrics[MetricType::EXTRA_INFO] = Value::MAP(node.second.extra_info);
+		if (ProfilingInfo::Enabled(profiler.settings, MetricsType::EXTRA_INFO)) {
+			info.metrics[MetricsType::EXTRA_INFO] = Value::MAP(node.second.extra_info);
 		}
-		if (ProfilingInfo::Enabled(profiler.settings, MetricType::SYSTEM_PEAK_BUFFER_MEMORY)) {
-			query_metrics.query_global_info.MetricMax(MetricType::SYSTEM_PEAK_BUFFER_MEMORY,
+		if (ProfilingInfo::Enabled(profiler.settings, MetricsType::SYSTEM_PEAK_BUFFER_MEMORY)) {
+			query_metrics.query_global_info.MetricMax(MetricsType::SYSTEM_PEAK_BUFFER_MEMORY,
 			                                          node.second.system_peak_buffer_manager_memory);
 		}
-		if (ProfilingInfo::Enabled(profiler.settings, MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE)) {
-			query_metrics.query_global_info.MetricMax(MetricType::SYSTEM_PEAK_TEMP_DIR_SIZE,
+		if (ProfilingInfo::Enabled(profiler.settings, MetricsType::SYSTEM_PEAK_TEMP_DIR_SIZE)) {
+			query_metrics.query_global_info.MetricMax(MetricsType::SYSTEM_PEAK_TEMP_DIR_SIZE,
 			                                          node.second.system_peak_temp_directory_size);
 		}
 	}
@@ -529,8 +691,8 @@ void QueryProfiler::SetBlockedTime(const double &blocked_thread_time) {
 	}
 
 	auto &info = root->GetProfilingInfo();
-	if (info.Enabled(info.expanded_settings, MetricType::BLOCKED_THREAD_TIME)) {
-		query_metrics.query_global_info.metrics[MetricType::BLOCKED_THREAD_TIME] = blocked_thread_time;
+	if (info.Enabled(info.expanded_settings, MetricsType::BLOCKED_THREAD_TIME)) {
+		query_metrics.query_global_info.metrics[MetricsType::BLOCKED_THREAD_TIME] = blocked_thread_time;
 	}
 }
 
@@ -607,15 +769,15 @@ void PrintPhaseTimingsToStream(std::ostream &ss, const ProfilingInfo &info, idx_
 			optimizer_timings[EnumUtil::ToString(entry.first).substr(10)] = entry.second.GetValue<double>();
 		} else if (MetricsUtils::IsPhaseTimingMetric(entry.first)) {
 			switch (entry.first) {
-			case MetricType::CUMULATIVE_OPTIMIZER_TIMING:
+			case MetricsType::CUMULATIVE_OPTIMIZER_TIMING:
 				continue;
-			case MetricType::ALL_OPTIMIZERS:
+			case MetricsType::ALL_OPTIMIZERS:
 				optimizer_head = {"Optimizer", entry.second.GetValue<double>()};
 				break;
-			case MetricType::PHYSICAL_PLANNER:
+			case MetricsType::PHYSICAL_PLANNER:
 				physical_planner_head = {"Physical Planner", entry.second.GetValue<double>()};
 				break;
-			case MetricType::PLANNER:
+			case MetricsType::PLANNER:
 				planner_head = {"Planner", entry.second.GetValue<double>()};
 				break;
 			default:
@@ -623,9 +785,9 @@ void PrintPhaseTimingsToStream(std::ostream &ss, const ProfilingInfo &info, idx_
 			}
 
 			auto metric = EnumUtil::ToString(entry.first);
-			if (StringUtil::StartsWith(metric, "PHYSICAL_PLANNER") && entry.first != MetricType::PHYSICAL_PLANNER) {
+			if (StringUtil::StartsWith(metric, "PHYSICAL_PLANNER") && entry.first != MetricsType::PHYSICAL_PLANNER) {
 				physical_planner_timings[metric.substr(17)] = entry.second.GetValue<double>();
-			} else if (StringUtil::StartsWith(metric, "PLANNER") && entry.first != MetricType::PLANNER) {
+			} else if (StringUtil::StartsWith(metric, "PLANNER") && entry.first != MetricsType::PLANNER) {
 				planner_timings[metric.substr(8)] = entry.second.GetValue<double>();
 			}
 		}
@@ -643,11 +805,11 @@ void QueryProfiler::QueryTreeToStream(std::ostream &ss) const {
 	ss << "││    Query Profiling Information    ││\n";
 	ss << "│└───────────────────────────────────┘│\n";
 	ss << "└─────────────────────────────────────┘\n";
-	ss << StringUtil::Replace(query_metrics.query_name, "\n", " ") + "\n";
+	ss << StringUtil::Replace(query_metrics.query, "\n", " ") + "\n";
 
 	// checking the tree to ensure the query is really empty
 	// the query string is empty when a logical plan is deserialized
-	if (query_metrics.query_name.empty() && !root) {
+	if (query_metrics.query.empty() && !root) {
 		return;
 	}
 
@@ -658,7 +820,7 @@ void QueryProfiler::QueryTreeToStream(std::ostream &ss) const {
 	constexpr idx_t TOTAL_BOX_WIDTH = 50;
 	ss << "┌────────────────────────────────────────────────┐\n";
 	ss << "│┌──────────────────────────────────────────────┐│\n";
-	string total_time = "Total Time: " + RenderTiming(query_metrics.latency);
+	string total_time = "Total Time: " + RenderTiming(query_metrics.latency.Elapsed());
 	ss << "││" + DrawPadded(total_time, TOTAL_BOX_WIDTH - 4) + "││\n";
 	ss << "│└──────────────────────────────────────────────┘│\n";
 	ss << "└────────────────────────────────────────────────┘\n";
@@ -730,9 +892,9 @@ static yyjson_mut_val *ToJSONRecursive(yyjson_mut_doc *doc, ProfilingNode &node)
 	auto result_obj = yyjson_mut_obj(doc);
 	auto &profiling_info = node.GetProfilingInfo();
 
-	if (profiling_info.Enabled(profiling_info.settings, MetricType::EXTRA_INFO)) {
-		profiling_info.metrics[MetricType::EXTRA_INFO] =
-		    QueryProfiler::JSONSanitize(profiling_info.metrics.at(MetricType::EXTRA_INFO));
+	if (profiling_info.Enabled(profiling_info.settings, MetricsType::EXTRA_INFO)) {
+		profiling_info.metrics[MetricsType::EXTRA_INFO] =
+		    QueryProfiler::JSONSanitize(profiling_info.metrics.at(MetricsType::EXTRA_INFO));
 	}
 
 	profiling_info.WriteMetricsToJSON(doc, result_obj);
@@ -777,7 +939,7 @@ string QueryProfiler::ToJSON() const {
 	auto result_obj = yyjson_mut_obj(json_holder.doc);
 	yyjson_mut_doc_set_root(json_holder.doc, result_obj);
 
-	if (query_metrics.query_name.empty() && !root) {
+	if (query_metrics.query.empty() && !root) {
 		yyjson_mut_obj_add_str(json_holder.doc, result_obj, "result", "empty");
 		return StringifyAndFree(json_holder, result_obj);
 	}
@@ -813,7 +975,7 @@ profiler_settings_t EraseQueryRootSettings(profiler_settings_t settings) {
 
 	for (auto &setting : settings) {
 		if (MetricsUtils::IsOptimizerMetric(setting) || MetricsUtils::IsPhaseTimingMetric(setting) ||
-		    MetricsUtils::IsRootScopeMetric(setting)) {
+		    MetricsUtils::IsQueryGlobalMetric(setting)) {
 			phase_timing_settings_to_erase.insert(setting);
 		}
 	}
@@ -841,11 +1003,11 @@ unique_ptr<ProfilingNode> QueryProfiler::CreateTree(const PhysicalOperator &root
 	node->depth = depth;
 
 	if (depth != 0) {
-		info.metrics[MetricType::OPERATOR_NAME] = root_p.GetName();
-		info.MetricSum<uint8_t>(MetricType::OPERATOR_TYPE, static_cast<uint8_t>(root_p.type));
+		info.metrics[MetricsType::OPERATOR_NAME] = root_p.GetName();
+		info.MetricSum<uint8_t>(MetricsType::OPERATOR_TYPE, static_cast<uint8_t>(root_p.type));
 	}
-	if (info.Enabled(info.settings, MetricType::EXTRA_INFO)) {
-		info.metrics[MetricType::EXTRA_INFO] = Value::MAP(root_p.ParamsToString());
+	if (info.Enabled(info.settings, MetricsType::EXTRA_INFO)) {
+		info.metrics[MetricsType::EXTRA_INFO] = Value::MAP(root_p.ParamsToString());
 	}
 
 	tree_map.insert(make_pair(reference<const PhysicalOperator>(root_p), reference<ProfilingNode>(*node)));
diff --git a/src/main/settings/custom_settings.cpp b/src/main/settings/custom_settings.cpp
index 63b5bdb4b3..44f4339542 100644
--- a/src/main/settings/custom_settings.cpp
+++ b/src/main/settings/custom_settings.cpp
@@ -369,7 +369,7 @@ Value CheckpointThresholdSetting::GetSetting(const ClientContext &context) {
 //===----------------------------------------------------------------------===//
 // Custom Profiling Settings
 //===----------------------------------------------------------------------===//
-bool IsEnabledOptimizer(MetricType metric, const set<OptimizerType> &disabled_optimizers) {
+bool IsEnabledOptimizer(MetricsType metric, const set<OptimizerType> &disabled_optimizers) {
 	auto matching_optimizer_type = MetricsUtils::GetOptimizerTypeByMetric(metric);
 	if (matching_optimizer_type != OptimizerType::INVALID &&
 	    disabled_optimizers.find(matching_optimizer_type) == disabled_optimizers.end()) {
@@ -378,39 +378,22 @@ bool IsEnabledOptimizer(MetricType metric, const set<OptimizerType> &disabled_op
 	return false;
 }
 
-static profiler_settings_t FillTreeNodeSettings(unordered_map<string, string> &input,
+static profiler_settings_t FillTreeNodeSettings(unordered_map<string, string> &json,
                                                 const set<OptimizerType> &disabled_optimizers) {
 	profiler_settings_t metrics;
 
 	string invalid_settings;
-	for (auto &entry : input) {
-		MetricType setting;
-		MetricGroup group = MetricGroup::INVALID;
+	for (auto &entry : json) {
+		MetricsType setting;
 		try {
-			setting = EnumUtil::FromString<MetricType>(StringUtil::Upper(entry.first));
+			setting = EnumUtil::FromString<MetricsType>(StringUtil::Upper(entry.first));
 		} catch (std::exception &ex) {
-			try {
-				group = EnumUtil::FromString<MetricGroup>(StringUtil::Upper(entry.first));
-			} catch (std::exception &ex) {
-				if (!invalid_settings.empty()) {
-					invalid_settings += ", ";
-				}
-				invalid_settings += entry.first;
-				continue;
-			}
-		}
-		if (group != MetricGroup::INVALID) {
-			if (entry.second == "true") {
-				auto group_metrics = MetricsUtils::GetMetricsByGroupType(group);
-				for (auto &metric : group_metrics) {
-					if (!MetricsUtils::IsOptimizerMetric(metric) || IsEnabledOptimizer(metric, disabled_optimizers)) {
-						metrics.insert(metric);
-					}
-				}
+			if (!invalid_settings.empty()) {
+				invalid_settings += ", ";
 			}
+			invalid_settings += entry.first;
 			continue;
 		}
-
 		if (StringUtil::Lower(entry.second) == "true" &&
 		    (!MetricsUtils::IsOptimizerMetric(setting) || IsEnabledOptimizer(setting, disabled_optimizers))) {
 			metrics.insert(setting);
@@ -424,7 +407,7 @@ static profiler_settings_t FillTreeNodeSettings(unordered_map<string, string> &i
 }
 
 void AddOptimizerMetrics(profiler_settings_t &settings, const set<OptimizerType> &disabled_optimizers) {
-	if (settings.find(MetricType::ALL_OPTIMIZERS) != settings.end()) {
+	if (settings.find(MetricsType::ALL_OPTIMIZERS) != settings.end()) {
 		auto optimizer_metrics = MetricsUtils::GetOptimizerMetrics();
 		for (auto &metric : optimizer_metrics) {
 			if (IsEnabledOptimizer(metric, disabled_optimizers)) {
@@ -438,9 +421,9 @@ void CustomProfilingSettingsSetting::SetLocal(ClientContext &context, const Valu
 	auto &config = ClientConfig::GetConfig(context);
 
 	// parse the file content
-	unordered_map<string, string> input_json;
+	unordered_map<string, string> json;
 	try {
-		input_json = StringUtil::ParseJSONMap(input.ToString())->Flatten();
+		json = StringUtil::ParseJSONMap(input.ToString())->Flatten();
 	} catch (std::exception &ex) {
 		throw IOException("Could not parse the custom profiler settings file due to incorrect JSON: \"%s\".  Make sure "
 		                  "all the keys and values start with a quote. ",
@@ -451,7 +434,7 @@ void CustomProfilingSettingsSetting::SetLocal(ClientContext &context, const Valu
 	auto &db_config = DBConfig::GetConfig(context);
 	auto &disabled_optimizers = db_config.options.disabled_optimizers;
 
-	auto settings = FillTreeNodeSettings(input_json, disabled_optimizers);
+	auto settings = FillTreeNodeSettings(json, disabled_optimizers);
 	AddOptimizerMetrics(settings, disabled_optimizers);
 	config.profiler_settings = settings;
 }
@@ -459,7 +442,7 @@ void CustomProfilingSettingsSetting::SetLocal(ClientContext &context, const Valu
 void CustomProfilingSettingsSetting::ResetLocal(ClientContext &context) {
 	auto &config = ClientConfig::GetConfig(context);
 	config.enable_profiler = ClientConfig().enable_profiler;
-	config.profiler_settings = MetricsUtils::GetDefaultMetrics();
+	config.profiler_settings = ProfilingInfo::DefaultSettings();
 }
 
 Value CustomProfilingSettingsSetting::GetSetting(const ClientContext &context) {
@@ -1412,12 +1395,6 @@ void ProfilingModeSetting::SetLocal(ClientContext &context, const Value &input)
 		for (auto &setting : phase_timing_settings) {
 			config.profiler_settings.insert(setting);
 		}
-	} else if (parameter == "all") {
-		config.enable_profiler = true;
-		auto all_metrics = MetricsUtils::GetAllMetrics();
-		for (auto &metric : all_metrics) {
-			config.profiler_settings.insert(metric);
-		}
 	} else {
 		throw ParserException("Unrecognized profiling mode \"%s\", supported formats: [standard, detailed]", parameter);
 	}
diff --git a/src/planner/planner.cpp b/src/planner/planner.cpp
index ca5e72d88d..a38bc2a6cc 100644
--- a/src/planner/planner.cpp
+++ b/src/planner/planner.cpp
@@ -40,7 +40,7 @@ void Planner::CreatePlan(SQLStatement &statement) {
 	// first bind the tables and columns to the catalog
 	bool parameters_resolved = true;
 	try {
-		profiler.StartPhase(MetricType::PLANNER_BINDING);
+		profiler.StartPhase(MetricsType::PLANNER_BINDING);
 		binder->SetParameters(bound_parameters);
 		auto bound_statement = binder->Bind(statement);
 		profiler.EndPhase();
diff --git a/src/storage/storage_manager.cpp b/src/storage/storage_manager.cpp
index 16fb285394..d71b34a5d4 100644
--- a/src/storage/storage_manager.cpp
+++ b/src/storage/storage_manager.cpp
@@ -334,13 +334,11 @@ void SingleFileStorageManager::LoadDatabase(QueryContext context) {
 			}
 		}
 
-		unique_ptr<ActiveTimer> timer = nullptr;
-
 		// Start timing the storage load step.
 		auto client_context = context.GetClientContext();
 		if (client_context) {
 			auto profiler = client_context->client_data->profiler;
-			timer = make_uniq<ActiveTimer>(profiler->StartTimer(MetricType::ATTACH_LOAD_STORAGE_LATENCY));
+			profiler->StartTimer(MetricsType::ATTACH_LOAD_STORAGE_LATENCY);
 		}
 
 		// Load the checkpoint from storage.
@@ -348,15 +346,15 @@ void SingleFileStorageManager::LoadDatabase(QueryContext context) {
 		checkpoint_reader.LoadFromStorage();
 
 		// End timing the storage load step.
-		if (timer) {
-			timer->EndTimer();
-			timer = nullptr;
+		if (client_context) {
+			auto profiler = client_context->client_data->profiler;
+			profiler->EndTimer(MetricsType::ATTACH_LOAD_STORAGE_LATENCY);
 		}
 
 		// Start timing the WAL replay step.
 		if (client_context) {
 			auto profiler = client_context->client_data->profiler;
-			timer = make_uniq<ActiveTimer>(profiler->StartTimer(MetricType::ATTACH_REPLAY_WAL_LATENCY));
+			profiler->StartTimer(MetricsType::ATTACH_REPLAY_WAL_LATENCY);
 		}
 
 		// Replay the WAL.
@@ -364,8 +362,9 @@ void SingleFileStorageManager::LoadDatabase(QueryContext context) {
 		wal = WriteAheadLog::Replay(context, fs, db, wal_path);
 
 		// End timing the WAL replay step.
-		if (timer) {
-			timer->EndTimer();
+		if (client_context) {
+			auto profiler = client_context->client_data->profiler;
+			profiler->EndTimer(MetricsType::ATTACH_REPLAY_WAL_LATENCY);
 		}
 	}
 
@@ -532,13 +531,20 @@ void SingleFileStorageManager::CreateCheckpoint(QueryContext context, Checkpoint
 			// Start timing the checkpoint.
 			auto client_context = context.GetClientContext();
 			if (client_context) {
-				auto profiler = client_context->client_data->profiler->StartTimer(MetricType::CHECKPOINT_LATENCY);
+				auto profiler = client_context->client_data->profiler;
+				profiler->StartTimer(MetricsType::CHECKPOINT_LATENCY);
 			}
 
 			// Write the checkpoint.
 			auto checkpointer = CreateCheckpointWriter(context, options);
 			checkpointer->CreateCheckpoint();
 
+			// End timing the checkpoint.
+			if (client_context) {
+				auto profiler = client_context->client_data->profiler;
+				profiler->EndTimer(MetricsType::CHECKPOINT_LATENCY);
+			}
+
 		} catch (std::exception &ex) {
 			ErrorData error(ex);
 			throw FatalException("Failed to create checkpoint because of error: %s", error.Message());
diff --git a/src/storage/wal_replay.cpp b/src/storage/wal_replay.cpp
index 8b3c718211..ea271f4885 100644
--- a/src/storage/wal_replay.cpp
+++ b/src/storage/wal_replay.cpp
@@ -312,7 +312,7 @@ unique_ptr<WriteAheadLog> WriteAheadLog::ReplayInternal(QueryContext context, At
 		auto client_context = context.GetClientContext();
 		if (client_context) {
 			auto &profiler = *client_context->client_data->profiler;
-			profiler.AddToCounter(MetricType::WAL_REPLAY_ENTRY_COUNT, replay_entry_count);
+			profiler.AddToCounter(MetricsType::WAL_REPLAY_ENTRY_COUNT, replay_entry_count);
 		}
 	} catch (std::exception &ex) { // LCOV_EXCL_START
 		ErrorData error(ex);
diff --git a/src/transaction/duck_transaction.cpp b/src/transaction/duck_transaction.cpp
index a2438b2e9b..7e8bdcd926 100644
--- a/src/transaction/duck_transaction.cpp
+++ b/src/transaction/duck_transaction.cpp
@@ -215,11 +215,13 @@ ErrorData DuckTransaction::WriteToWAL(ClientContext &context, AttachedDatabase &
 
 		auto &profiler = *context.client_data->profiler;
 
-		auto commit_timer = profiler.StartTimer(MetricType::COMMIT_LOCAL_STORAGE_LATENCY);
+		profiler.StartTimer(MetricsType::COMMIT_LOCAL_STORAGE_LATENCY);
 		storage->Commit(commit_state.get());
+		profiler.EndTimer(MetricsType::COMMIT_LOCAL_STORAGE_LATENCY);
 
-		auto wal_timer = profiler.StartTimer(MetricType::WRITE_TO_WAL_LATENCY);
+		profiler.StartTimer(MetricsType::WRITE_TO_WAL_LATENCY);
 		undo_buffer.WriteToWAL(*wal, commit_state.get());
+		profiler.EndTimer(MetricsType::WRITE_TO_WAL_LATENCY);
 		if (commit_state->HasRowGroupData()) {
 			// if we have optimistically written any data AND we are writing to the WAL, we have written references to
 			// optimistically written blocks
diff --git a/test/api/capi/test_capi_profiling.cpp b/test/api/capi/test_capi_profiling.cpp
index ada774860b..8cab7d5e19 100644
--- a/test/api/capi/test_capi_profiling.cpp
+++ b/test/api/capi/test_capi_profiling.cpp
@@ -42,22 +42,22 @@ void RetrieveMetrics(duckdb_profiling_info info, duckdb::map<string, double> &cu
 		auto value_str = duckdb::string(value_c_str);
 
 		if (depth == 0) {
-			REQUIRE(key_str != EnumUtil::ToString(MetricType::OPERATOR_CARDINALITY));
-			REQUIRE(key_str != EnumUtil::ToString(MetricType::OPERATOR_ROWS_SCANNED));
-			REQUIRE(key_str != EnumUtil::ToString(MetricType::OPERATOR_TIMING));
-			REQUIRE(key_str != EnumUtil::ToString(MetricType::OPERATOR_NAME));
-			REQUIRE(key_str != EnumUtil::ToString(MetricType::OPERATOR_TYPE));
+			REQUIRE(key_str != EnumUtil::ToString(MetricsType::OPERATOR_CARDINALITY));
+			REQUIRE(key_str != EnumUtil::ToString(MetricsType::OPERATOR_ROWS_SCANNED));
+			REQUIRE(key_str != EnumUtil::ToString(MetricsType::OPERATOR_TIMING));
+			REQUIRE(key_str != EnumUtil::ToString(MetricsType::OPERATOR_NAME));
+			REQUIRE(key_str != EnumUtil::ToString(MetricsType::OPERATOR_TYPE));
 		} else {
-			REQUIRE(key_str != EnumUtil::ToString(MetricType::QUERY_NAME));
-			REQUIRE(key_str != EnumUtil::ToString(MetricType::BLOCKED_THREAD_TIME));
-			REQUIRE(key_str != EnumUtil::ToString(MetricType::LATENCY));
-			REQUIRE(key_str != EnumUtil::ToString(MetricType::ROWS_RETURNED));
+			REQUIRE(key_str != EnumUtil::ToString(MetricsType::QUERY_NAME));
+			REQUIRE(key_str != EnumUtil::ToString(MetricsType::BLOCKED_THREAD_TIME));
+			REQUIRE(key_str != EnumUtil::ToString(MetricsType::LATENCY));
+			REQUIRE(key_str != EnumUtil::ToString(MetricsType::ROWS_RETURNED));
 		}
 
-		if (key_str == EnumUtil::ToString(MetricType::QUERY_NAME) ||
-		    key_str == EnumUtil::ToString(MetricType::OPERATOR_NAME) ||
-		    key_str == EnumUtil::ToString(MetricType::OPERATOR_TYPE) ||
-		    key_str == EnumUtil::ToString(MetricType::EXTRA_INFO)) {
+		if (key_str == EnumUtil::ToString(MetricsType::QUERY_NAME) ||
+		    key_str == EnumUtil::ToString(MetricsType::OPERATOR_NAME) ||
+		    key_str == EnumUtil::ToString(MetricsType::OPERATOR_TYPE) ||
+		    key_str == EnumUtil::ToString(MetricsType::EXTRA_INFO)) {
 			REQUIRE(!value_str.empty());
 		} else {
 			double result = 0;
@@ -298,7 +298,7 @@ TEST_CASE("Test profiling with Extra Info enabled", "[capi]") {
 		auto value_c_str = duckdb_get_varchar(value);
 		auto value_str = duckdb::string(value_c_str);
 
-		if (key_str == EnumUtil::ToString(MetricType::EXTRA_INFO)) {
+		if (key_str == EnumUtil::ToString(MetricsType::EXTRA_INFO)) {
 			REQUIRE(value_str.find("__order_by__"));
 			REQUIRE(value_str.find("ASC"));
 			found_extra_info = true;
diff --git a/test/sql/pragma/profiling/test_all_profiling_settings.test b/test/sql/pragma/profiling/test_all_profiling_settings.test
deleted file mode 100644
index 4401ee7f4e..0000000000
--- a/test/sql/pragma/profiling/test_all_profiling_settings.test
+++ /dev/null
@@ -1,103 +0,0 @@
-# name: test/sql/pragma/profiling/test_all_profiling_settings.test
-# description: Test all settings profiling settings.
-# group: [profiling]
-
-# This file is automatically generated by scripts/generate_metric_enums.py
-# Do not edit this file manually, your changes will be overwritten
-
-require json
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SET profiling_mode='all';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"ALL_OPTIMIZERS": "true"
-"ATTACH_LOAD_STORAGE_LATENCY": "true"
-"ATTACH_REPLAY_WAL_LATENCY": "true"
-"BLOCKED_THREAD_TIME": "true"
-"CHECKPOINT_LATENCY": "true"
-"COMMIT_LOCAL_STORAGE_LATENCY": "true"
-"CPU_TIME": "true"
-"CUMULATIVE_CARDINALITY": "true"
-"CUMULATIVE_OPTIMIZER_TIMING": "true"
-"CUMULATIVE_ROWS_SCANNED": "true"
-"EXTRA_INFO": "true"
-"LATENCY": "true"
-"OPERATOR_CARDINALITY": "true"
-"OPERATOR_NAME": "true"
-"OPERATOR_ROWS_SCANNED": "true"
-"OPERATOR_TIMING": "true"
-"OPERATOR_TYPE": "true"
-"OPTIMIZER_BUILD_SIDE_PROBE_SIDE": "true"
-"OPTIMIZER_COLUMN_LIFETIME": "true"
-"OPTIMIZER_COMMON_AGGREGATE": "true"
-"OPTIMIZER_COMMON_SUBEXPRESSIONS": "true"
-"OPTIMIZER_COMMON_SUBPLAN": "true"
-"OPTIMIZER_COMPRESSED_MATERIALIZATION": "true"
-"OPTIMIZER_CTE_FILTER_PUSHER": "true"
-"OPTIMIZER_CTE_INLINING": "true"
-"OPTIMIZER_DELIMINATOR": "true"
-"OPTIMIZER_DUPLICATE_GROUPS": "true"
-"OPTIMIZER_EMPTY_RESULT_PULLUP": "true"
-"OPTIMIZER_EXPRESSION_REWRITER": "true"
-"OPTIMIZER_EXTENSION": "true"
-"OPTIMIZER_FILTER_PULLUP": "true"
-"OPTIMIZER_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_IN_CLAUSE": "true"
-"OPTIMIZER_JOIN_ELIMINATION": "true"
-"OPTIMIZER_JOIN_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_JOIN_ORDER": "true"
-"OPTIMIZER_LATE_MATERIALIZATION": "true"
-"OPTIMIZER_LIMIT_PUSHDOWN": "true"
-"OPTIMIZER_MATERIALIZED_CTE": "true"
-"OPTIMIZER_REGEX_RANGE": "true"
-"OPTIMIZER_REORDER_FILTER": "true"
-"OPTIMIZER_SAMPLING_PUSHDOWN": "true"
-"OPTIMIZER_STATISTICS_PROPAGATION": "true"
-"OPTIMIZER_SUM_REWRITER": "true"
-"OPTIMIZER_TOP_N": "true"
-"OPTIMIZER_TOP_N_WINDOW_ELIMINATION": "true"
-"OPTIMIZER_UNNEST_REWRITER": "true"
-"OPTIMIZER_UNUSED_COLUMNS": "true"
-"PHYSICAL_PLANNER": "true"
-"PHYSICAL_PLANNER_COLUMN_BINDING": "true"
-"PHYSICAL_PLANNER_CREATE_PLAN": "true"
-"PHYSICAL_PLANNER_RESOLVE_TYPES": "true"
-"PLANNER": "true"
-"PLANNER_BINDING": "true"
-"QUERY_NAME": "true"
-"RESULT_SET_SIZE": "true"
-"ROWS_RETURNED": "true"
-"SYSTEM_PEAK_BUFFER_MEMORY": "true"
-"SYSTEM_PEAK_TEMP_DIR_SIZE": "true"
-"TOTAL_BYTES_READ": "true"
-"TOTAL_BYTES_WRITTEN": "true"
-"TOTAL_MEMORY_ALLOCATED": "true"
-"WAITING_TO_ATTACH_LATENCY": "true"
-"WAL_REPLAY_ENTRY_COUNT": "true"
-"WRITE_TO_WAL_LATENCY": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT cpu_time, extra_info, rows_returned, latency FROM metrics_output;
-
diff --git a/test/sql/pragma/profiling/test_custom_profiling_memory_and_temp_dir.test_slow b/test/sql/pragma/profiling/test_custom_profiling_memory_and_temp_dir.test_slow
index 862c277560..3d786b26c1 100644
--- a/test/sql/pragma/profiling/test_custom_profiling_memory_and_temp_dir.test_slow
+++ b/test/sql/pragma/profiling/test_custom_profiling_memory_and_temp_dir.test_slow
@@ -10,9 +10,6 @@ PRAGMA enable_verification;
 statement ok
 PRAGMA enable_profiling = 'json';
 
-statement ok
-PRAGMA custom_profiling_settings='{"SYSTEM_PEAK_BUFFER_MEMORY": "true", "SYSTEM_PEAK_TEMP_DIR_SIZE": "true"}';
-
 statement ok
 PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
 
diff --git a/test/sql/pragma/profiling/test_custom_profiling_optimizer_settings.test b/test/sql/pragma/profiling/test_custom_profiling_optimizer.test
similarity index 99%
rename from test/sql/pragma/profiling/test_custom_profiling_optimizer_settings.test
rename to test/sql/pragma/profiling/test_custom_profiling_optimizer.test
index d062a80d84..fe9d5e99bd 100644
--- a/test/sql/pragma/profiling/test_custom_profiling_optimizer_settings.test
+++ b/test/sql/pragma/profiling/test_custom_profiling_optimizer.test
@@ -1,4 +1,4 @@
-# name: test/sql/pragma/profiling/test_custom_profiling_optimizer_settings.test
+# name: test/sql/pragma/profiling/test_custom_profiling_optimizer.test
 # description: Test custom optimizer profiling settings.
 # group: [profiling]
 
@@ -8,13 +8,13 @@
 require json
 
 statement ok
-PRAGMA enable_profiling = 'json';
+PRAGMA enable_verification;
 
 statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
+PRAGMA enable_profiling = 'json';
 
 statement ok
-SET profiling_mode='standard';
+PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
 
 statement ok
 PRAGMA custom_profiling_settings='{"ALL_OPTIMIZERS": "true"}';
diff --git a/test/sql/pragma/profiling/test_custom_profiling_using_groups.test b/test/sql/pragma/profiling/test_custom_profiling_using_groups.test
deleted file mode 100644
index 1f650845ef..0000000000
--- a/test/sql/pragma/profiling/test_custom_profiling_using_groups.test
+++ /dev/null
@@ -1,926 +0,0 @@
-# name: test/sql/pragma/profiling/test_custom_profiling_using_groups.test
-# description: Test default profiling settings using groups.
-# group: [profiling]
-
-# This file is automatically generated by scripts/generate_metric_enums.py
-# Do not edit this file manually, your changes will be overwritten
-
-require json
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"ALL": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"ALL_OPTIMIZERS": "true"
-"ATTACH_LOAD_STORAGE_LATENCY": "true"
-"ATTACH_REPLAY_WAL_LATENCY": "true"
-"BLOCKED_THREAD_TIME": "true"
-"CHECKPOINT_LATENCY": "true"
-"COMMIT_LOCAL_STORAGE_LATENCY": "true"
-"CPU_TIME": "true"
-"CUMULATIVE_CARDINALITY": "true"
-"CUMULATIVE_OPTIMIZER_TIMING": "true"
-"CUMULATIVE_ROWS_SCANNED": "true"
-"EXTRA_INFO": "true"
-"LATENCY": "true"
-"OPERATOR_CARDINALITY": "true"
-"OPERATOR_NAME": "true"
-"OPERATOR_ROWS_SCANNED": "true"
-"OPERATOR_TIMING": "true"
-"OPERATOR_TYPE": "true"
-"OPTIMIZER_BUILD_SIDE_PROBE_SIDE": "true"
-"OPTIMIZER_COLUMN_LIFETIME": "true"
-"OPTIMIZER_COMMON_AGGREGATE": "true"
-"OPTIMIZER_COMMON_SUBEXPRESSIONS": "true"
-"OPTIMIZER_COMMON_SUBPLAN": "true"
-"OPTIMIZER_COMPRESSED_MATERIALIZATION": "true"
-"OPTIMIZER_CTE_FILTER_PUSHER": "true"
-"OPTIMIZER_CTE_INLINING": "true"
-"OPTIMIZER_DELIMINATOR": "true"
-"OPTIMIZER_DUPLICATE_GROUPS": "true"
-"OPTIMIZER_EMPTY_RESULT_PULLUP": "true"
-"OPTIMIZER_EXPRESSION_REWRITER": "true"
-"OPTIMIZER_EXTENSION": "true"
-"OPTIMIZER_FILTER_PULLUP": "true"
-"OPTIMIZER_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_IN_CLAUSE": "true"
-"OPTIMIZER_JOIN_ELIMINATION": "true"
-"OPTIMIZER_JOIN_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_JOIN_ORDER": "true"
-"OPTIMIZER_LATE_MATERIALIZATION": "true"
-"OPTIMIZER_LIMIT_PUSHDOWN": "true"
-"OPTIMIZER_MATERIALIZED_CTE": "true"
-"OPTIMIZER_REGEX_RANGE": "true"
-"OPTIMIZER_REORDER_FILTER": "true"
-"OPTIMIZER_SAMPLING_PUSHDOWN": "true"
-"OPTIMIZER_STATISTICS_PROPAGATION": "true"
-"OPTIMIZER_SUM_REWRITER": "true"
-"OPTIMIZER_TOP_N": "true"
-"OPTIMIZER_TOP_N_WINDOW_ELIMINATION": "true"
-"OPTIMIZER_UNNEST_REWRITER": "true"
-"OPTIMIZER_UNUSED_COLUMNS": "true"
-"PHYSICAL_PLANNER": "true"
-"PHYSICAL_PLANNER_COLUMN_BINDING": "true"
-"PHYSICAL_PLANNER_CREATE_PLAN": "true"
-"PHYSICAL_PLANNER_RESOLVE_TYPES": "true"
-"PLANNER": "true"
-"PLANNER_BINDING": "true"
-"QUERY_NAME": "true"
-"RESULT_SET_SIZE": "true"
-"ROWS_RETURNED": "true"
-"SYSTEM_PEAK_BUFFER_MEMORY": "true"
-"SYSTEM_PEAK_TEMP_DIR_SIZE": "true"
-"TOTAL_BYTES_READ": "true"
-"TOTAL_BYTES_WRITTEN": "true"
-"TOTAL_MEMORY_ALLOCATED": "true"
-"WAITING_TO_ATTACH_LATENCY": "true"
-"WAL_REPLAY_ENTRY_COUNT": "true"
-"WRITE_TO_WAL_LATENCY": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT ALL_OPTIMIZERS,
-	ATTACH_LOAD_STORAGE_LATENCY,
-	ATTACH_REPLAY_WAL_LATENCY,
-	BLOCKED_THREAD_TIME,
-	CHECKPOINT_LATENCY,
-	COMMIT_LOCAL_STORAGE_LATENCY,
-	CPU_TIME,
-	CUMULATIVE_CARDINALITY,
-	CUMULATIVE_OPTIMIZER_TIMING,
-	CUMULATIVE_ROWS_SCANNED,
-	EXTRA_INFO,
-	LATENCY,
-	OPTIMIZER_BUILD_SIDE_PROBE_SIDE,
-	OPTIMIZER_COLUMN_LIFETIME,
-	OPTIMIZER_COMMON_AGGREGATE,
-	OPTIMIZER_COMMON_SUBEXPRESSIONS,
-	OPTIMIZER_COMMON_SUBPLAN,
-	OPTIMIZER_COMPRESSED_MATERIALIZATION,
-	OPTIMIZER_CTE_FILTER_PUSHER,
-	OPTIMIZER_CTE_INLINING,
-	OPTIMIZER_DELIMINATOR,
-	OPTIMIZER_DUPLICATE_GROUPS,
-	OPTIMIZER_EMPTY_RESULT_PULLUP,
-	OPTIMIZER_EXPRESSION_REWRITER,
-	OPTIMIZER_EXTENSION,
-	OPTIMIZER_FILTER_PULLUP,
-	OPTIMIZER_FILTER_PUSHDOWN,
-	OPTIMIZER_IN_CLAUSE,
-	OPTIMIZER_JOIN_ELIMINATION,
-	OPTIMIZER_JOIN_FILTER_PUSHDOWN,
-	OPTIMIZER_JOIN_ORDER,
-	OPTIMIZER_LATE_MATERIALIZATION,
-	OPTIMIZER_LIMIT_PUSHDOWN,
-	OPTIMIZER_MATERIALIZED_CTE,
-	OPTIMIZER_REGEX_RANGE,
-	OPTIMIZER_REORDER_FILTER,
-	OPTIMIZER_SAMPLING_PUSHDOWN,
-	OPTIMIZER_STATISTICS_PROPAGATION,
-	OPTIMIZER_SUM_REWRITER,
-	OPTIMIZER_TOP_N,
-	OPTIMIZER_TOP_N_WINDOW_ELIMINATION,
-	OPTIMIZER_UNNEST_REWRITER,
-	OPTIMIZER_UNUSED_COLUMNS,
-	PHYSICAL_PLANNER,
-	PHYSICAL_PLANNER_COLUMN_BINDING,
-	PHYSICAL_PLANNER_CREATE_PLAN,
-	PHYSICAL_PLANNER_RESOLVE_TYPES,
-	PLANNER,
-	PLANNER_BINDING,
-	QUERY_NAME,
-	RESULT_SET_SIZE,
-	ROWS_RETURNED,
-	SYSTEM_PEAK_BUFFER_MEMORY,
-	SYSTEM_PEAK_TEMP_DIR_SIZE,
-	TOTAL_BYTES_READ,
-	TOTAL_BYTES_WRITTEN,
-	TOTAL_MEMORY_ALLOCATED,
-	WAITING_TO_ATTACH_LATENCY,
-	WAL_REPLAY_ENTRY_COUNT,
-	WRITE_TO_WAL_LATENCY
-FROM metrics_output;
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"CORE": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"CPU_TIME": "true"
-"CUMULATIVE_CARDINALITY": "true"
-"CUMULATIVE_ROWS_SCANNED": "true"
-"EXTRA_INFO": "true"
-"LATENCY": "true"
-"QUERY_NAME": "true"
-"RESULT_SET_SIZE": "true"
-"ROWS_RETURNED": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT CPU_TIME,
-	CUMULATIVE_CARDINALITY,
-	CUMULATIVE_ROWS_SCANNED,
-	EXTRA_INFO,
-	LATENCY,
-	QUERY_NAME,
-	RESULT_SET_SIZE,
-	ROWS_RETURNED
-FROM metrics_output;
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"DEFAULT": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"ATTACH_LOAD_STORAGE_LATENCY": "true"
-"ATTACH_REPLAY_WAL_LATENCY": "true"
-"BLOCKED_THREAD_TIME": "true"
-"CHECKPOINT_LATENCY": "true"
-"COMMIT_LOCAL_STORAGE_LATENCY": "true"
-"CPU_TIME": "true"
-"CUMULATIVE_CARDINALITY": "true"
-"CUMULATIVE_ROWS_SCANNED": "true"
-"EXTRA_INFO": "true"
-"LATENCY": "true"
-"OPERATOR_CARDINALITY": "true"
-"OPERATOR_NAME": "true"
-"OPERATOR_ROWS_SCANNED": "true"
-"OPERATOR_TIMING": "true"
-"OPERATOR_TYPE": "true"
-"QUERY_NAME": "true"
-"RESULT_SET_SIZE": "true"
-"ROWS_RETURNED": "true"
-"SYSTEM_PEAK_BUFFER_MEMORY": "true"
-"SYSTEM_PEAK_TEMP_DIR_SIZE": "true"
-"TOTAL_BYTES_READ": "true"
-"TOTAL_BYTES_WRITTEN": "true"
-"TOTAL_MEMORY_ALLOCATED": "true"
-"WAITING_TO_ATTACH_LATENCY": "true"
-"WAL_REPLAY_ENTRY_COUNT": "true"
-"WRITE_TO_WAL_LATENCY": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT ATTACH_LOAD_STORAGE_LATENCY,
-	ATTACH_REPLAY_WAL_LATENCY,
-	BLOCKED_THREAD_TIME,
-	CHECKPOINT_LATENCY,
-	COMMIT_LOCAL_STORAGE_LATENCY,
-	CPU_TIME,
-	CUMULATIVE_CARDINALITY,
-	CUMULATIVE_ROWS_SCANNED,
-	EXTRA_INFO,
-	LATENCY,
-	QUERY_NAME,
-	RESULT_SET_SIZE,
-	ROWS_RETURNED,
-	SYSTEM_PEAK_BUFFER_MEMORY,
-	SYSTEM_PEAK_TEMP_DIR_SIZE,
-	TOTAL_BYTES_READ,
-	TOTAL_BYTES_WRITTEN,
-	TOTAL_MEMORY_ALLOCATED,
-	WAITING_TO_ATTACH_LATENCY,
-	WAL_REPLAY_ENTRY_COUNT,
-	WRITE_TO_WAL_LATENCY
-FROM metrics_output;
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"EXECUTION": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"BLOCKED_THREAD_TIME": "true"
-"SYSTEM_PEAK_BUFFER_MEMORY": "true"
-"SYSTEM_PEAK_TEMP_DIR_SIZE": "true"
-"TOTAL_MEMORY_ALLOCATED": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT BLOCKED_THREAD_TIME,
-	SYSTEM_PEAK_BUFFER_MEMORY,
-	SYSTEM_PEAK_TEMP_DIR_SIZE,
-	TOTAL_MEMORY_ALLOCATED
-FROM metrics_output;
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"FILE": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"ATTACH_LOAD_STORAGE_LATENCY": "true"
-"ATTACH_REPLAY_WAL_LATENCY": "true"
-"CHECKPOINT_LATENCY": "true"
-"COMMIT_LOCAL_STORAGE_LATENCY": "true"
-"TOTAL_BYTES_READ": "true"
-"TOTAL_BYTES_WRITTEN": "true"
-"WAITING_TO_ATTACH_LATENCY": "true"
-"WAL_REPLAY_ENTRY_COUNT": "true"
-"WRITE_TO_WAL_LATENCY": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT ATTACH_LOAD_STORAGE_LATENCY,
-	ATTACH_REPLAY_WAL_LATENCY,
-	CHECKPOINT_LATENCY,
-	COMMIT_LOCAL_STORAGE_LATENCY,
-	TOTAL_BYTES_READ,
-	TOTAL_BYTES_WRITTEN,
-	WAITING_TO_ATTACH_LATENCY,
-	WAL_REPLAY_ENTRY_COUNT,
-	WRITE_TO_WAL_LATENCY
-FROM metrics_output;
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"OPERATOR": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"OPERATOR_CARDINALITY": "true"
-"OPERATOR_NAME": "true"
-"OPERATOR_ROWS_SCANNED": "true"
-"OPERATOR_TIMING": "true"
-"OPERATOR_TYPE": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT OPERATOR_CARDINALITY,
-	OPERATOR_NAME,
-	OPERATOR_ROWS_SCANNED,
-	OPERATOR_TIMING,
-	OPERATOR_TYPE
-FROM (
-	SELECT unnest(children, max_depth := 2)
-	FROM metrics_output
-)
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"OPTIMIZER": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"OPTIMIZER_BUILD_SIDE_PROBE_SIDE": "true"
-"OPTIMIZER_COLUMN_LIFETIME": "true"
-"OPTIMIZER_COMMON_AGGREGATE": "true"
-"OPTIMIZER_COMMON_SUBEXPRESSIONS": "true"
-"OPTIMIZER_COMMON_SUBPLAN": "true"
-"OPTIMIZER_COMPRESSED_MATERIALIZATION": "true"
-"OPTIMIZER_CTE_FILTER_PUSHER": "true"
-"OPTIMIZER_CTE_INLINING": "true"
-"OPTIMIZER_DELIMINATOR": "true"
-"OPTIMIZER_DUPLICATE_GROUPS": "true"
-"OPTIMIZER_EMPTY_RESULT_PULLUP": "true"
-"OPTIMIZER_EXPRESSION_REWRITER": "true"
-"OPTIMIZER_EXTENSION": "true"
-"OPTIMIZER_FILTER_PULLUP": "true"
-"OPTIMIZER_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_IN_CLAUSE": "true"
-"OPTIMIZER_JOIN_ELIMINATION": "true"
-"OPTIMIZER_JOIN_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_JOIN_ORDER": "true"
-"OPTIMIZER_LATE_MATERIALIZATION": "true"
-"OPTIMIZER_LIMIT_PUSHDOWN": "true"
-"OPTIMIZER_MATERIALIZED_CTE": "true"
-"OPTIMIZER_REGEX_RANGE": "true"
-"OPTIMIZER_REORDER_FILTER": "true"
-"OPTIMIZER_SAMPLING_PUSHDOWN": "true"
-"OPTIMIZER_STATISTICS_PROPAGATION": "true"
-"OPTIMIZER_SUM_REWRITER": "true"
-"OPTIMIZER_TOP_N": "true"
-"OPTIMIZER_TOP_N_WINDOW_ELIMINATION": "true"
-"OPTIMIZER_UNNEST_REWRITER": "true"
-"OPTIMIZER_UNUSED_COLUMNS": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT OPTIMIZER_BUILD_SIDE_PROBE_SIDE,
-	OPTIMIZER_COLUMN_LIFETIME,
-	OPTIMIZER_COMMON_AGGREGATE,
-	OPTIMIZER_COMMON_SUBEXPRESSIONS,
-	OPTIMIZER_COMMON_SUBPLAN,
-	OPTIMIZER_COMPRESSED_MATERIALIZATION,
-	OPTIMIZER_CTE_FILTER_PUSHER,
-	OPTIMIZER_CTE_INLINING,
-	OPTIMIZER_DELIMINATOR,
-	OPTIMIZER_DUPLICATE_GROUPS,
-	OPTIMIZER_EMPTY_RESULT_PULLUP,
-	OPTIMIZER_EXPRESSION_REWRITER,
-	OPTIMIZER_EXTENSION,
-	OPTIMIZER_FILTER_PULLUP,
-	OPTIMIZER_FILTER_PUSHDOWN,
-	OPTIMIZER_IN_CLAUSE,
-	OPTIMIZER_JOIN_ELIMINATION,
-	OPTIMIZER_JOIN_FILTER_PUSHDOWN,
-	OPTIMIZER_JOIN_ORDER,
-	OPTIMIZER_LATE_MATERIALIZATION,
-	OPTIMIZER_LIMIT_PUSHDOWN,
-	OPTIMIZER_MATERIALIZED_CTE,
-	OPTIMIZER_REGEX_RANGE,
-	OPTIMIZER_REORDER_FILTER,
-	OPTIMIZER_SAMPLING_PUSHDOWN,
-	OPTIMIZER_STATISTICS_PROPAGATION,
-	OPTIMIZER_SUM_REWRITER,
-	OPTIMIZER_TOP_N,
-	OPTIMIZER_TOP_N_WINDOW_ELIMINATION,
-	OPTIMIZER_UNNEST_REWRITER,
-	OPTIMIZER_UNUSED_COLUMNS
-FROM metrics_output;
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"PHASE_TIMING": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"ALL_OPTIMIZERS": "true"
-"CUMULATIVE_OPTIMIZER_TIMING": "true"
-"OPTIMIZER_BUILD_SIDE_PROBE_SIDE": "true"
-"OPTIMIZER_COLUMN_LIFETIME": "true"
-"OPTIMIZER_COMMON_AGGREGATE": "true"
-"OPTIMIZER_COMMON_SUBEXPRESSIONS": "true"
-"OPTIMIZER_COMMON_SUBPLAN": "true"
-"OPTIMIZER_COMPRESSED_MATERIALIZATION": "true"
-"OPTIMIZER_CTE_FILTER_PUSHER": "true"
-"OPTIMIZER_CTE_INLINING": "true"
-"OPTIMIZER_DELIMINATOR": "true"
-"OPTIMIZER_DUPLICATE_GROUPS": "true"
-"OPTIMIZER_EMPTY_RESULT_PULLUP": "true"
-"OPTIMIZER_EXPRESSION_REWRITER": "true"
-"OPTIMIZER_EXTENSION": "true"
-"OPTIMIZER_FILTER_PULLUP": "true"
-"OPTIMIZER_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_IN_CLAUSE": "true"
-"OPTIMIZER_JOIN_ELIMINATION": "true"
-"OPTIMIZER_JOIN_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_JOIN_ORDER": "true"
-"OPTIMIZER_LATE_MATERIALIZATION": "true"
-"OPTIMIZER_LIMIT_PUSHDOWN": "true"
-"OPTIMIZER_MATERIALIZED_CTE": "true"
-"OPTIMIZER_REGEX_RANGE": "true"
-"OPTIMIZER_REORDER_FILTER": "true"
-"OPTIMIZER_SAMPLING_PUSHDOWN": "true"
-"OPTIMIZER_STATISTICS_PROPAGATION": "true"
-"OPTIMIZER_SUM_REWRITER": "true"
-"OPTIMIZER_TOP_N": "true"
-"OPTIMIZER_TOP_N_WINDOW_ELIMINATION": "true"
-"OPTIMIZER_UNNEST_REWRITER": "true"
-"OPTIMIZER_UNUSED_COLUMNS": "true"
-"PHYSICAL_PLANNER": "true"
-"PHYSICAL_PLANNER_COLUMN_BINDING": "true"
-"PHYSICAL_PLANNER_CREATE_PLAN": "true"
-"PHYSICAL_PLANNER_RESOLVE_TYPES": "true"
-"PLANNER": "true"
-"PLANNER_BINDING": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT ALL_OPTIMIZERS,
-	CUMULATIVE_OPTIMIZER_TIMING,
-	OPTIMIZER_BUILD_SIDE_PROBE_SIDE,
-	OPTIMIZER_COLUMN_LIFETIME,
-	OPTIMIZER_COMMON_AGGREGATE,
-	OPTIMIZER_COMMON_SUBEXPRESSIONS,
-	OPTIMIZER_COMMON_SUBPLAN,
-	OPTIMIZER_COMPRESSED_MATERIALIZATION,
-	OPTIMIZER_CTE_FILTER_PUSHER,
-	OPTIMIZER_CTE_INLINING,
-	OPTIMIZER_DELIMINATOR,
-	OPTIMIZER_DUPLICATE_GROUPS,
-	OPTIMIZER_EMPTY_RESULT_PULLUP,
-	OPTIMIZER_EXPRESSION_REWRITER,
-	OPTIMIZER_EXTENSION,
-	OPTIMIZER_FILTER_PULLUP,
-	OPTIMIZER_FILTER_PUSHDOWN,
-	OPTIMIZER_IN_CLAUSE,
-	OPTIMIZER_JOIN_ELIMINATION,
-	OPTIMIZER_JOIN_FILTER_PUSHDOWN,
-	OPTIMIZER_JOIN_ORDER,
-	OPTIMIZER_LATE_MATERIALIZATION,
-	OPTIMIZER_LIMIT_PUSHDOWN,
-	OPTIMIZER_MATERIALIZED_CTE,
-	OPTIMIZER_REGEX_RANGE,
-	OPTIMIZER_REORDER_FILTER,
-	OPTIMIZER_SAMPLING_PUSHDOWN,
-	OPTIMIZER_STATISTICS_PROPAGATION,
-	OPTIMIZER_SUM_REWRITER,
-	OPTIMIZER_TOP_N,
-	OPTIMIZER_TOP_N_WINDOW_ELIMINATION,
-	OPTIMIZER_UNNEST_REWRITER,
-	OPTIMIZER_UNUSED_COLUMNS,
-	PHYSICAL_PLANNER,
-	PHYSICAL_PLANNER_COLUMN_BINDING,
-	PHYSICAL_PLANNER_CREATE_PLAN,
-	PHYSICAL_PLANNER_RESOLVE_TYPES,
-	PLANNER,
-	PLANNER_BINDING
-FROM metrics_output;
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"DEFAULT": "true", "FILE": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"ATTACH_LOAD_STORAGE_LATENCY": "true"
-"ATTACH_REPLAY_WAL_LATENCY": "true"
-"BLOCKED_THREAD_TIME": "true"
-"CHECKPOINT_LATENCY": "true"
-"COMMIT_LOCAL_STORAGE_LATENCY": "true"
-"CPU_TIME": "true"
-"CUMULATIVE_CARDINALITY": "true"
-"CUMULATIVE_ROWS_SCANNED": "true"
-"EXTRA_INFO": "true"
-"LATENCY": "true"
-"OPERATOR_CARDINALITY": "true"
-"OPERATOR_NAME": "true"
-"OPERATOR_ROWS_SCANNED": "true"
-"OPERATOR_TIMING": "true"
-"OPERATOR_TYPE": "true"
-"QUERY_NAME": "true"
-"RESULT_SET_SIZE": "true"
-"ROWS_RETURNED": "true"
-"SYSTEM_PEAK_BUFFER_MEMORY": "true"
-"SYSTEM_PEAK_TEMP_DIR_SIZE": "true"
-"TOTAL_BYTES_READ": "true"
-"TOTAL_BYTES_WRITTEN": "true"
-"TOTAL_MEMORY_ALLOCATED": "true"
-"WAITING_TO_ATTACH_LATENCY": "true"
-"WAL_REPLAY_ENTRY_COUNT": "true"
-"WRITE_TO_WAL_LATENCY": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT ATTACH_LOAD_STORAGE_LATENCY,
-	ATTACH_REPLAY_WAL_LATENCY,
-	BLOCKED_THREAD_TIME,
-	CHECKPOINT_LATENCY,
-	COMMIT_LOCAL_STORAGE_LATENCY,
-	CPU_TIME,
-	CUMULATIVE_CARDINALITY,
-	CUMULATIVE_ROWS_SCANNED,
-	EXTRA_INFO,
-	LATENCY,
-	QUERY_NAME,
-	RESULT_SET_SIZE,
-	ROWS_RETURNED,
-	SYSTEM_PEAK_BUFFER_MEMORY,
-	SYSTEM_PEAK_TEMP_DIR_SIZE,
-	TOTAL_BYTES_READ,
-	TOTAL_BYTES_WRITTEN,
-	TOTAL_MEMORY_ALLOCATED,
-	WAITING_TO_ATTACH_LATENCY,
-	WAL_REPLAY_ENTRY_COUNT,
-	WRITE_TO_WAL_LATENCY
-FROM metrics_output;
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"FILE": "true", "OPTIMIZER": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"ATTACH_LOAD_STORAGE_LATENCY": "true"
-"ATTACH_REPLAY_WAL_LATENCY": "true"
-"CHECKPOINT_LATENCY": "true"
-"COMMIT_LOCAL_STORAGE_LATENCY": "true"
-"OPTIMIZER_BUILD_SIDE_PROBE_SIDE": "true"
-"OPTIMIZER_COLUMN_LIFETIME": "true"
-"OPTIMIZER_COMMON_AGGREGATE": "true"
-"OPTIMIZER_COMMON_SUBEXPRESSIONS": "true"
-"OPTIMIZER_COMMON_SUBPLAN": "true"
-"OPTIMIZER_COMPRESSED_MATERIALIZATION": "true"
-"OPTIMIZER_CTE_FILTER_PUSHER": "true"
-"OPTIMIZER_CTE_INLINING": "true"
-"OPTIMIZER_DELIMINATOR": "true"
-"OPTIMIZER_DUPLICATE_GROUPS": "true"
-"OPTIMIZER_EMPTY_RESULT_PULLUP": "true"
-"OPTIMIZER_EXPRESSION_REWRITER": "true"
-"OPTIMIZER_EXTENSION": "true"
-"OPTIMIZER_FILTER_PULLUP": "true"
-"OPTIMIZER_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_IN_CLAUSE": "true"
-"OPTIMIZER_JOIN_ELIMINATION": "true"
-"OPTIMIZER_JOIN_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_JOIN_ORDER": "true"
-"OPTIMIZER_LATE_MATERIALIZATION": "true"
-"OPTIMIZER_LIMIT_PUSHDOWN": "true"
-"OPTIMIZER_MATERIALIZED_CTE": "true"
-"OPTIMIZER_REGEX_RANGE": "true"
-"OPTIMIZER_REORDER_FILTER": "true"
-"OPTIMIZER_SAMPLING_PUSHDOWN": "true"
-"OPTIMIZER_STATISTICS_PROPAGATION": "true"
-"OPTIMIZER_SUM_REWRITER": "true"
-"OPTIMIZER_TOP_N": "true"
-"OPTIMIZER_TOP_N_WINDOW_ELIMINATION": "true"
-"OPTIMIZER_UNNEST_REWRITER": "true"
-"OPTIMIZER_UNUSED_COLUMNS": "true"
-"TOTAL_BYTES_READ": "true"
-"TOTAL_BYTES_WRITTEN": "true"
-"WAITING_TO_ATTACH_LATENCY": "true"
-"WAL_REPLAY_ENTRY_COUNT": "true"
-"WRITE_TO_WAL_LATENCY": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT ATTACH_LOAD_STORAGE_LATENCY,
-	ATTACH_REPLAY_WAL_LATENCY,
-	CHECKPOINT_LATENCY,
-	COMMIT_LOCAL_STORAGE_LATENCY,
-	OPTIMIZER_BUILD_SIDE_PROBE_SIDE,
-	OPTIMIZER_COLUMN_LIFETIME,
-	OPTIMIZER_COMMON_AGGREGATE,
-	OPTIMIZER_COMMON_SUBEXPRESSIONS,
-	OPTIMIZER_COMMON_SUBPLAN,
-	OPTIMIZER_COMPRESSED_MATERIALIZATION,
-	OPTIMIZER_CTE_FILTER_PUSHER,
-	OPTIMIZER_CTE_INLINING,
-	OPTIMIZER_DELIMINATOR,
-	OPTIMIZER_DUPLICATE_GROUPS,
-	OPTIMIZER_EMPTY_RESULT_PULLUP,
-	OPTIMIZER_EXPRESSION_REWRITER,
-	OPTIMIZER_EXTENSION,
-	OPTIMIZER_FILTER_PULLUP,
-	OPTIMIZER_FILTER_PUSHDOWN,
-	OPTIMIZER_IN_CLAUSE,
-	OPTIMIZER_JOIN_ELIMINATION,
-	OPTIMIZER_JOIN_FILTER_PUSHDOWN,
-	OPTIMIZER_JOIN_ORDER,
-	OPTIMIZER_LATE_MATERIALIZATION,
-	OPTIMIZER_LIMIT_PUSHDOWN,
-	OPTIMIZER_MATERIALIZED_CTE,
-	OPTIMIZER_REGEX_RANGE,
-	OPTIMIZER_REORDER_FILTER,
-	OPTIMIZER_SAMPLING_PUSHDOWN,
-	OPTIMIZER_STATISTICS_PROPAGATION,
-	OPTIMIZER_SUM_REWRITER,
-	OPTIMIZER_TOP_N,
-	OPTIMIZER_TOP_N_WINDOW_ELIMINATION,
-	OPTIMIZER_UNNEST_REWRITER,
-	OPTIMIZER_UNUSED_COLUMNS,
-	TOTAL_BYTES_READ,
-	TOTAL_BYTES_WRITTEN,
-	WAITING_TO_ATTACH_LATENCY,
-	WAL_REPLAY_ENTRY_COUNT,
-	WRITE_TO_WAL_LATENCY
-FROM metrics_output;
-
-statement ok
-PRAGMA enable_profiling = 'json';
-
-statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
-
-statement ok
-PRAGMA custom_profiling_settings='{"PHASE_TIMING": "true", "EXECUTION": "true", "FILE": "true"}';
-
-statement ok
-SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
-
-statement ok
-PRAGMA disable_profiling;
-
-query I
-SELECT unnest(res) FROM (
-    SELECT current_setting('custom_profiling_settings') AS raw_setting,
-    raw_setting.trim('{}') AS setting,
-    string_split(setting, ', ') AS res
-) ORDER BY ALL;
-----
-"ALL_OPTIMIZERS": "true"
-"ATTACH_LOAD_STORAGE_LATENCY": "true"
-"ATTACH_REPLAY_WAL_LATENCY": "true"
-"BLOCKED_THREAD_TIME": "true"
-"CHECKPOINT_LATENCY": "true"
-"COMMIT_LOCAL_STORAGE_LATENCY": "true"
-"CUMULATIVE_OPTIMIZER_TIMING": "true"
-"OPTIMIZER_BUILD_SIDE_PROBE_SIDE": "true"
-"OPTIMIZER_COLUMN_LIFETIME": "true"
-"OPTIMIZER_COMMON_AGGREGATE": "true"
-"OPTIMIZER_COMMON_SUBEXPRESSIONS": "true"
-"OPTIMIZER_COMMON_SUBPLAN": "true"
-"OPTIMIZER_COMPRESSED_MATERIALIZATION": "true"
-"OPTIMIZER_CTE_FILTER_PUSHER": "true"
-"OPTIMIZER_CTE_INLINING": "true"
-"OPTIMIZER_DELIMINATOR": "true"
-"OPTIMIZER_DUPLICATE_GROUPS": "true"
-"OPTIMIZER_EMPTY_RESULT_PULLUP": "true"
-"OPTIMIZER_EXPRESSION_REWRITER": "true"
-"OPTIMIZER_EXTENSION": "true"
-"OPTIMIZER_FILTER_PULLUP": "true"
-"OPTIMIZER_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_IN_CLAUSE": "true"
-"OPTIMIZER_JOIN_ELIMINATION": "true"
-"OPTIMIZER_JOIN_FILTER_PUSHDOWN": "true"
-"OPTIMIZER_JOIN_ORDER": "true"
-"OPTIMIZER_LATE_MATERIALIZATION": "true"
-"OPTIMIZER_LIMIT_PUSHDOWN": "true"
-"OPTIMIZER_MATERIALIZED_CTE": "true"
-"OPTIMIZER_REGEX_RANGE": "true"
-"OPTIMIZER_REORDER_FILTER": "true"
-"OPTIMIZER_SAMPLING_PUSHDOWN": "true"
-"OPTIMIZER_STATISTICS_PROPAGATION": "true"
-"OPTIMIZER_SUM_REWRITER": "true"
-"OPTIMIZER_TOP_N": "true"
-"OPTIMIZER_TOP_N_WINDOW_ELIMINATION": "true"
-"OPTIMIZER_UNNEST_REWRITER": "true"
-"OPTIMIZER_UNUSED_COLUMNS": "true"
-"PHYSICAL_PLANNER": "true"
-"PHYSICAL_PLANNER_COLUMN_BINDING": "true"
-"PHYSICAL_PLANNER_CREATE_PLAN": "true"
-"PHYSICAL_PLANNER_RESOLVE_TYPES": "true"
-"PLANNER": "true"
-"PLANNER_BINDING": "true"
-"SYSTEM_PEAK_BUFFER_MEMORY": "true"
-"SYSTEM_PEAK_TEMP_DIR_SIZE": "true"
-"TOTAL_BYTES_READ": "true"
-"TOTAL_BYTES_WRITTEN": "true"
-"TOTAL_MEMORY_ALLOCATED": "true"
-"WAITING_TO_ATTACH_LATENCY": "true"
-"WAL_REPLAY_ENTRY_COUNT": "true"
-"WRITE_TO_WAL_LATENCY": "true"
-
-statement ok
-CREATE OR REPLACE TABLE metrics_output AS SELECT * FROM '__TEST_DIR__/profiling_output.json';
-
-statement ok
-SELECT ALL_OPTIMIZERS,
-	ATTACH_LOAD_STORAGE_LATENCY,
-	ATTACH_REPLAY_WAL_LATENCY,
-	BLOCKED_THREAD_TIME,
-	CHECKPOINT_LATENCY,
-	COMMIT_LOCAL_STORAGE_LATENCY,
-	CUMULATIVE_OPTIMIZER_TIMING,
-	OPTIMIZER_BUILD_SIDE_PROBE_SIDE,
-	OPTIMIZER_COLUMN_LIFETIME,
-	OPTIMIZER_COMMON_AGGREGATE,
-	OPTIMIZER_COMMON_SUBEXPRESSIONS,
-	OPTIMIZER_COMMON_SUBPLAN,
-	OPTIMIZER_COMPRESSED_MATERIALIZATION,
-	OPTIMIZER_CTE_FILTER_PUSHER,
-	OPTIMIZER_CTE_INLINING,
-	OPTIMIZER_DELIMINATOR,
-	OPTIMIZER_DUPLICATE_GROUPS,
-	OPTIMIZER_EMPTY_RESULT_PULLUP,
-	OPTIMIZER_EXPRESSION_REWRITER,
-	OPTIMIZER_EXTENSION,
-	OPTIMIZER_FILTER_PULLUP,
-	OPTIMIZER_FILTER_PUSHDOWN,
-	OPTIMIZER_IN_CLAUSE,
-	OPTIMIZER_JOIN_ELIMINATION,
-	OPTIMIZER_JOIN_FILTER_PUSHDOWN,
-	OPTIMIZER_JOIN_ORDER,
-	OPTIMIZER_LATE_MATERIALIZATION,
-	OPTIMIZER_LIMIT_PUSHDOWN,
-	OPTIMIZER_MATERIALIZED_CTE,
-	OPTIMIZER_REGEX_RANGE,
-	OPTIMIZER_REORDER_FILTER,
-	OPTIMIZER_SAMPLING_PUSHDOWN,
-	OPTIMIZER_STATISTICS_PROPAGATION,
-	OPTIMIZER_SUM_REWRITER,
-	OPTIMIZER_TOP_N,
-	OPTIMIZER_TOP_N_WINDOW_ELIMINATION,
-	OPTIMIZER_UNNEST_REWRITER,
-	OPTIMIZER_UNUSED_COLUMNS,
-	PHYSICAL_PLANNER,
-	PHYSICAL_PLANNER_COLUMN_BINDING,
-	PHYSICAL_PLANNER_CREATE_PLAN,
-	PHYSICAL_PLANNER_RESOLVE_TYPES,
-	PLANNER,
-	PLANNER_BINDING,
-	SYSTEM_PEAK_BUFFER_MEMORY,
-	SYSTEM_PEAK_TEMP_DIR_SIZE,
-	TOTAL_BYTES_READ,
-	TOTAL_BYTES_WRITTEN,
-	TOTAL_MEMORY_ALLOCATED,
-	WAITING_TO_ATTACH_LATENCY,
-	WAL_REPLAY_ENTRY_COUNT,
-	WRITE_TO_WAL_LATENCY
-FROM metrics_output;
-
diff --git a/test/sql/pragma/profiling/test_default_profiling_settings.test b/test/sql/pragma/profiling/test_default_profiling_settings.test
index ca5a609e7e..940680eb71 100644
--- a/test/sql/pragma/profiling/test_default_profiling_settings.test
+++ b/test/sql/pragma/profiling/test_default_profiling_settings.test
@@ -8,13 +8,13 @@
 require json
 
 statement ok
-PRAGMA enable_profiling = 'json';
+PRAGMA enable_verification;
 
 statement ok
-PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
+PRAGMA enable_profiling = 'json';
 
 statement ok
-SET profiling_mode='standard';
+PRAGMA profiling_output = '__TEST_DIR__/profiling_output.json';
 
 statement ok
 SELECT unnest(['Maia', 'Thijs', 'Mark', 'Hannes', 'Tom', 'Max', 'Carlo', 'Sam', 'Tania']) AS names ORDER BY random();
diff --git a/test/sql/settings/setting_profiling_mode.test b/test/sql/settings/setting_profiling_mode.test
index b5888b5040..72890ef6fb 100644
--- a/test/sql/settings/setting_profiling_mode.test
+++ b/test/sql/settings/setting_profiling_mode.test
@@ -8,10 +8,7 @@ SET profiling_mode='standard';
 statement ok
 SET profiling_mode='detailed';
 
-statement ok
-SET profiling_mode='all';
-
 statement error
 SET profiling_mode='unknown';
 ----
-<REGEX>:.*Parser Error.*Unrecognized profiling mode.*
+<REGEX>:.*Parser Error.*Unrecognized profiling mode.*
\ No newline at end of file
diff --git a/test/sql/types/numeric/bool_casts.test b/test/sql/types/numeric/bool_casts.test
index d2fcb222a5..a64295757b 100644
--- a/test/sql/types/numeric/bool_casts.test
+++ b/test/sql/types/numeric/bool_casts.test
@@ -42,3 +42,4 @@ False
 True
 
 endloop
+
